[
  {
    "objectID": "chapters/10-Correlation_and_regression.html#other-correlation-coefficients",
    "href": "chapters/10-Correlation_and_regression.html#other-correlation-coefficients",
    "title": "10 Correlation and regression",
    "section": "\n3.1 Other correlation-coefficients",
    "text": "3.1 Other correlation-coefficients\nWhen looking for correlations in data that is non-parametric, i.e. not normally distributed you could use Spearman’s rank order correlation-coefficient (rho ρ) rather than Pearson’s r. cor.test(... method = \"...\") allows you to specify the method used for correlation, you can set this to Spearman’s rho by writing method = \"spearman\"\nData will need to contain continuous or ordinal variables. The Spearman correlation coefficient is based on the ranked values for each variable rather than the raw data. The Spearman correlation between two variables is equal to the Pearson correlation between the rank values of those two variables.\nWe want to look at the correlation between students self-efficacy in digital competencies (ICTEFFIC) and wealth (HOMEPOS) for students in the the UK. To make the data set manageable, let us examine girls whose mother or father is a software developer\n\n# create a data set for the UK, including the HOMEPOS and ICTEFFIC variables\nsub_data &lt;- PISA_2022 %&gt;% \n              select(CNT, HOMEPOS, ICTEFFIC, ST004D01T, OCOD1, OCOD2) %&gt;%\n              filter(CNT == \"United Kingdom\") %&gt;%\n              filter(ST004D01T == \"Female\") %&gt;%\n              filter(OCOD1 == \"Software developers\" | OCOD2 == \"Software developers\")\n\nIt is unclear if ICTEFFIC, self-efficacy in digital competencies, is normalised. We can graph it with geom_density to find out:\n\nggplot(sub_data) + \n  geom_density(aes(x=ICTEFFIC))\n\n\n\n\n\n\n\nThe data doesn’t look very normal.\nWe can run the Shapiro-Wilk Test to check for the the normality of the data, any alpha value greater than 0.05 means we can assume that the data is normally distributed.\n\nshapiro.test(sub_data$ICTEFFIC)\n\n\n    Shapiro-Wilk normality test\n\ndata:  sub_data$ICTEFFIC\nW = 0.85272, p-value = 0.0001823\n\n\nIn this case the data isn’t normally distributed as p &lt; 0.05 and we need to use a non-parametric correlation test. We need to run Spearman rather than Pearson:\n\ncor.test(sub_data$HOMEPOS, sub_data$ICTEFFIC, method = \"spearman\")\n\n\n    Spearman's rank correlation rho\n\ndata:  sub_data$HOMEPOS and sub_data$ICTEFFIC\nS = 9301.1, p-value = 0.5459\nalternative hypothesis: true rho is not equal to 0\nsample estimates:\n       rho \n-0.1025489 \n\n\nThe result shows no significant correlation (p=0.5459) between wealth and IT self-efficacy for girls who home at least one parent who is a software developer",
    "crumbs": [
      "10 Correlation and regression"
    ]
  },
  {
    "objectID": "chapters/10-Correlation_and_regression.html#checking-the-assumptions-of-the-model",
    "href": "chapters/10-Correlation_and_regression.html#checking-the-assumptions-of-the-model",
    "title": "10 Correlation and regression",
    "section": "\n3.2 Checking the assumptions of the model",
    "text": "3.2 Checking the assumptions of the model\nFor you to conduct the correct correlation test you need to be sure that the data meet several criteria. First, as noted above, the data should be normally distributed for a pearson test to be conducted. You can check the normality of the data using the shapiro.test function and/or by graphing the data. For large data sets such as PISA (n &gt; 5,000), the shapiro.test won’t work and you might want to use the graph to check; alternatively you can also use the central limit theorem, which means that when you have a sufficiently large sample you can presume that the data is normally distributed (Field, Miles, and Field 2012). As a rule of thumb “30 is the magic number”, and any samples you are studying with 30 or more data items can be treated as parametric, e.g. you could use pearson when running correlation analysis on 30 or more items. This is a rough rule of thumb and you should always check the normality of your data before when checking and presenting any result any tests.\nYou also need to expect a linear relationship between the two variables. For example, if you were to plot the data and it looked like a curve, you might want to use a different test. You can use the ggplot function to plot the data and see if it looks linear. The graph below shows data that doesn’t appear to be linearly related.\n\n\n\n\n\n\n\n\nThe data should be of paired observations. If you have missing data in one of the variables you should remove the missing data from the other variable using na.omit() e.g.:\n\nPISA_2015 &lt;- PISA_2015 %&gt;% select(PV1MATH, PV1SCIE) %&gt;% na.omit()\n\nWhen dealing with non-parametric and small data sets you can also use Kendall’s Tau i.e. cor.test(... method = \"kendall\")",
    "crumbs": [
      "10 Correlation and regression"
    ]
  },
  {
    "objectID": "chapters/10-Correlation_and_regression.html#reporting-correlations",
    "href": "chapters/10-Correlation_and_regression.html#reporting-correlations",
    "title": "10 Correlation and regression",
    "section": "\n3.3 Reporting correlations",
    "text": "3.3 Reporting correlations\nTo interpret the correlation co-efficient of a model we can use the following table:\n\n\nCorrelation co-efficient\nRelationship\n\n\n\n.70 or higher\nvery strong positive\n\n\n.40 to .69\nstrong positive\n\n\n.30 to .39\nmoderate positive\n\n\n.20 to .29\nweak positive\n\n\n.01 to .19\nnegligible or none\n\n\n0\nno relationship\n\n\n-.01 to -.19\nnegligible or none\n\n\n-.20 to -.29\nweak negative\n\n\n-.30 to -.39\nmoderate negative\n\n\n-.40 to -.69\nstrong negative\n\n\n-.70 or higher\nvery strong negative\n\n\n\nWhen writing a report we might present our findings like this:\n\nThere was no significant relationship between the perceived quality of sleep and its impact on Mood, r = -.12, p = .17\n\nor\n\nThere is a significant very strong correlation between overall well-being and life satisfaction, r = .86, p = .00",
    "crumbs": [
      "10 Correlation and regression"
    ]
  },
  {
    "objectID": "chapters/10-Correlation_and_regression.html#questions-correlation",
    "href": "chapters/10-Correlation_and_regression.html#questions-correlation",
    "title": "10 Correlation and regression",
    "section": "\n3.4 Questions: Correlation",
    "text": "3.4 Questions: Correlation\n\nUse cor.test to explore the following relationships:\n\n\nPV1MATH to PV1SCIE, is this a stronger relationship than that between Maths and Reading? Why might they be different?\n\n\nanswercor.test(PISA_2022$PV1MATH, PISA_2022$PV1SCIE, method = \"pearson\")\n#&gt; cor 0.8888601\n\ncor.test(PISA_2022$PV1MATH, PISA_2022$PV1READ, method = \"pearson\")\n#&gt; cor 0.8312513\n\n#&gt; very slightly, yes!\n\n\n\nHow does the correlation of wealth HOMEPOS of females ST004D01T and their Reading PV1READ scores compare to males? Why might they be different?\n\n\nanswerdata &lt;- PISA_2022 %&gt;% filter(ST004D01T == \"Female\")\ncor.test(data$HOMEPOS, data$PV1READ, method = \"pearson\")\n#&gt; 0.4972371 \n\ndata &lt;- PISA_2022 %&gt;% filter(ST004D01T == \"Male\")\ncor.test(data$HOMEPOS, data$PV1READ, method = \"pearson\")\n#&gt; cor 0.4216684 \n\n\n\nHow does life satisfaction ST016Q01NA correlate with the science score of students?\n\n\nanswercor.test(PISA_2022$ST016Q01NA, PISA_2022$PV1SCIE, method = \"pearson\")\n#&gt; -0.06439345\n#&gt; there is negligible or no correlation between these variables\n\n\n\nHow does parental involvement in education PARINVOL correlate with reading outcomes for students in Germany (HINT: you might want to check the normality of this data!):\n\n\nanswermdl_data &lt;- PISA_2022 %&gt;%\n  mutate(gender = ST004D01T) %&gt;%\n  filter(!is.na(PARINVOL),\n         CNT == \"Germany\") %&gt;%\n  select(CNT, gender, PARINVOL, PV1READ)\n\nshapiro.test(mdl_data$PARINVOL)\n#&gt; not normally distributed!\n#&gt; W = 0.96017, p-value &lt; 2.2e-16\nggplot(mdl_data) + \n  geom_density(aes(x=PARINVOL))\n\nshapiro.test(mdl_data$PV1READ)\n#&gt; not normally distributed!\n#W = 0.99362, p-value = 4.224e-08\nggplot(mdl_data) + \n  geom_density(aes(x=PV1READ))\n\n#&gt; as the data isn't normally distributed we need to use a non-parametric test, i.e. spearman's rho\ncor.test(mdl_data$PARINVOL, mdl_data$PV1READ, method = \"spearman\")\n#&gt; p-value &lt; 2.2e-16\n#&gt; rho -0.2962208\n\n# or as a graph\nggplot(mdl_data, aes(x=PARINVOL, y=PV1READ)) + \n  geom_point() +\n  geom_smooth(method=\"lm\")\n\n\n\nUsing the full PISA data set, for the United Kingdom How does the sense of belonging to school BELONG correlate with the item that measures bullying BULLIED? How does the UK compare against other countries?\n\n\nanswerdata &lt;- PISA_2022 %&gt;% filter(CNT == \"United Kingdom\")\ncor.test(data$BELONG, data$BULLIED, method = \"pearson\")\n#&gt; -0.3797393\n#&gt; there is a moderate negative correlation between these variables,\n#&gt; students who are bullied less have a greater sense of belonging                                                \n\n\n\n\n\n\n\n\n\nTip\n\n\n\nIf you want to find all the numeric fields, i.e. the fields that you can easily run correlation calculations on, use the following code to list them:\n\nPISA_2022 %&gt;% select(where(is.numeric)) %&gt;% names()\n\n [1] \"CNTSCHID\"   \"CNTSTUID\"   \"ST016Q01NA\" \"WB151Q01HA\" \"WB152Q01HA\"\n [6] \"WB156Q01HA\" \"BELONG\"     \"BULLIED\"    \"DISCLIM\"    \"HOMEPOS\"   \n[11] \"ESCS\"       \"ATTCONFM\"   \"ICTEFFIC\"   \"STUBMI\"     \"PQMIMP\"    \n[16] \"PARINVOL\"   \"PV1MATH\"    \"PV1READ\"    \"PV1SCIE\"",
    "crumbs": [
      "10 Correlation and regression"
    ]
  },
  {
    "objectID": "chapters/10-Correlation_and_regression.html#linear-models-and-regression",
    "href": "chapters/10-Correlation_and_regression.html#linear-models-and-regression",
    "title": "10 Correlation and regression",
    "section": "\n4.1 Linear models and regression",
    "text": "4.1 Linear models and regression\nThe model used is a linear one, therefore, we describe the relationship using the equation of a straight line. In linear regression, with one dependent and one independent variable, we use the Method of Least Squares to find the line of best fit. The means finding a straight line that passes as close as possible to all the points. The distance between a point and this line is called a residual. The line of best fit is the line where the sum of the residuals squared is the smallest number possible.\n\n\nMethod of Least Squares\n\nThe line that is created can be described by the equation:\nOutput = Intercept + Coefficient * Input \nLet’s use linear regression to explore the relationship between the score in maths(PV1MATH) and the score in reading (PV1READ). To build this model we use the lm command:\nlm(&lt;dependent_var&gt; ~ &lt;independent_var&gt; , data=&lt;dataframe&gt;)\nThe first part defines the model we are going to explore, listing the dependent variable and separating it from the independent variable[s] with a tilde ~. You can specify multiple independent variables by adding more plusses, but for the example here we are only going to use one. Once the model has been built we can feed it into the summary(&lt;mdl&gt;) command to output the results:\n\nmdl_math_read &lt;- lm(PV1MATH ~ PV1READ, data=PISA_2022)\nsummary(mdl_math_read)\n\n\nCall:\nlm(formula = PV1MATH ~ PV1READ, data = PISA_2022)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-273.61  -38.33   -2.48   36.01  323.51 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 1.021e+02  2.981e-01   342.5   &lt;2e-16 ***\nPV1READ     7.731e-01  6.599e-04  1171.5   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 56.61 on 613742 degrees of freedom\nMultiple R-squared:  0.691, Adjusted R-squared:  0.691 \nF-statistic: 1.372e+06 on 1 and 613742 DF,  p-value: &lt; 2.2e-16\n\n\nIf you look at the Coefficents: table we can see that PV1READ is significant in explaining the outcome of the model as the p-value Pr(&gt;|t|) is less than 0.001 &lt;2e-16 ***. The null hypothesis is that one variable does not predict another, we can dismiss this. By looking at the Estimate we can also see by how much a PV1MATH grade would increase if the PV1READ increased by one: 0.7731. Additionally, we have R2 value of 0.691, this suggests that the model is very good at explaining the value of the dependent variable, 69.1% of the variance in the PV1MATH grade is explained by the PV1READ grade.",
    "crumbs": [
      "10 Correlation and regression"
    ]
  },
  {
    "objectID": "chapters/10-Correlation_and_regression.html#r-squared",
    "href": "chapters/10-Correlation_and_regression.html#r-squared",
    "title": "10 Correlation and regression",
    "section": "\n4.2 R squared",
    "text": "4.2 R squared\nWith large data sets you will often find a statistically significant difference, but p-values should be read with caution as the larger the data set you use the more likely you are to get a low p-value. The actual magnitude of a significant difference might be very small. r-squared and adjusted r-squared are ways for you to report on the magnitude of a significant difference and when you report the findings from a linear model you should be looking at the p and the R^2^ values. You have already met R, this is the correlation coefficient from earlier, R2 is this value squared:\n\n\nR - The correlation between the observed values of the outcome, and the values predicted by the model.\n\nR2 - The proportion of variance in the dependent variable accounted for by the model.\n\nAdj. R2 - An estimate of R2 in the population (shrinkage), often very similar to plain R2.\n\nImagine we take two experiments a) and b)\n\n\n(a) larger effect-size; (b) smaller effect-size from Coe (2002)\n\nBoth have statistically significant results, but it’s clear that the impact of the intervention in graph a) is larger as there is less overlap between the curves, i.e. there is more difference between the the outcomes.\n\nif the difference were as in graph (a) it would be very significant; in graph (b), on the other hand, the difference might hardly be noticeable (Coe 2002, p2)\n\nDifferent effect sizes have different meanings and there is some debate on how to interpret them, with different interpretations for different fields of research (Schäfer and Schwarz 2019)\n\nHow to interpret effect sizes (Cohen 1962)\n\n\nEffect size value\nEffect size\n\n\n\n0.0 to 0.19\nnegligible\n\n\n0.2 to 0.49\nsmall\n\n\n0.5 to 0.79\nmedium\n\n\n0.8+\nlarge\n\n\n\nHowever, acceptable effect sizes in social sciences - including education - are often very low. You might be familiar with the Education Endowment Foundation’s Teaching and Learning Toolkit which outlines the Impact of different interventions on student learning. For example, repeating a year is seen to decrease student progress by 3 months and providing students with feedback is seen to increase student progress by 6 months. Behind the scenes they are using effect-sizes to predict the impact of educational interventions. In their model an effect-size of 0.1 is considered to have “Low impact”, but also an effect size of this magnitude is translated to 2 months progress in the Toolkit (Higgins et al. 2016, 5).",
    "crumbs": [
      "10 Correlation and regression"
    ]
  },
  {
    "objectID": "chapters/10-Correlation_and_regression.html#questions-regression",
    "href": "chapters/10-Correlation_and_regression.html#questions-regression",
    "title": "10 Correlation and regression",
    "section": "\n4.3 Questions: Regression",
    "text": "4.3 Questions: Regression\n\n\nRun a regression model to look at how wealth HOMEPOS influences Maths grades in Kazakhstan What is the impact of increasing the wealth of students by one unit? How does this model compare against the same model for science and reading scores?\n\n\nanswermdl &lt;- lm(PV1MATH ~ HOMEPOS, \n          data=PISA_2022 %&gt;% filter(CNT==\"Kazakhstan\"))\nsummary(mdl)\n#&gt; HOMEPOS    33.432 \n#&gt; R-squared:  0.1018\n\nmdl &lt;- lm(PV1READ ~ HOMEPOS, \n          data=PISA_2022 %&gt;% filter(CNT==\"Kazakhstan\"))\nsummary(mdl)\n#&gt; HOMEPOS    37.1606 \n#&gt; R-squared:  0.1258\n\nmdl &lt;- lm(PV1SCIE ~ HOMEPOS, \n          data=PISA_2022 %&gt;% filter(CNT==\"Kazakhstan\"))\nsummary(mdl)\n#&gt; HOMEPOS    33.5009\n#&gt; R-squared:  0.1089\n\n\n\nRun a regression model to look at how science grades predict Maths outcomes in UK students. How does this compare to students in France?\n\n\nanswermdl &lt;- lm(PV1MATH ~ PV1SCIE, \n          data=PISA_2022 %&gt;% filter(CNT==\"United Kingdom\"))\nsummary(mdl)\n#&gt; Estimate = 0.80789\n#&gt; p&lt;0.001\n#&gt; R2 = 0.7533\n\nmdl &lt;- lm(PV1MATH ~ PV1SCIE, \n          data=PISA_2022 %&gt;% filter(CNT==\"France\"))\nsummary(mdl)\n#&gt; Estimate = 0.793547\n#&gt; p&lt;0.001\n#&gt; R2 = 0.8012\n\n#&gt; both models are significant, but the model in France has a higher R squared \n#&gt; value, i.e. Science is a better at explaining the variance in maths outcomes \n#&gt; in France than it is in the UK.\n\n\n\nCreate a linear model to look at parental involvement PARINVOL influences Maths grades for female students in Germany and Hong Kong (China). If we use the Education Endowment Foundation’s interpretation of effect sizes (Higgins et al. 2016, 4) what is the impact of increasing parental involvement on student grades in each country?\n\n\nanswermdl &lt;- lm(PV1MATH ~ PARINVOL, \n          data=PISA_2022 %&gt;% filter(ST004D01T==\"Female\",\n                                    CNT==\"Germany\"))\nsummary(mdl)\n#&gt; Estimate = -41.864\n#&gt; p&lt;0.001\n#&gt; R2 = 0.1289\n#&gt; this is just above 0.1, meaning the model has a \"Low impact\" effect size \n#&gt; if we use the Education Endowment Foundation's interpretation of effect sizes\n#&gt; However, increased parental involvement decreases Maths scores!?\n\nmdl &lt;- lm(PV1MATH ~ PARINVOL, \n          data=PISA_2022 %&gt;% filter(ST004D01T==\"Female\",\n                                    CNT==\"Hong Kong (China)\"))\nsummary(mdl)\n\n#&gt; Estimate = -4.614\n#&gt; p&lt;0.001\n#&gt; R2 = 0.001756\n#&gt; Parental involvement has a negligible effect on Maths scores in Hong Kong\n\n\n\nIs it reasonable to presume that using 5 interventions from the education endowment foundation toolkit, each with effect-sizes of 0.1, i.e. 2 months improvement, will increase the progress for the average student in your class by 10 months (5 * 2)?\n\n\nanswer#&gt; Probably not! The effect of the interventions might not be additive, and the \n#&gt; effect of the interventions might not be the same for all students.",
    "crumbs": [
      "10 Correlation and regression"
    ]
  },
  {
    "objectID": "chapters/10-Correlation_and_regression.html#checking-the-assumptions-of-the-model-1",
    "href": "chapters/10-Correlation_and_regression.html#checking-the-assumptions-of-the-model-1",
    "title": "10 Correlation and regression",
    "section": "\n5.1 Checking the assumptions of the model",
    "text": "5.1 Checking the assumptions of the model\nLike the other statistical models you have met so far, linear regression has a number of assumptions that need to be met for the model to be valid. These are:\n\n\nIndependence: The residuals should be independent of each other, i.e. the residuals from one observation should not predict the residuals from another observation, there shouldn’t be patterns in the residuals. We can test the independence of the residuals using the Durbin Watson test from the car package. Where p-values of &lt; 0.05 indicate that the residuals are not independent.\n\n\nlibrary(car)\nmdl &lt;- lm(PV1READ ~ PV1MATH + ST004D01T + ESCS, \n          data = PISA_2022 %&gt;% filter(CNT == \"United Kingdom\"))\ndurbinWatsonTest(mdl)\n\n lag Autocorrelation D-W Statistic p-value\n   1     0.002082558      1.995719   0.848\n Alternative hypothesis: rho != 0\n\n\nIn this test, we can see that the p-value is &gt; 0.05 meaning we can assume that the residuals are independent.\n\n\nNo multicollinearity: The independent variables should not be correlated with each other, e.g. having PV1MATH and PV1SCIE in a model, which are highly correlated, might make it difficult to work out which of the scores is having the impact. You might be able to alleviate this issue by creating a composite variable: composite_score = (PV1MATH + PV1SCIE) / 2 and using this in your model instead. Field, Miles, and Field (2012) suggest that if the correlation between two variables is “above 0.80 or 0.90” (p.276), then you might have a problem with multicollinearity, the actual correlation between these two fields is 0.89. More advanced checks can use the vif() function from the car package to check for multicollinearity. This function will calculate the Variance Inflation Factor (VIF) for each variable in the model. A VIF of 1 means that the variable is not correlated with any other variables, and a VIF of 5 or more means that the variable is highly correlated with other variables.(ibid. p293)\n\n\nlibrary(car)\nmdl &lt;- lm(PV1READ ~ PV1MATH + PV1SCIE + ST004D01T, \n          data = PISA_2022 %&gt;% filter(CNT == \"United Kingdom\"))\n# They are close to 5, consider removing one of the PV1 variables or combining them\nvif(mdl) \n\n  PV1MATH   PV1SCIE ST004D01T \n 4.082640  4.066330  1.008424 \n\n\n\n\nNormality: The residuals should be normally distributed. To check this we can use Q-Q plots. The Shapiro-Wilk test is also used for smaller data sets where there are n &lt; 5000 observations.\n\n\nmdl &lt;- lm(PV1READ ~ PV1MATH + PV1SCIE + ST004D01T, \n          data = PISA_2022 %&gt;% \n            filter(CNT == \"United Kingdom\"))\npar(mfrow = c(2, 2))\nplot(mdl)\n\n\n\n\n\n\n\nThere is some deviation from the red line in the Q-Q Residuals plot, but the residuals are close to the line within the x-axis [-2,2] range and we can assume the data is normally distributed with some confidence.\n\n\nHomoscedasticity: The residuals (the difference between the observed and predicted values) should be equal across all values of the independent variables. This means that the variance of the residuals should be constant. You can use ols_plot_resid_fit from the olsrr package to check for the normality and homoscedasticity of the model. The data points should be spread randomly, with no funneling from one end to another:\n\n\nlibrary(olsrr)\nmdl &lt;- lm(PV1READ ~ PV1MATH + PV1SCIE + ST004D01T, \n          data = PISA_2022 %&gt;% filter(CNT == \"United Kingdom\"))\n\nols_plot_resid_fit(mdl)\n\n\n\n\n\n\n\nThese plots looks good for a random distribution of residuals, but we can add to our analysis by using the Breusch-Pagan test - ols_test_breusch_pagan() in the olsrr package:\n\nlibrary(olsrr)\nmdl &lt;- lm(PV1READ ~ PV1MATH + PV1SCIE + ST004D01T, \n          data = PISA_2022 %&gt;% filter(CNT == \"United Kingdom\"))\n\nols_test_breusch_pagan(mdl)\n\n\n Breusch Pagan Test for Heteroskedasticity\n -----------------------------------------\n Ho: the variance is constant            \n Ha: the variance is not constant        \n\n               Data                 \n -----------------------------------\n Response : PV1READ \n Variables: fitted values of PV1READ \n\n         Test Summary           \n -------------------------------\n DF            =    1 \n Chi2          =    47.53604 \n Prob &gt; Chi2   =    5.400197e-12 \n\n\nThe result here of p&lt;0.05 suggests that there is a degree of heteroscedasticity in the model, for example, we might find that students with high reading scores do relatively badly at maths, when compared to those with lower reading scores, this looks marginally true:\n\n\n\n\n\n\n\n\nHowever, the Breusch-Pagan test does appear to be at odds with the graphs above and it is the case that with large data sets (PISA is huge) many of these model significance tests can overstate the issue, i.e. they report significance when the actual actual effect on the model is very small. A good way of thinking about this is the story of The Princess and the Pea, however many mattresses were placed underneath the princess, she could still feel the pea at the bottom of the pile of mattresses. For everyone else the pea wasn’t important at all, when they saw how many mattresses there were ((https://stats.stackexchange.com/users/247274/dave), n.d.). The mattresses are our data samples, and the princess is our Breusch-Pagan test complaining about something that actually isn’t that important given the large data set we are using. The graphs look fine and we can assume that homoscedasticity is not a problem in our model. Good graphs can often overrule the output of model tests if the data set is large enough (Schmidt and Finan 2018).\nNot meeting all of the assumptions needed for linear models doesn’t mean we can’t report the linear model results, but we should make note of the assumptions that we have checked and the results of these checks to help readers better understand the limitations of the analysis and the robustness of the results. Additionally, we might want to:\n\n\nlog-transform the outcome variable if you think the relationship might be logarithmic, or apply square root or cube root transforms\ncombine the two PV score predictors into one to avoid the potential multi-collinearity,\nfocus on particular countries rather than the whole data set, or\nsplit our data so we only look at high, medium or low performing students only. \n\n\nOther types of regression, such as multilevel models might be able to help you get past these issues as it will allow you to run multiple models on different subsets of the data.\n\n\n\n\n\n\nTip\n\n\n\nTo find out more about the assumptions when using linear models, please see Field, Miles, and Field (2012) and a great book by the University of Wisconsin\nYou might also want to utilise the easystats package which will help you check the assumptions of your model using the check_model() command\n\nlibrary(easystats)\n\nmdl &lt;- lm(PV1READ ~ PV1SCIE + ST004D01T, \n          data = PISA_2022 %&gt;% filter(CNT == \"United Kingdom\"))\n\ncheck_model(mdl)",
    "crumbs": [
      "10 Correlation and regression"
    ]
  },
  {
    "objectID": "chapters/10-Correlation_and_regression.html#reporting-regression",
    "href": "chapters/10-Correlation_and_regression.html#reporting-regression",
    "title": "10 Correlation and regression",
    "section": "\n5.2 Reporting regression",
    "text": "5.2 Reporting regression\nWhen reporting linear regression we should make note of the estimate (also known as beta β-value) of each factor along with their p-values. We need to know the R2 and p-value for the model as well as the F-statistic and the degrees of freedom. We can then construct a few sentences to explain our findings (Zach 2021):\n\nSimple linear regression was used to test if [predictor variable] significantly predicted [response variable]. The overall regression was statistically significant (R2 = [R2 value], F(df regression, df residual) = [F-value], p = [p-value]). It was found that [predictor variable] significantly predicted [response variable] (β = [β-value], p = [p-value]).\n\nFor the example above, this would be:\n\nSimple linear regression was used to test if a student reading grade significantly predicted student maths grade. The overall regression was statistically significant (R2 = 0.7062, F(1,613662) = 737500, p = &lt;0.001). It was found that reading grade significantly predicted maths grade (β = 0.7863, p = &lt;0.001).\n\nAlternatively, you could make use of the easystats package which will do most of the heavy lifting for you:\n\nlibrary(easystats)\nmdl &lt;- lm(PV1MATH ~ PV1READ, data=PISA_2022)\nsummary(mdl)\n\n\nCall:\nlm(formula = PV1MATH ~ PV1READ, data = PISA_2022)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-273.61  -38.33   -2.48   36.01  323.51 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 1.021e+02  2.981e-01   342.5   &lt;2e-16 ***\nPV1READ     7.731e-01  6.599e-04  1171.5   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 56.61 on 613742 degrees of freedom\nMultiple R-squared:  0.691, Adjusted R-squared:  0.691 \nF-statistic: 1.372e+06 on 1 and 613742 DF,  p-value: &lt; 2.2e-16\n\nreport(mdl)\n\nWe fitted a linear model (estimated using OLS) to predict PV1MATH with PV1READ\n(formula: PV1MATH ~ PV1READ). The model explains a statistically significant\nand substantial proportion of variance (R2 = 0.69, F(1, 613742) = 1.37e+06, p &lt;\n.001, adj. R2 = 0.69). The model's intercept, corresponding to PV1READ = 0, is\nat 102.10 (95% CI [101.52, 102.69], t(613742) = 342.54, p &lt; .001). Within this\nmodel:\n\n  - The effect of PV1READ is statistically significant and positive (beta = 0.77,\n95% CI [0.77, 0.77], t(613742) = 1171.47, p &lt; .001; Std. beta = 0.83, 95% CI\n[0.83, 0.83])\n\nStandardized parameters were obtained by fitting the model on a standardized\nversion of the dataset. 95% Confidence Intervals (CIs) and p-values were\ncomputed using a Wald t-distribution approximation.\n\n\n\nYou might also find that you want to convert the results of a linear model into a data frame for further analysis or plotting. To do this we can use the broom package and the tidy() function:\n\nlibrary(broom)\nmdl &lt;- lm(PV1MATH ~ PV1READ, data=PISA_2022)\ntidy(mdl)\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 (Intercept)  102.     0.298         343.       0\n2 PV1READ        0.773  0.000660     1171.       0",
    "crumbs": [
      "10 Correlation and regression"
    ]
  },
  {
    "objectID": "chapters/10-Correlation_and_regression.html#questions-multivariable-regression",
    "href": "chapters/10-Correlation_and_regression.html#questions-multivariable-regression",
    "title": "10 Correlation and regression",
    "section": "\n5.3 Questions: Multivariable regression",
    "text": "5.3 Questions: Multivariable regression\n\n\nCan you explain the result of the following multivariable regression model\n\n\nmdl &lt;- lm(PV1MATH ~ ST016Q01NA + ST004D01T, data = PISA_2022)\nsummary(mdl)\n\n\nCall:\nlm(formula = PV1MATH ~ ST016Q01NA + ST004D01T, data = PISA_2022)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-446.40  -74.65   -8.02   68.69  476.42 \n\nCoefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   446.31124    0.40789 1094.19   &lt;2e-16 ***\nST016Q01NA     -1.81287    0.05404  -33.55   &lt;2e-16 ***\nST004D01TMale   7.33878    0.28095   26.12   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 99.97 on 517070 degrees of freedom\n  (96671 observations deleted due to missingness)\nMultiple R-squared:  0.003065,  Adjusted R-squared:  0.003061 \nF-statistic: 794.8 on 2 and 517070 DF,  p-value: &lt; 2.2e-16\n\n\n\nanswer# The model is significant, p &lt; 0.001, but the overall model has a very \n# small/insignificant effect size, R2 = 0.003, meaning the model explains \n# very little of the variance in maths scores. The estimate for ST016Q01NA \n# statistically significant with an estimate of -1.8, meaning for every \n# point increase in student satisfaction with life, their grades went down.\n# When controlling for life satisfaction, student gender was also \n# significant, with males typically getting 7.3 points more than females.\n\n\n\nCreate a multivariable analysis to look at the impact of gender ST004D01T and parental involvement PARINVOL on reading scores. What is wrong with this model, how could you improve this model?\n\n\nanswermdl &lt;- lm(PV1READ ~ ST004D01T + PARINVOL, data = PISA_2022)\nsummary(mdl)\n\n# the R2 is very low, you could try adding more variables to the model\n# you could also try using the stepwise selection method to find the best model\n# PARINVOL can be seen on table: 19.118\n# https://www.oecd.org/pisa/data/pisa2022technicalreport/PISA-2022-Technical-Report-Ch-19-PISA-Tables.xlsx\n\n\n\nFor the following model, check that the assumptions needed for multivariable analysis have been met:\n\n\nmdl &lt;- lm(PV1SCIE ~ other_grades + ST004D01T + ESCS, \n          data = PISA_2022 %&gt;% \n            filter(CNT == \"Brazil\") %&gt;%\n            mutate(other_grades = (PV1MATH + PV1READ)/2))\nsummary(mdl)\n\n\nanswer# quickest way:\nlibrary(easystats)\ncheck_model(mdl)\n\n# For individual tests:    \nlibrary(car)\nlibrary(olsrr)\n\nmdl &lt;- lm(PV1SCIE ~ other_grades + ST004D01T + ESCS, \n          data = PISA_2022 %&gt;% \n            filter(CNT == \"Brazil\") %&gt;%\n            mutate(other_grades = (PV1MATH + PV1READ)/2))\n\n# Independence\ndurbinWatsonTest(mdl)\n#&gt; lag Autocorrelation D-W Statistic p-value\n#&gt;   1      0.01650897      1.966672   0.094\n# p&gt;0.05 therefore we can assume values are independent\n\n# No multicollinearity\nvif(mdl)\n#&gt; other_grades    ST004D01T         ESCS \n#&gt;     1.161354     1.004684     1.163242 \n# no value over 5, therefore we can assume no multicollinearity\n\n# Normality and Homoscedasticity\npar(mfrow = c(2, 2))\nplot(mdl)\n# QQ plot looks good and no funneling\n\n# Breusch-Pagan test p&gt;0.05\n# therefore data is Homoscedastic\nols_test_breusch_pagan(mdl)\n\n#All tests check out, we can use the model\n\n\n\nCreate your own multivariable analysis and present your findings to another person in your group. Are you able to explain the results to them? Does the model meet the assumptions necessary for a multivariable analysis?",
    "crumbs": [
      "10 Correlation and regression"
    ]
  },
  {
    "objectID": "chapters/10-Correlation_and_regression.html#checking-the-assumptions-of-logistic-regression",
    "href": "chapters/10-Correlation_and_regression.html#checking-the-assumptions-of-logistic-regression",
    "title": "10 Correlation and regression",
    "section": "\n6.1 Checking the assumptions of logistic regression",
    "text": "6.1 Checking the assumptions of logistic regression\nField, Miles, and Field (2012) recommends that you check the assumptions of logistic regression by looking at :\n\n\nLinearity - there exists a linear relationship between the predictors and the logit of the outcome variable (as the outcome can only assume two values, the logit is the natural log of the odds of the event happening)\n\nIndependence of errors - data points should be independent of each other\n\nNo-Multicollinearity - The independent variables should not be correlated with each other\n\nWe can test these using a number of methods, for example, we can use the vif() function from the car package to check for multicollinearity, the Hosmer-Lemeshow hltest() from glmtoolbox package to test for Linearity (note that large datasets might result in low p-values and this test “is to some extent obsolete”2) and the check_model plots from the easystats package. For example\n\nlibrary(easystats)\nlibrary(glmtoolbox)\nlibrary(car)\n\n# make a logistic model \nmdl &lt;- glm(top_5_per ~ gender + z_ESCS + z_PV1READ, \n    data = PISA_2022_top_5 %&gt;% \n      mutate(z_ESCS = z_ESCS[,1],\n             z_PV1READ = scale(PV1READ)[,1]), \n    family=\"binomial\")\n\nvif(mdl)\nhltest(mdl)\ngrphs &lt;- check_model(mdl)\ngrphs$PP_CHECK",
    "crumbs": [
      "10 Correlation and regression"
    ]
  },
  {
    "objectID": "chapters/10-Correlation_and_regression.html#sec-z-values",
    "href": "chapters/10-Correlation_and_regression.html#sec-z-values",
    "title": "10 Correlation and regression",
    "section": "\n8.1 Standardising results with z-values",
    "text": "8.1 Standardising results with z-values\nWhen we are trying to compare data between countries, our results can be heavily skewed by the overall performance of a country. For example, imagine we have country A and country U. Students in country A generally get high grades with a very high standard deviation, whilst students in country U generally get very low grades with a very low standard deviation.\n\ndf &lt;- data.frame(sex=c(\"M\",\"M\",\"M\",\"F\",\"F\",\"F\",\"M\",\"M\",\"M\",\"F\",\"F\",\"F\"),\n           country=c(\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"U\",\"U\",\"U\",\"U\",\"U\",\"U\"),\n           grade=c(100,87,98,95,82,90,10,8,9,12,10,11))\n\ndf %&gt;% group_by(country, sex) %&gt;% \n  mutate(mgrade = mean(grade)) %&gt;%\n  group_by(country) %&gt;%\n  mutate(meancountry = mean(grade),\n         sdgrade = sd(grade)) %&gt;%\n  pivot_wider(names_from = sex, values_from = mgrade) %&gt;%\n  summarise(M_max = max(M, na.rm=TRUE),\n            `F_max` = max(`F`, na.rm=TRUE),\n            difference = M_max-`F_max`,\n            sd = max(sdgrade),\n            mean = max(meancountry))\n\n# A tibble: 2 × 6\n  country M_max F_max difference    sd  mean\n  &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 A          95    89          6  6.90    92\n2 U           9    11         -2  1.41    10\n\n\nIf we look for the difference in grades between females and males in country A we might see a massive difference, whilst female and male students in country U have a much smaller difference. We might then conclude that country U is more equitable. But in reality, because the standard deviation in country U is so small, the relative difference between females and males is actually larger than that seen in country A! To get around this problem, when dealing with situations like this, we can use standardised, or z, values. These z-values would be a student’s grade in relation to the standard deviation of all of that country’s grades.\nTo calculate the standardised z-value for each entry, we use:\n(entry - mean of grouping) / sd of grouping\nFor example, for the first Male student in country A who scored 100 points, we would calculate\n(100 - 92) / 6.899 = 1.16\nThis shows that this student got 1.16 standard deviations more than the mean of the population. For the first female in country U, we would calculate:\n(12 - 10) / 1.141 = 1.75\nThese two values are then directly comparable, the first males in country A is relatively closer to the mean grade of country A, than the first female in country U. How does this work out for the whole country? Going back to whether sex had a greater impact on results in country A or country U we can calculate the z-values for each student by using the scale() command:\n\ndfz &lt;- df %&gt;% group_by(country) %&gt;% \n  mutate(zgrade = scale(grade))\ndfz\n\n# A tibble: 12 × 4\n# Groups:   country [2]\n   sex   country grade zgrade[,1]\n   &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt;      &lt;dbl&gt;\n 1 M     A         100      1.16 \n 2 M     A          87     -0.725\n 3 M     A          98      0.870\n 4 F     A          95      0.435\n 5 F     A          82     -1.45 \n 6 F     A          90     -0.290\n 7 M     U          10      0    \n 8 M     U           8     -1.41 \n 9 M     U           9     -0.707\n10 F     U          12      1.41 \n11 F     U          10      0    \n12 F     U          11      0.707\n\n\nWe can then group by country and by sex and see how the mean z-value varies\n\ndfz %&gt;%\n  group_by(country, sex) %&gt;%\n  summarise(mean_zgrade = mean(zgrade))\n\n# A tibble: 4 × 3\n# Groups:   country [2]\n  country sex   mean_zgrade\n  &lt;chr&gt;   &lt;chr&gt;       &lt;dbl&gt;\n1 A       F          -0.435\n2 A       M           0.435\n3 U       F           0.707\n4 U       M          -0.707\n\n\nWe can clearly see that the grades in country A are relatively closer to the mean of country A, than the grades in country U, meaning that there is less variation in country A.",
    "crumbs": [
      "10 Correlation and regression"
    ]
  },
  {
    "objectID": "chapters/10-Correlation_and_regression.html#sec-Stoet-Geary",
    "href": "chapters/10-Correlation_and_regression.html#sec-Stoet-Geary",
    "title": "10 Correlation and regression",
    "section": "\n8.2 Recreating Stoet and Geary’s paper",
    "text": "8.2 Recreating Stoet and Geary’s paper\nStoet and Geary’s 2018 paper: “The Gender-Equality Paradox in Science, Technology, Engineering, and Mathematics Education” presented controversial findings, including how the increased female uptake of STEM degrees in country could be partially explained (using regression) by the decreased gender equality in that country. We are going to explore part of this paper by looking at another finding (figure 3a) that looked at girls’ achievement in the PISA_2015 science test compared to their maths and reading grades. Comparing this relative grade to boys in the same country, it showed that as gender equality of their country increased, the gap got bigger, i.e. the more gender equal a country, the worse the female relative performance in science.\n\nThe gender gap in intraindividual science scores (a) was larger in more gender-equal countries (rs = .42)",
    "crumbs": [
      "10 Correlation and regression"
    ]
  },
  {
    "objectID": "chapters/10-Correlation_and_regression.html#loading-data-sets",
    "href": "chapters/10-Correlation_and_regression.html#loading-data-sets",
    "title": "10 Correlation and regression",
    "section": "\n8.3 Loading data sets",
    "text": "8.3 Loading data sets\nTo perform more complex analysis you will often want to join different data sets together. Stoet and Geary (2018) explore gender differences in outcomes with gender equality in countries (see their figures 3 and 4), by using the PISA_2015 data set with the science efficacy SCIEEFF, and science performance (maybe PV1SCIE, or a aggregation of PV1, PV2 etc ) fields; mapping this data set to the 2015 Global Gender Gap Index (GGGI). Let’s try and recreate what they did.\nFirst we are going to download the GGGI, unfortunately, it’s difficult to find the 2015 data set, so we’ll use 2013 instead, which can be found here\nThe data is in a .csv format so we need to use read.csv to get it into R (make sure that you use read.csv rather than read_csv as the names will come out slightly differently)\n\n# load the GGGI\nGGGI &lt;- read.csv(\"&lt;folder&gt;table-3b-detailed-rankings-2013.csv\")\n\nIf we look at the names of the GGGI fields we find that there is a Country column and the Overall.Score column, these are the columns that we are interested in. We can also see that many of the top scoring countries, i.e. those with better gender equality are Nordic countries.\n\nGGGI %&gt;% head(5) %&gt;% select(Country, Overall.Score)\n\n      Country Overall.Score\n1     Iceland        0.8731\n2     Finland        0.8421\n3      Norway        0.8417\n4      Sweden        0.8129\n5 Philippines        0.7832\n\n\nNow we will load the 2015 PISA data set, we have a .parquet copy for you here\n\n# load PISA_2015 student data set\nPISA_2015 &lt;- read_parquet(\"&lt;folder&gt;PISA_2015_student_subset.parquet\")",
    "crumbs": [
      "10 Correlation and regression"
    ]
  },
  {
    "objectID": "chapters/10-Correlation_and_regression.html#sec-leftjoin",
    "href": "chapters/10-Correlation_and_regression.html#sec-leftjoin",
    "title": "10 Correlation and regression",
    "section": "\n8.4 Linking data using left_join\n",
    "text": "8.4 Linking data using left_join\n\nTo link the GGGI to the PISA_2015 data set we will use the left_join function from the tidyverse. This takes a few parameters\nleft_join(&lt;table_1&gt;, &lt;table_2&gt;, by=&lt;matching_field[s]&gt;)\nWe will now join a subset of the PISA_2015 data set to a subset of the GGGI scores:\n\nPISA_2015_GGGI &lt;- left_join(\n  PISA_2015 %&gt;% select(CNT, ST004D01T, PV1MATH, PV1SCIE, PV1READ, SCIEEFF),\n  GGGI %&gt;% select(Country, Overall.Score),\n  by=c(\"CNT\"=\"Country\"))\n\n\nline 1, assigns &lt;- the result of the left_join to a new object, PISA_2015_GGGI,\nline 2, specifies &lt;table_1&gt; to be PISA_2015 with the selected fields, note we have chosen to use PV1 grades here, it’s unclear what the original paper uses (See ?@sec-PV for a discussion on the use of PV grades)\nline 3, specifies &lt;table_2&gt; to be GGGI with just the country and Overall.Score fields\nline 4, specifies the &lt;matching_field&gt; to be CNTfrom PISA_2015 and Country from GGGI, this means that the data in &lt;table_2&gt; will be added to &lt;table_1&gt; where CNT and Country are the same. For example for every entry of Finland in PISA_2015, the Overall.Score of 0.8421 will be added. Where it can’t find a matching country, e.g. Albania doesn’t have a GGGI entry, NA will be added.\n\nYou can see the new data set has attached the Overall.Score field from GGGI to the selected fields from PISA_2015:\n\n\n# A tibble: 3 × 7\n  CNT     ST004D01T PV1MATH PV1SCIE PV1READ SCIEEFF Overall.Score\n  &lt;chr&gt;   &lt;fct&gt;       &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;         &lt;dbl&gt;\n1 Albania Female       463.    517.    430.      NA         0.641\n2 Albania Female       430.    480.    463.      NA         0.641\n3 Albania Female       303.    447.    503.      NA         0.641\n\n\n\n\n\n\n\n\nTip\n\n\n\nThere are multiple types of join in the tidyverse, you can find out more about them here\n\n\nThe available joins in the tidyverse, CC 4.0, by rstudio.com",
    "crumbs": [
      "10 Correlation and regression"
    ]
  },
  {
    "objectID": "chapters/10-Correlation_and_regression.html#sec-standard-stoet-geary",
    "href": "chapters/10-Correlation_and_regression.html#sec-standard-stoet-geary",
    "title": "10 Correlation and regression",
    "section": "\n8.5 Standardising PISA results",
    "text": "8.5 Standardising PISA results\nNext, we will try to wrangle the data into shape to recreate figure 3 from Stoet and Geary (2018). To do this we first need to standardise the grades for maths, science and reading so we can compare the results of students between countries without low performing or high performing countries skewing the results (see Section 8.1 for details on how to standardise data). Following the steps outlined on page 7:\n\n\nWe standardized the mathematics, science, and reading scores on a nation-by-nation basis. We call these new standardized scores zMath, zRead, and zScience.\nWe calculated for each student the standardized average score of the new z-scores and we call this zGeneral.\nThen, we calculated for each student their intra-individual strengths by subtracting zGeneral as follows: relativeSciencestrength = zScience - zGeneral, relativeMathstrength = zMath - zGeneral, relativeReadingstrength = zReading - zGeneral.\nFinally, using these new intra-individual (relative) scores, we calculated for each country the averages for boys and girls and subtracted those to calculate the gender gaps in relative academic strengths\n\n\nproduces the following code:\n\ncode# standardise the results for each student in line with pg7\n# https://eprints.leedsbeckett.ac.uk/id/eprint/4753/6/symplectic-version.pdf\n\nlibrary(tidyverse)\nlibrary(arrow)\nlibrary(ggrepel)\n\n# step 1\nPISA_2015z &lt;- PISA_2015_GGGI %&gt;% \n  rename(gender = ST004D01T) %&gt;%\n  group_by(CNT) %&gt;%\n  mutate(zMaths   = scale(PV1MATH),\n         zScience = scale(PV1SCIE), \n         zReading = scale(PV1READ))\n\n# step 2\nPISA_2015z &lt;- PISA_2015z %&gt;% \n  mutate(zGeneral = (zMaths + zScience + zReading) / 3)\n\n# step 3\nPISA_2015z &lt;- PISA_2015z %&gt;% \n  mutate(rel_MATH = zMaths   - zGeneral,\n         rel_SCIE = zScience - zGeneral,\n         rel_READ = zReading - zGeneral)\n\n# step 4 part 1\nPISA_2015z &lt;- PISA_2015z %&gt;% \n  group_by(CNT, gender) %&gt;%\n  summarise(zMaths = mean(zMaths, na.rm=TRUE),\n            zScience = mean(zScience, na.rm=TRUE),\n            zReading = mean(zReading, na.rm=TRUE),\n            zGeneral = mean(zGeneral, na.rm=TRUE),\n            rel_MATH = zMaths - zGeneral,\n            rel_SCIE = zScience - zGeneral,\n            rel_READ = zReading - zGeneral,\n            gggi = unique(Overall.Score))\n\n# step 4 part 2\npisa_gggi_diff &lt;- PISA_2015z %&gt;%\n  select(CNT, gender, gggi, rel_SCIE) %&gt;%\n  pivot_wider(names_from = gender,\n              values_from = rel_SCIE) %&gt;%\n  mutate(difference =  Male - Female)\n\n\nFinally we will plot the results:\n\ngraph codelibrary(ggrepel)\n\nggplot(pisa_gggi_diff,\n       aes(x=difference, y=gggi)) + \n  geom_point(colour=\"red\") +\n  geom_smooth(method=\"lm\") +\n  geom_text_repel(aes(label=CNT),\n            box.padding = 0.2,\n            max.overlaps = Inf,\n            colour=\"black\") +\n  xlab(paste0(\"relative difference in PV1SCIE scores (male-female)\"))\n\n\n\n\n\n\n\nThe graph is pretty good recreation of what the paper presented, with the general shape the same; differences in grades for each country might be explained by the original paper using 5 plausible values rather than just PV1SCIE, as we have used (Stoet and Geary 2020). Does the statistical model stand up to scrutiny? To find out we will use correlation. Stoet and Geary used Spearman’s rho, signified by the s in rs:\n\nThe most important and novel finding here is that the sex difference in intraindividual strength in science was higher and more favorable to boys in more gender-equal countries, rs = .42, 95% CI = [.19,.61], p &lt; .001, n = 62 (Fig. 3a)\n\nWe can run our version of this model using the following:\n\nresult &lt;- cor.test(pisa_gggi_diff$gggi, \n                    pisa_gggi_diff$difference, \n                    method=\"spearman\")\nresult\n\n\n    Spearman's rank correlation rho\n\ndata:  pisa_gggi_diff$gggi and pisa_gggi_diff$difference\nS = 24384, p-value = 0.02763\nalternative hypothesis: true rho is not equal to 0\nsample estimates:\n      rho \n0.2874342 \n\n\nOur model doesn’t show such a strong correlation. In fact, our model shows a “weak positive” relationship of just 0.287, albeit a significant one (p&lt;0.05).\nFor our version of this model it seems unnecessary to use Spearman’s rho, the number of countries we are comparing with valid data is 59 (pisa_gggi_diff %&gt;% na.omit() %&gt;% nrow()), which is greater than 30 and using the central limit theorem we should be able to use Pearson’s r. Additionally,shapiro.teston both difference andgggi give non-significant results, suggesting Pearson is the better test to use here:\n\nshapiro.test(pisa_gggi_diff$gggi) \n#&gt; p-value = 0.1226\nshapiro.test(pisa_gggi_diff$difference)\n#&gt; p-value = 0.4078\n\nIf we run the model again using Pearson’s r, we get:\n\nresult &lt;- cor.test(pisa_gggi_diff$gggi, \n                    pisa_gggi_diff$difference, \n                    method=\"pearson\")\nresult\n\n\n    Pearson's product-moment correlation\n\ndata:  pisa_gggi_diff$gggi and pisa_gggi_diff$difference\nt = 3.9972, df = 57, p-value = 0.0001863\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.2406661 0.6465242\nsample estimates:\n      cor \n0.4679109 \n\n\nA result much closer to the one published. The differences here might be the result of the different GGGI data set we used or a difference in the way we calculated difference, or something to do with the correlation model used. It would be good to know!\nWe can also explore this data using regression and a linear model looking at the relationship between difference in grades and the gggi value for each country:\n\nmdl &lt;- lm(difference ~ gggi, data = pisa_gggi_diff)\nsummary(mdl)\n\n\nCall:\nlm(formula = difference ~ gggi, data = pisa_gggi_diff)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.067343 -0.018964 -0.003605  0.023548  0.083991 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -0.12926    0.05317  -2.431 0.018228 *  \ngggi         0.29826    0.07462   3.997 0.000186 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.03247 on 57 degrees of freedom\n  (14 observations deleted due to missingness)\nMultiple R-squared:  0.2189,    Adjusted R-squared:  0.2052 \nF-statistic: 15.98 on 1 and 57 DF,  p-value: 0.0001863\n\n\nThis model also finds a significant difference (p&lt;0.001) and an estimate for gggi of 0.298, i.e. for each increase of 1 in gggi, males will do 0.298 of a standard deviation better than females. The R2 is pretty decent too at 0.219 suggesting the finding that Stoet and Geary reported is a sound one.",
    "crumbs": [
      "10 Correlation and regression"
    ]
  },
  {
    "objectID": "chapters/10-Correlation_and_regression.html#footnotes",
    "href": "chapters/10-Correlation_and_regression.html#footnotes",
    "title": "10 Correlation and regression",
    "section": "Footnotes",
    "text": "Footnotes\n\nfor normally distributed data one SD will cover ~68% of responses↩︎\nhttps://stats.stackexchange.com/questions/18750/hosmer-lemeshow-vs-aic-for-logistic-regression↩︎\nhttps://www.statisticssolutions.com/the-linear-regression-analysis-in-spss/:↩︎",
    "crumbs": [
      "10 Correlation and regression"
    ]
  },
  {
    "objectID": "chapters/03-Descriptive.html",
    "href": "chapters/03-Descriptive.html",
    "title": "03 Descriptive Statistics",
    "section": "",
    "text": "Before the session, please read: Davis (2013) Link to chapter\nGetting set up\nEnsure you have the PISA 2022 data frame loaded. If you can see the PISA_2022 data frame in your environment window (at the top right of your screen), there is no need to reload.\n\n# Load the PISA data.\n\nlibrary(arrow)\nlibrary(tidyverse)\n\nPISA_2022 &lt;- read_parquet(r\"[&lt;folder&gt;PISA_2022_student_subset.parquet]\")",
    "crumbs": [
      "03 Descriptive Statistics"
    ]
  },
  {
    "objectID": "chapters/03-Descriptive.html#using-the-command-line-for-descriptive-statistics",
    "href": "chapters/03-Descriptive.html#using-the-command-line-for-descriptive-statistics",
    "title": "03 Descriptive Statistics",
    "section": "2.1 Using the command line for descriptive statistics",
    "text": "2.1 Using the command line for descriptive statistics\nFor further reading on descriptive statistics see chapter 5 of Navaro’s Learning Statistics with R.\n\n\n\n\n\n\nTip\n\n\n\nWe are going to focus on the following variables in the PISA_2022 data frame:\n\nCNT the country of the student.\nHOMEPOS is a self-reported measure of a student’s wealth, linked to the number of possessions students report having in their home (e.g. books, computers, cars, phones etc.). It is a numeric variable, with a mean of -0.447, minimum of -10.07 and a maximum of 15.24.\nESCS is the index of economic, social and cultural status. It might be thought of as a measure of economic and social status (with some cultural capital measures included). It is a numeric variable, with a mean of -0.310, minimum of -6.84 and a maximum of 7.38. It is constructed from three items: highest parental occupation (HISEI), highest level of parental education (PARED), and home possessions (HOMEPOS), including books in the home\nPV1MATH, PV1SCIE, PV1READ are the plausible value scores for achievement tests in mathematics, science and reading, respectively. The full achievement tests are long, so each student only completes a subset of items (which still takes 2 hours). Statistical models are then used to calculate an overall score, based on the students’ answers to the subset of questions, as if students had answered all the questions. Ten different approaches (ten different statistical models, that take different approaches to estimating the overalls score are used) to calculating a representative scores, plausible values are used, leading to ten different plausible values. In this course, will just use the first plausible value (PV1). This differs from the PISA recommendation for using the scores, but simplifies things for teaching. For more on plausible values see: What are plausible values?\nST004D01T is the gender variable and and can take the values: Male, Female or NA.\n\n\n\nThe simplest way to find information about a data frame is to use the console. You can type commands to find out about a data frame directly into the console. To preform an action on a particular column (also called a vector), we use the $ symbol. For example, to refer to country data (which is in the vector CNT) we would use PISA_2022$CNT\nIn the command line, if you want to find the mean of all the repsonses to the HOMEPOS (Home Possessions, a proxy for wealth) item you can type the following:\n\nmean(PISA_2022$HOMEPOS)\n\nNotice that you get this response: [1] NA. An NA in the data frame can occur for a number of reasons, for example it may indicate a response is missing or incomplete, hence the mean can’t be calculated. To tell R to ignore NAs, we add na.rm = TRUE to a function:\n\nmean(PISA_2022$HOMEPOS, na.rm = TRUE)\n\nYou can use the command line with a number of functions to find useful information about a data frame. R has a number of standard functions that might be useful for descriptive statistics. To find out details about data frames, you can use:\n\nnrow() finds the number of rows (e.g. nrow(PISA_2022))\nncol() finds the number of columns (e.g. ncol(PISA_2022))\nnames() finds the names of all the columns (e.g. names(PISA_2022))\n\nIf you are working on individual columns, e.g. max(PISA_2022$PV1SCIE), you can use:\n\nmean() - finds the arithmetic mean\nmedian() - finds the median value\nmin() - finds the minimum value\nmax() - finds the maximum value\nsd() - finds the standard deviation\nrange() - finds the range of values\nlength()- finds the number of items\nunique() - finds the unique items\n\n\n\n\n\n\n\nTip\n\n\n\nMaybe surprisingly, there is no function to calculate the mode in the tidyverse package. However, you can get one by loading the modeest package and using the most frequent value (mfv) function.\n\n# Install the modeest package to calculate a mode\n\nlibrary(modeest)\nlibrary(tidyverse)\n\n# The mode can be found with the most frequent value (mfv) function\n# We can look at about number of books in the home (ST255Q01JA)\n# Then use mfv to find the mode value (note the na.rm=TRUE to avoid NAs)\n\nmfv(PISA_2022$ST255Q01JA, na.rm = TRUE)\n\n[1] 26-100 books\n11 Levels: There are no books. 1-10 books 11-25 books ... No Response\n\n# In the whole dataframe, the mode number of books is 26-100 books\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nYou can read a complete list of the items in PISA here: PISA 2022 student survey item descriptors\n\n\nA useful way to get a quick summary of what is in a data.frame is, the summary command. This command outputs the minimum, median, mean, maximum (and 1st and 3rd quartile values, i.e. the values at 25% and 75% of the range). For example, to get a sense of the science score variable (PV1SCIE) we can use:\n\nsummary(PISA_2022$PV1SCIE)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n    0.0   371.7   444.5   450.5   524.7   895.4",
    "crumbs": [
      "03 Descriptive Statistics"
    ]
  },
  {
    "objectID": "chapters/03-Descriptive.html#bar-graphs",
    "href": "chapters/03-Descriptive.html#bar-graphs",
    "title": "03 Descriptive Statistics",
    "section": "5.1 Bar graphs",
    "text": "5.1 Bar graphs\nImagine we want to plot a graph of how many digital devices with screens students report in their home ST253Q01JA in the UK.\nWhen plotting graphs, it makes things easier to have a data.frame of the data you will pass to ggplot - a bit like the final table of data you will actually plot when drawing a graph in real life.\nTo produce the graph, we will first create a new data.frame that we will use in the plot. I have called that data.frame DDplot (it is data on digital devices (DD) we will plot). To do this, take the PISA_2022 data.frame, pipe it, and select ST253Q01JA and CNT and filter for the UK.\nYou have seen piping before. The new element here is using ggplot, one of R’s graphing functions (you can find more details on how to use geom_bar to plot bar graphs, in the section: Geom_bar).\nTo plot a graph, you call ggplot and specify the data you want to use for the graph (in our case, the new data.frame we have created, DDplot).\nThe next layer of ggplot is the aesthetics (aes), i.e., what our graph will look like. First, we tell ggplot what data we want our y axis to represent, in this case the number of digital devices students have in their home ST253Q01JA . Finally, we specify we want a bar graph using geom_bar().\n\n# Graphing the numbers of digital devices students have\n1DDplot &lt;- PISA_2022 %&gt;%\n2  select(CNT, ST253Q01JA) %&gt;%\n3  filter(CNT == \"United Kingdom\")\n\n# use the DDplot data to create a graph\n4ggplot(data = DDplot,\n5       aes(x = ST253Q01JA)) +\n6  geom_bar()\n\n\n1\n\nline 1 - create a new dataframe for plotting DDplot - we pipe PISA_2022 into the new data frame\n\n2\n\nline 2 - select the columns we need, CNT (country) and ST253Q01JA the item on digital devices\n\n3\n\nline 3 - ‘filter’ for only UK entries\n\n4\n\nline 4 - to plot the chart, we pass the data to the plotting function ggplot\n\n5\n\nline 5 - the first step in plotting is specifying the aesthetics (aes) - for a bar graph it is simple, we only need to state what is on the x-axis (x = ST253Q01JA) - the number of digital devices\n\n6\n\nline 6 - we specify the geom we want, in this case a bar chart with geom_bar()\n\n\n\n\n\n\n\n\n\n\n\nThat is a good first attempt, but there are some aspects we will want to tidy up.\nYou can modify the graph by adding axis labels and titles using xlab(\"label\"), ylab(\"label\"), and ggtitle(\"title\").\n\n# use digital device data to create a graph\n# Adding axis labels and a title\n1ggplot(data = DDplot,\n2       aes(x = ST253Q01JA)) +\n3  geom_bar() +\n4  xlab(\"How many digital devices do you have?\") +\n5  ylab(\"Count\") +\n6  ggtitle(\"Counts of availability of digital devices in the UK\")\n\n\n1\n\nline 1 - to plot the chart, we pass the data to the plotting function ggplot\n\n2\n\nline 2 - the first step in plotting is specifying the aesthetics (aes) - for a bar graph it is simple, we only need to state what is on the x-axis (x = ST253Q01JA) - the number of digital devices\n\n3\n\nline 3 - we specify the geom we want, in this case a bar chart with geom_bar()\n\n4\n\nline 4 - we set the x-axis label with xlab(\"\")\n\n5\n\nline 5 - we set the y-axis label with ylab(\"\")\n\n6\n\nline 6 - we give a titleusing ggtitle(\"\")\n\n\n\n\n\n\n\n\n\n\n\nYou can add colour, by specifying that the fill of the bars should be by the value of IC009Q11NA in the aesthetics: aes(x=IC009Q11NA, fill=IC009Q11NA).\n\n# Adding axis labels and a title\n# And adding colour\nggplot(data = DDplot,\n2       aes(x = ST253Q01JA, fill = ST253Q01JA)) +\n  geom_bar() +\n  xlab(\"How many digital devices do you have?\") +\n  ylab(\"Count\") +\n  ggtitle(\"Counts of availability of digital devices in the UK\")\n\n\n2\n\nline 2 - to set the colour of the columns, within aes we specify the fill should be set by the variable ST253Q01JA (the number of digital devices)\n\n\n\n\n\n\n\n\n\n\n\nTo rotate the text on the x-axis you can add the text: theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)). Inserting \\n into the title adds a line break to divide the long title. We can turn the legend off with theme(legend.position = \"none\")\n\n# Rotating axis text and removing legend\n\nggplot(data = DDplot,\n       aes(x = ST253Q01JA, fill = ST253Q01JA)) +\n  geom_bar() +\n  xlab(\"How many digital devices do you have?\") +\n  ylab(\"Count\") +\n6  ggtitle(\"Counts of availability \\n of digital devices in the UK\") +\n7  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +\n8  theme(legend.position = \"none\")\n\n\n6\n\nline 6 - note that the \\n in the title inserts a line break\n\n7\n\nline 7 - to rotate the text on the x-axis we use theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))\n\n8\n\nline 8 - we can turn off the legend by adding: theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n\n\nYou make wish to plot multiple series, for example, the interactive whiteboard data reported by boys and girls. In that case, we need to include the gender vector ST004D01T in the data frame to plot DDplot. To highlight the difference between boys and girls, in the aesthetics we set the fill colour by the gender variable: fill=ST004D01T. Finally, we need to tell ggplot to plot the bars side-by-side, rather than stacking them - you do this by specifying position = position_dodge2().\n\n# Graphing the number of digital devices students have by gender\n\nDDplot &lt;- PISA_2022 %&gt;%\n2  select(CNT, ST253Q01JA, ST004D01T) %&gt;%\n  filter(CNT == \"United Kingdom\")\n\n# Plotting two series - in this case, by gender\n\nggplot(data = DDplot,\n       aes(x = ST253Q01JA, fill = ST004D01T)) +\n  geom_bar(position = position_dodge2()) +\n  xlab(\"How many digital devices do you have?\") +\n  ylab(\"Count\") +\n  ggtitle(\"Counts of availability \\n of digital devices in the UK\") +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))\n\n\n2\n\nline 2 - to plot two series, we include gender (ST004D01T) in the filter\n\n\n\n\n\n\n\n\n\n\n\nIf you take `position = position_dodge2() out, ggplot will default to stacking the bars. The long response for no devices (\"There are no &lt;digital devices&gt; with screens.\") is not terribly aesthetically pleasing. I will use mutate to change it - recode changes all the \"There are no &lt;digital devices&gt; with screens.\" to \"None\" in the vector ST253Q01JA.\n\n# Graphing the number of digital devices students have\nDDplot &lt;- PISA_2022 %&gt;%\n  select(CNT, ST253Q01JA, ST004D01T) %&gt;%\n  filter(CNT == \"United Kingdom\")\n\n# Changing the longer label for a shorter for ease of plotting\n# Change the long \"There are no &lt;digital devices&gt; with screens\" to \"None\"\nDDplot&lt;-DDplot %&gt;%\n  mutate(ST253Q01JA = recode(ST253Q01JA, \"There are no &lt;digital devices&gt; with screens.\"=\"None\"))\n\n# Plotting two series - in this case, by gender\n\nggplot(data=DDplot,\n       aes(x = ST253Q01JA, fill = ST004D01T)) +\n  geom_bar() +\n  xlab(\"How many digital devices do you have\") +\n  ylab(\"Count\") +\n  ggtitle(\"Counts of availability of digital devices in the UK\")\n\n\n\n\n\n\n\n\nYou can add text, for example the counts, to the graphs, using geom_text. We set the label to after_stat(count)and stat=count. Because the bars have been positioned using position_dodge, you need to do the same for the labels. vjust=-0.5 sets the height of the label over the bar.\n\n# Graphing the number of students who have digital devices by gender\nDDplot &lt;- PISA_2022 %&gt;%\n  select(CNT, ST253Q01JA, ST004D01T) %&gt;%\n  filter(CNT == \"United Kingdom\")\n\n# Changing the longer label for a shorter for ease of plotting\nDDplot&lt;-DDplot%&gt;%\n  mutate(ST253Q01JA = recode(ST253Q01JA, \n6                      \"There are no &lt;digital devices&gt; with screens.\" = \"None\"))\n\n# Plotting two series - in this case, by gender with text\nggplot(data = DDplot,\n       aes(x = ST253Q01JA, fill = ST004D01T)) +\n  geom_bar(position = position_dodge2()) +\n  xlab(\"How many digital devices do you have?\") +\n  ylab(\"Count\") +\n  ggtitle(\"Counts of availability of digital devices in the UK\") +\n  geom_text(aes(label=after_stat(count)), stat = \"count\",\n            position = position_dodge2(width = 0.9), vjust = -0.5, size = 3)\n\n\n6\n\nline 6 - the label There are no &lt;digital devices&gt; with screens is too long to fit on the plot. We can use the recode function, which switches all entries of There are no &lt;digital devices&gt; with screens to None which produces a neater plot",
    "crumbs": [
      "03 Descriptive Statistics"
    ]
  },
  {
    "objectID": "chapters/03-Descriptive.html#scatter-graphs",
    "href": "chapters/03-Descriptive.html#scatter-graphs",
    "title": "03 Descriptive Statistics",
    "section": "5.2 Scatter graphs",
    "text": "5.2 Scatter graphs\nTo plot a scatter graph we use geom_point (see also: Geom_Point section), which works in a similar way to geom_bar.\nExample\nImagine we want to plot a graph of mathematics scores PV1MATH (on the x-axis) against science scores PV1SCIE (y-axis) for students in the UK.\nA above, we first want to create a data.frame to plot - in this case we have called it plotdata. We select only the columns we need (PV1MATH, PV1SCIE, and CNT to filter for the UK), and then filter for the UK.\nWe use the ggplot function, specifying data = plotdata (i.e. we want to plot the data in the specified data frame). As with geom_bar, we can use ggplot and first specify the data we want to plot (ggplot(data = plotdata,). Next, we set the aesthetic variables (aes) - to keep things simple, we will set only the x and y variables. Then we call geom_point to plot the points as a scatter graph.\n\n# Filter to create a data frame of UK scores in science and mathematics\n\nplotdata&lt;-PISA_2022 %&gt;%\n2  select(CNT, PV1SCIE, PV1MATH)%&gt;%\n3  filter(CNT == \"United Kingdom\")\n\n# Plot the data as a scatter graph with geom_point()\n\n4ggplot(data = plotdata,\n5       aes(x = PV1MATH, y = PV1SCIE)) +\n6  geom_point()\n\n\n2\n\nline 2 - select the columns we need for our new plotdata data frame, CNT (country), PV1SCIE (science score), and PV1MATH (maths score).\n\n3\n\nline 3 - filer for UK data\n\n4\n\nline 4 - pass the plotdata we created to ggplot\n\n5\n\nline 5 - set the aesthetics, unlike the bar graph, for a scatter plot we set the variable to plot on the x and y axes (aes(x = PV1MATH, y = PV1SCIE))\n\n6\n\nline 6 - to plot a scatter plot, we use geom_point\n\n\n\n\n\n\n\n\n\n\n\nWe can make things more pleasing by adding more features. For example, we can add colour (geom_point(colour = \"blue\")) and rename the axes labs(x = \"Mathematics score\", y = \"Science score\"). Note when adding to ggplot, the + should come at the end of the line before the new addition to avoid an error.\n\n# Filter to create a data frame of UK scores in science and mathematics\nplotdata&lt;-PISA_2022 %&gt;%\n  select(CNT, PV1SCIE, PV1MATH)%&gt;%\n  filter(CNT == \"United Kingdom\")\n\n# Plot the data as a scatter graph with geom_point()\n\nggplot(data = plotdata,\n       aes(x = PV1MATH, y = PV1SCIE)) +\n6  geom_point(colour = \"blue\") +\n7  labs(x = \"Mathematics Score\", y = \"Science Score\")\n\n\n6\n\nline 6 - inside geom_point we set colour = \"blue\" to plot blue points\n\n7\n\nline 7 - we can use labs() to set the x and y axes labels\n\n\n\n\n\n\n\n\n\n\n\nWe can also add a line using (geom_smooth(method='lm')) - here lm specifies a linear plot (i.e. a straight line).\n\n# Filter to create a data frame of UK scores in science and mathematics\n\nplotdata&lt;-PISA_2022 %&gt;%\n  select(CNT, PV1SCIE, PV1MATH)%&gt;%\n  filter(CNT == \"United Kingdom\")\n\n# Plot the data as a scatter graph with geom_point()\n\nggplot(data = plotdata,\n       aes(x = PV1MATH, y = PV1SCIE)) +\n  geom_point(colour = \"blue\") +\n  labs(x = \"Mathematics Score\", y = \"Science Score\") +\n8  (geom_smooth(method = 'lm'))\n\n\n8\n\nline 8 - geom_smooth is a general function for drawing lines. If we set the (method - 'lm') that uses the linear method (lm) giving a straight line.\n\n\n\n\n\n\n\n\n\n\n\nWe can also change the colour of the points by a variable in the data frame - for example by gender (aes(colour=ST004D01T) - NB In order to change colour by gender, the gender variable (ST0040D01T) must be included in the data set to plot. We can vary the size of points and make them slightly transparent (their alpha level): geom_point(alpha=0.4, size=0.6), and move the legend to the bottom (theme(legend.position = \"bottom\"))\n\n# Create a data set of UK maths and science scores including gender\n\nplotdata&lt;-PISA_2022 %&gt;%\n  select(CNT, PV1SCIE, PV1MATH, ST004D01T) %&gt;%\n  filter(CNT == \"United Kingdom\")\n\n# Plot the data as a scatter graph with geom_point()\nggplot(data = plotdata,\n6       aes(x = PV1MATH, y=PV1SCIE, colour = ST004D01T)) +\n  geom_point(alpha = 0.4, size = 0.6) +\n  labs(x=\"Mathematics Score\", y=\"Science Score\") +\n  (geom_smooth(method = 'lm')) +\n  theme(legend.position = \"bottom\") +\n  theme(legend.title = element_blank())\n\n\n6\n\nline 6 - set the colour of the points by gender (colour = ST004D01T)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nFor a summary of all the elements of a graph you can change in ggplot - see this help sheet.",
    "crumbs": [
      "03 Descriptive Statistics"
    ]
  },
  {
    "objectID": "chapters/03-Descriptive.html#task-1---what-makes-a-good-graph",
    "href": "chapters/03-Descriptive.html#task-1---what-makes-a-good-graph",
    "title": "03 Descriptive Statistics",
    "section": "6.1 Task 1 - What makes a good graph?",
    "text": "6.1 Task 1 - What makes a good graph?\n\nConsider an example of a good and a bad graph / data representation.\n\nis the type of graph appropriate for the data? Can you think of a better choice?\nare the data fairly represented? Are there features that skew how the data might be read? (broken axes, different scales on different sub-graphs, improper scaling, missing labels, omitted data, unhelpful 3D features, poor use of colour)\nare there any unnecessary features, labels or data? What could be added? What is missing?\ndoes the graph tell a clear story? What features allow or prevent a clear message about the data coming across to the reader?",
    "crumbs": [
      "03 Descriptive Statistics"
    ]
  },
  {
    "objectID": "chapters/03-Descriptive.html#task-2---using-the-command-line",
    "href": "chapters/03-Descriptive.html#task-2---using-the-command-line",
    "title": "03 Descriptive Statistics",
    "section": "6.2 Task 2 - Using the command line",
    "text": "6.2 Task 2 - Using the command line\n\n\nUsing the command line, find out:\n\n\nThe number of students (i.e. the number of rows) in the PISA 2022 data frame\nThe number of items in our data frame (i.e. the number of columns)\nThe mean, maximum and minimum science score (don’t forget to use $)\nThe unique values of ST003D02T - what information do you think this column holds?\n\n\n\n\nAnswer\n# Using the command line\n# a) Find the number of students (i.e. the number of rows) in the PISA 2022 data frame\n\nnrow(PISA_2022)\n\n# b) The number of items in our data frame (i.e. the number of columns)\n\nncol(PISA_2022)\n\n# c) The mean, maximum and minimum science score (don't forget to use $)\n\nmean(PISA_2022$PV1SCIE)\nmax(PISA_2022$PV1SCIE)\nmin(PISA_2022$PV1SCIE)\n\n# d) The unique values of ST003D02T - what information do you think this column holds?\n\nunique(PISA_2022$ST003D02T)\n\n# This column contains students' birth months\n# You can find out the subtitle of columns using\n\nattributes(PISA_2022$ST003D02T)",
    "crumbs": [
      "03 Descriptive Statistics"
    ]
  },
  {
    "objectID": "chapters/03-Descriptive.html#task-3---using-the-summary-function",
    "href": "chapters/03-Descriptive.html#task-3---using-the-summary-function",
    "title": "03 Descriptive Statistics",
    "section": "6.3 Task 3 - Using the summary function",
    "text": "6.3 Task 3 - Using the summary function\n\n\nUsing summary find:\n\n\nThe maximum and minimum of the HOMEPOS (Wealth) variable\nThe mean reading score\nThe minimum science score in the data set\nConsider the distributions of the reading and science scores, and comment on any differences.\n\n\n\n\nAnswer\n# Using the command line\n\nsummary(PISA_2022$HOMEPOS)\n\nsummary(PISA_2022$PV1READ)\n\nsummary(PISA_2022$PV1SCIE)",
    "crumbs": [
      "03 Descriptive Statistics"
    ]
  },
  {
    "objectID": "chapters/03-Descriptive.html#task-4---creating-summary-tables",
    "href": "chapters/03-Descriptive.html#task-4---creating-summary-tables",
    "title": "03 Descriptive Statistics",
    "section": "6.4 Task 4 - Creating summary tables",
    "text": "6.4 Task 4 - Creating summary tables\n\n\n\n\n\n\nTip\n\n\n\nMake sure you have spelled the name of the variables PV1MATH, etc. correctly. They are case sensitive. You can use the function colnames(PISA_2022) to get a list of names and copy and paste them.\n\n\n\n\nFind the total number of students who responded in the United States, and their mean science, mathematics and reading scores. Compare that to the responses from the UK. Don’t forget to pipe (%&gt;%) each step!\nFilter the data frame for the UK and group_by gender (which is ST004D01T). Use summarise to find the maximum, minimum and mean scores for boys and girls in mathematics in the UK.\nFilter the data frame for the UK, the US, and group_by gender (which is ST004D01T) and country. Use summarise to compare mathematics and science achievement.\n\n\n\n\nAnswer\n# Summarising responses in the US and UK and finding means\n\nPISA_2022 %&gt;% \n filter(CNT == \"United Kingdom\" | CNT == \"United States\")%&gt;%\n  group_by(CNT)%&gt;%\n  summarise(MeanSci = mean(PV1SCIE), \n            MeanMath = mean(PV1MATH),\n            MeanRead = mean(PV1READ),\n            Total = n())\n\n# Comparing male and female mathematics performance in the UK\n\nPISA_2022 %&gt;% \n filter(CNT == \"United Kingdom\")%&gt;%\n  group_by(ST004D01T)%&gt;%\n  summarise(MeanUKMath = mean(PV1MATH),\n            MaxUKMath = max(PV1MATH),\n            MinUKMath = min(PV1MATH))\n\n# Comparing male and female mathematics performance in the UK and US\n\nPISA_2022 %&gt;% \n  filter(CNT == \"United Kingdom\" | CNT== \"United States\" )%&gt;%\n  group_by(ST004D01T, CNT)%&gt;%\n  summarise(MeanMath = mean(PV1MATH),\n            MaxMath = max(PV1MATH),\n            MinMath = min(PV1MATH))\n\n\n\n\n\n\n\n\nTip\n\n\n\nDon’t forget to use the pipe operator %&gt;% between each function!\n\n\n\nWB171Q01HA asks participants to think of the last time you had a break between classes at school: How did you feel: Happy. For students in France, find out the percentage of students who responded with the different options: Not at all A little Quite a bit Extremely Valid Skip Not Applicable Invalid No Response Missing. (Hint: don’t forget to droplevels()).\n\n\n\nAnswer\n# Finding the percentage of students who feel happy between lessons in France\n\nWellData&lt;-PISA_2022%&gt;%\n  select(CNT, WB171Q01HA)%&gt;%\n  filter(CNT == \"France\")%&gt;%\n  droplevels()\n\nWellData&lt;-as.data.frame(table(WellData))\nTotal = sum(WellData$Freq)\nWellData&lt;-WellData%&gt;%\n  mutate(WellData=round((Freq*100 / Total),1))\n\nWellData\n\n\n\nST251Q06JA asks students if they have a musical instrument in their home. What percentage of students in the UK have no instruments in their home? What is the percentage in China?\n\n\n\nAnswer\n# Finding the percentage of students with no musical instruments in the UK and China\n# Select the relevant variables, filter for the countries and group - dropping levels to cut unnecessary countries\nMusicData&lt;-PISA_2022%&gt;%\n  select(CNT, ST251Q06JA)%&gt;%\n  filter(CNT == \"United Kingdom\"|CNT == \"B-S-J-Z (China)\")%&gt;%\n  group_by(ST251Q06JA, CNT)%&gt;%\n  droplevels()\n\n# Convert to a data frame\n\nMusicData&lt;-as.data.frame(table(MusicData))\n\n# Find the total number of students to calculate percentages\nTotal = sum(MusicData$Freq)\n\n# Mutate to add a column with the percentage calculation\nMusicData&lt;-MusicData%&gt;%\n  mutate(PercComp = round((Freq*100 / Total), 1))\nMusicData\n\n\n\n\n\n\n\n\nTip\n\n\n\nDon’t forget to use the pipe operator %&gt;% between each function!",
    "crumbs": [
      "03 Descriptive Statistics"
    ]
  },
  {
    "objectID": "chapters/03-Descriptive.html#task-5---bar-graphs",
    "href": "chapters/03-Descriptive.html#task-5---bar-graphs",
    "title": "03 Descriptive Statistics",
    "section": "6.5 Task 5 - Bar graphs",
    "text": "6.5 Task 5 - Bar graphs\n\n\nST038Q08NA asks students in the past 12 months, how often do other students spread nasty rumours about them. Plot a graph of how often students spread rumours in the UK and France.\n\n\n\n\nAnswer\n# Select country and question data and Filter for the UK and France\nRumplot &lt;- PISA_2022 %&gt;%\n  select(CNT, ST038Q08NA) %&gt;%\n  filter(CNT == \"United Kingdom\"|CNT == \"France\")\n\n# use rumour data to create a graph\n# Set x as the item on culture and fill by the country\n# Remember to use position dodge to plot the bars side by side\nggplot(data = Rumplot,\n       aes(x = ST038Q08NA, fill = CNT)) +\n  geom_bar(position = \"dodge2\")+\n  xlab(\"Do students spread rumours about you?\")+\n  ylab(\"Count\")+\n  ggtitle(\"Spreading rumours: France vs. the UK\")+\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))\n  # Rotate axis text\n\n\n\n\nPA195Q01JA asks students how many books are in their home. Plot a bar graph for students in Germany. Then plot a graph splitting the data by gender (ST004D01T).\n\n\n\n\nAnswer\n# Create a data set related to books in Germany and include gender\nBookplot &lt;- PISA_2022 %&gt;%\n  select(CNT, PA195Q01JA, ST004D01T) %&gt;%\n  filter(CNT == \"Germany\")\n\n# use book data to create a graph\nggplot(data = Bookplot,\n       aes(x = PA195Q01JA, fill=PA195Q01JA)) +\n  geom_bar(position = \"dodge2\") +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))+ \n  # To rotate the x-axis text\n  xlab(\"Number of books in the home\")+\n  ylab(\"Count\")+\n  ggtitle(\"Number of books in the home for German students by gender\")\n\n# use fill by gender to split the data\nggplot(data = Bookplot,\n       aes(x = PA195Q01JA, fill = ST004D01T)) +\n  geom_bar(position = \"dodge2\") +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))+ \n  # To rotate the x-axis text\n  xlab(\"Number of books in the home\")+\n  ylab(\"Count\")+\n  ggtitle(\"Number of books in the home for German students by gender\")\n\n\n\n\nPlot a bar graph of the mean mathematics scores of all the countries in the PISA data frame\nHint one: you will need to create a summary dataframe using group_by and summarise and then geom_bar(stat=\"identity\"). You use stat=identity when you want geom_bar to plot the values in the data.frame (because you have already summarised) rather than counting the values.\nHint two: you can reorder the x-axis with the reorder function. Rather than a simple x=CNT you can put x=reorder(CNT, -SciMean) which will reorder the x axis in descending order (because of the - sign) of SciMean.\n\n\n\n\nAnswer\n# Create a data set of science scores, and use group_by and summarise to create mean scores by country\n\nSciplot &lt;- PISA_2022 %&gt;%\n  select(CNT, PV1SCIE) %&gt;%\n  group_by(CNT)%&gt;%\n  summarise(MeanSci = mean(PV1SCIE))\n\n# Use geom_bar to plot the data\n\nggplot(data = Sciplot,\n       aes(x = reorder(CNT, -MeanSci), y = MeanSci, fill = MeanSci)) +\n  geom_bar(stat = \"identity\") +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))",
    "crumbs": [
      "03 Descriptive Statistics"
    ]
  },
  {
    "objectID": "chapters/03-Descriptive.html#task-6---scatter-graphs",
    "href": "chapters/03-Descriptive.html#task-6---scatter-graphs",
    "title": "03 Descriptive Statistics",
    "section": "6.6 Task 6 - Scatter graphs",
    "text": "6.6 Task 6 - Scatter graphs\n\n\nFor students in the UK and Brazil, plot science scores (PV1SCIE) by the index of economic, social and cultural status (ESCS). (You may have come across this variable in your studies as socioeconomic status, similar to the idea of ‘social class’.) Then try varying the colour of points by country, and add a line for each.\n\n\n\n\nAnswer\nplotdata&lt;-PISA_2022 %&gt;%\n  select(CNT, PV1SCIE, ESCS)%&gt;%\n  filter(CNT == \"United Kingdom\"|CNT == \"Brazil\")\n# Plot the data as a scatter graph with geom_point()\nggplot(data=plotdata,\n       aes(x = ESCS,y = PV1SCIE, colour = CNT)) +\n  geom_point(alpha = 0.2, size = 0.6)+\n  labs(x = \"Index of economic, social and cultural status\",\n       y = \"Science Score\")+\n  (geom_smooth(method = 'lm'))+\n  theme(legend.position = \"bottom\")+\n  labs(CNT = \"Country\") # Changes ST004D01T to gender for the plot\n\n\n\n\nFor students in the UK, plot a graph of science scores (PV1SCIE) against reading scores (PV1READ). Add a straight line and vary the colour of points by students’ gender.\n\n\n\n\nAnswer\nplotdata&lt;-PISA_2022 %&gt;%\n  select(CNT, PV1SCIE, PV1READ, ST004D01T) %&gt;%\n  filter(CNT == \"United Kingdom\")\n# Plot the data as a scatter graph with geom_point()\nggplot(data = plotdata,\n       aes(x = PV1READ, y = PV1SCIE, colour = ST004D01T)) +\n  geom_point(alpha = 0.6, size = 0.6) +\n  labs(x = \"Reading Score\", y = \"Science Score\") +\n  geom_smooth(method = 'lm') +\n  theme(legend.position = \"bottom\")+\n  labs(colour = \"Gender\") # Changes ST004D01T to gender for the plot\n\n\n\n\nChallenging task (!): Plot a graph of mean mathematics score (PV1MATH) by economic, social and cultural status (ESCS) and highlight countries with mathematics scores above 800. An outline of how to achieve this:\n\n\nCreate a data frame of mean PV1MATH and ESCS by country using group_by and summarise. (Don’t forget to use na.RM=TRUE)\nUse mutate and ifelse to add a new variable, called text which contains the names of countires with mathematics scores over 550.\nUse geom_label to add these data points to the x and y coordinates of the countries e.g. geom_text_repel(PV1MATHmean, ESCSmean, label).\n\n\n\n\nAnswer\n# Create a data frame of ESCS scores and mathematics scores\nplotdata&lt;-PISA_2022%&gt;%\n  select(CNT, ESCS, PV1MATH)%&gt;%\n  group_by(CNT)%&gt;% # group_by country\n  summarise(PV1MATHmean = mean(PV1MATH), #calculate means\n            ESCSmean = mean(ESCS, na.rm = TRUE))%&gt;%\n  mutate(text = ifelse(PV1MATHmean &gt; 550, as.character(CNT), \"\")) \n\n# Use mutate to create a newc columns called text\n# If PV1MATHmean is over 800 set text to equal CNT, otherwise set it to blank (\"\")\n\n# Plot the data, putting mean math score on y and ESCS mean on the x\n# Set the colour of points by the mean math score\n\nggplot(plotdata, aes(y=PV1MATHmean, x = ESCSmean, colour = PV1MATHmean))+\n  geom_point()+\n  geom_text_repel(aes(y = PV1MATHmean, x=ESCSmean, label = text))+\n  xlab(\"Mean ESCS score\")+\n  ylab(\"Mean mathematics score\")+\n  ggtitle(\"Comparison of mean mathematics and mean ESCS score\")+ \n  theme(legend.position = \"none\") # Hide the legend\n\n\n:::",
    "crumbs": [
      "03 Descriptive Statistics"
    ]
  },
  {
    "objectID": "chapters/03-Descriptive.html#task-1-binning-data",
    "href": "chapters/03-Descriptive.html#task-1-binning-data",
    "title": "03 Descriptive Statistics",
    "section": "7.1 Task 1 Binning data",
    "text": "7.1 Task 1 Binning data\nFrequency plots are often used to show data following a normal distribution, To produce a frequency plot, we need to divide data into counts, each covering a range of data. This is called ‘binning’. There is a choice to be made here, in how large or small to make the divisions (‘bins’) - this can affect how the data looks when graphed.\nFor example, to produce a frequency plot of science scores in the UK, we can first run a summary command on PV1SCIE to find the minimum and maximum score:\n\n# Find the range of science score\nsummary(PISA_2022$PV1SCIE)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n    0.0   371.7   444.5   450.5   524.7   895.4 \n\n\nIf we wanted to plot a frequency chart of heights, we might divide the range of scores (from 0-895.4) into bins of 20 points. To do this we can use the cut(&lt;field&gt;,&lt;breaks&gt;) function within the mutate command on a ‘data.frame’. The &lt;field&gt; specifies the range (i.e. from around 0-900) and &lt;breaks&gt; the size of bins.\nIn the example below, we use cut(PV1SCIE, breaks=seq(0,900,20)) to create a new vector (column in the table) with the science scores divided up into bins. The specification breaks=seq(0,900,20)) sets how the data are divided up - into bins (i.e. groups of respondents) of scores starting at 0 and rising to 900 in steps of 20.\n\n# Creates distribution of science scores\n\nbinnedsize &lt;- PISA_2022 %&gt;% # Creates a new data frame with binned data\n  select(PV1SCIE, CNT)%&gt;% # Select the columns needed\n  filter(CNT == \"United Kingdom\")%&gt;%\n  mutate(BinnedPV1SCIE = cut(PV1SCIE, breaks=seq(0, 900, 20)))%&gt;%\n  na.omit() # Drop any NAs\n\n# Plot the data as a bar graph\nggplot(binnedsize,\n       aes(x = BinnedPV1SCIE)) +\n  geom_bar(fill = \"dark green\") +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +\n  labs(y = \"Number of responses\", x = \"Scores range\")\n\n\n\n\n\n\n\n\n\nCreate a graph of the binned counts of mathematics scores in Malta. Don’t forget to run a summary command first to get a sense of the range in values.\n\n\n\n\n\n\n\nTip\n\n\n\nTo find out the range of a vector, you can use the range function in the console - for example, to get a sense of the range of science scores for the whole data frame, we can type: range(PISA_2022$PV1SCIE, na.rm=TRUE). Notice that, because there are NAs in the data, we need to tell the function to ignore them, using na.rm=TRUE.\n\n\n\n\nAnswer\n# Creates distribution of schools by size\nbinnedsize &lt;- PISA_2022 %&gt;% # Creates a new data frame with binned data\n  select(PV1MATH, CNT)%&gt;% # Select the column I need\n  filter(CNT == \"Malta\")%&gt;%\n  mutate(BinnedPV1MATH = cut(PV1MATH, breaks=seq(20,900,20)))%&gt;%\n  na.omit() # Drop any NAs\n# Plot the data as a bar graph\nggplot(binnedsize,\n       aes(x = BinnedPV1MATH)) +\n  geom_bar(fill = \"orange\") +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +\n  labs(y = \"Number of schools\", x = \"Pupil range\")\n\n\n\n\n\n\n\n\nTip\n\n\n\nTo find out a range of a vector, you can use the range function in the console - for example, to get a sense of the range of numbers of students on SEN support. I can type: range(DfE_SEN_data$SEN.support)\n\n\n\nPlot a binned geom_bar graph of the HOMEPOS scores in the UK and Belarus on the same axes.\n\n\n\nAnswer\n# Creates distribution of schools by size\nbinnedwealth &lt;- PISA_2022 %&gt;% # Creates a new data frame with binned data\n  select(HOMEPOS, CNT)%&gt;% # Select the column I need\n  filter(CNT == \"Belarus\"| CNT == \"United Kingdom\")%&gt;%\n  mutate(BinnedHOMEPOS = cut(HOMEPOS, breaks=seq(-8, 5, 0.25)))%&gt;%\n  na.omit() # Drop any NAs\n# Plot the data as a bar graph\nggplot(binnedwealth,\n       aes(x = BinnedHOMEPOS, fill = CNT)) +\n  geom_bar() +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +\n  labs(y = \"Frequency\", x = \"Wealth\")",
    "crumbs": [
      "03 Descriptive Statistics"
    ]
  },
  {
    "objectID": "chapters/03-Descriptive.html#task-2-plotting-data-on-maps",
    "href": "chapters/03-Descriptive.html#task-2-plotting-data-on-maps",
    "title": "03 Descriptive Statistics",
    "section": "7.2 Task 2 Plotting data on maps",
    "text": "7.2 Task 2 Plotting data on maps\nAs well as graphs, R can also plot data onto maps. The geom_map function will plot a map of a region and you can either plot points (using geom_point) or fill regions by drawing a polygon of the shape of that region (using geom_polygon).\nFor example, imagine we created a data frame of the mean science scores of countries in the PISA data:\n\n# Pipe the total data frame and calculate the mean science scores\n# To match with another data frame we will use, we will rename CNT to region\nWorldSci &lt;- PISA_2022 %&gt;%\n  select(CNT, PV1SCIE) %&gt;%\n  group_by(CNT) %&gt;%\n  summarise(meanSci = mean(PV1SCIE)) %&gt;%\n  rename(region = CNT)\n\nIn order to plot the data onto a map, colouring the countries by science scores, we need data which gives the coordinates of the edges of the countries. This data is available from the map_data function in ggplot. First we load the latitude and longitude data into a new data frame world_data. In the next steps we will then use left_join to combine it with the science data, but we need to tidy the data to match the PISA data, before we can join the two data sets.\n\n# Create a data frame of country latitude and longitude data\nworld_data &lt;- map_data(map = \"world\")\n\nOne quirk of the two data frames (world_data and the PISA data) is that some countries have different names. For example, PISA uses ‘United Kingdom’, but the rworldmap package uses ‘UK’. We can change the names of countries in the PISA data.frame to match those in rworldmap, using the case_when function with mutate. For example, if we want to change all United Kingdom entries to UK we use: mutate(region = case_when(region == \"United Kingdom\" ~ \"UK\". The final part of the case_when sets the default - .default = region - that means if none of the matches are found, then region is set to region - i.e. it is left unchanged.\n\n# The names of two countries in the PISA data frame and world_data data frame don't match (UK/United Kingdom and US/United States). Change the level names in the PISA data to match the world_data\n\n WorldSci &lt;- WorldSci %&gt;%\n   mutate(region = case_when(\n                       region == \"United Kingdom\" ~ \"UK\",\n                       region == \"United States\"  ~ \"USA\",\n                       .default = region))\n\nNow that the country names in the two data frames match, we can use left_join to combine them.\n\n# Add the country latitude and longitude data to the PISA scores\n\nWorldSci &lt;- left_join(WorldSci, world_data, by = \"region\")\n\nTo add labels, you can create a data.frame, with only the country names, and their longitudes and latitudes (the mean of the country longitude and latitude), to use as the labels. You can then add geom_text_repelto add the labels. The repel means the labels won’t overlap. Given the number of countries, using geom_text_repel creates a warning that some labels won’t fit.\nTo plot the data, we use ggplot, with the data frame to WorldSci, and the x and y variables set to long and lat, the longitudes and latitudes. We specify that we want to keep the grouping of the data frame (i.e. by country).\nFirst we use geom_map to plot a blank map using the data - this will be the base for the highlighted countries. In the aes we give the longitudes and latitudes, and, as we want a blank map, set the fill to white and the line colour to black.\nFinally, we use geom_polygon to draw coloured shapes, with the fill changing by the value of meanSci. To make the map look nice, I have used a pre-defined colour scale.\n\n# Use geom_map to plot the basic world map (fill is white, line colour is black)\n# Use geom_polygon to plot the PISA data\n# Add a colour scale\nggplot(data = WorldSci, aes(x = long, y = lat, group=group)) +\n  geom_map(data = world_data, \n           map = world_data, \n           aes(map_id = region), \n           fill = \"white\", \n           colour = \"black\")+\n  geom_polygon(aes(fill = meanSci)) +\n  scale_fill_viridis_c(option = \"viridis\")\n\n\n\n\n\n\n\n\nIn ggplot, by default, the aesthetics are passed from one layer to the next. In our first aes call we set a grouping (group=group). However, when we come to the labeling function geom_text_repel, the data frame Labels is not grouped. We therefore need to use new aesthetics and want to ignore the original aesthetics (aes(x=long, y=lat, group=group,label=region))) we previously set.We do this with the command inherit.aes = FALSE (i.e. do not inherit the previous aesthetics).\nTo neaten up the labels we use the ggrepel package to get the geom_text_repel function. You’ll need to make sure that you have installed the ggrepel package, for a reminder on how to install packages see ?@sec-installation. This ensures that text labels don’t overlap. Then in geom_text_repel(data=Labels, inherit.aes = FALSE, aes(x=long, y=lat,label=region)) we specify the label data.frame, and in aes pass the positions of the labels (x=long, y=lat) and specify that the labels are in the region vector.\n\nlibrary(ggrepel)\n\nggplot(data = WorldSci, \n       aes(x = long, y = lat, group = group,label = region)) +\n  geom_map(data = world_data,\n           map = world_data, \n           aes(map_id = region), \n           fill = \"white\",\n           colour = \"black\")+\n  geom_polygon(aes(fill = meanSci)) +\n  scale_fill_viridis_c(option = \"viridis\") +\n  geom_text_repel(data = Labels,\n                 inherit.aes = FALSE,\n                 aes(x = long, y = lat, label = region))\n\n\n\n\n\n\n\n\n\nPlot mean PISA mathematics scores on a world map, labelling the countries.\n\n\n\nAnswer\n# Create a data.frame of mathematics scores\nWorldMath &lt;- PISA_2022 %&gt;%\n  select(CNT, PV1MATH) %&gt;%\n  group_by(CNT) %&gt;%\n  summarise(meanmath = mean(PV1MATH)) %&gt;%\n  rename(region = CNT)\n# The names of two countries in the PISA data frame and world_data data frame don't match (UK/United Kingdom and US/United States). Change the level names in the PISA data to match the world_data\n\nWorldMath &lt;- WorldMath %&gt;%\n   mutate(region = case_when(\n                       region == \"United Kingdom\" ~ \"UK\",\n                       region == \"United States\"  ~ \"USA\",\n                       region == \"Russian Federation\" ~ \"Russia\",\n                       .default = region))\n\n# Create a data frame of country latitude and longitude data\nworld_data &lt;- map_data(map = \"world\")\n\nWorldMath &lt;- left_join(WorldMath, world_data, by = \"region\")\n\n# Use geom_map to plot the basic world map (fill is white, line colour is black)\n# Use geom_polygon to plot the PISA data\n# Add a colour scale\n\nLabels&lt;-WorldMath%&gt;%\n  group_by(region)%&gt;%\n  summarise(meanmath = mean(meanmath), lat = mean(lat), long = mean(long))%&gt;%\n  na.omit()\n\n# Use geom_map to plot the basic world map (fill is white, line colour is black)\n# Use geom_polygon to plot the PISA data\n# Add a colour scale\nggplot(data = WorldMath, \n       aes(x = long, y = lat, group = group,label = region)) +\n  geom_map(data = world_data,\n           map = world_data, \n           aes(map_id = region), \n           fill = \"white\",\n           colour = \"black\")+\n  geom_polygon(aes(fill = meanmath)) +\n  scale_fill_viridis_c(option = \"viridis\") +\n  geom_text_repel(data = Labels,\n                 inherit.aes = FALSE,\n                 aes(x = long, y = lat, label = region))",
    "crumbs": [
      "03 Descriptive Statistics"
    ]
  },
  {
    "objectID": "chapters/03-Descriptive.html#task-3-violin-plots",
    "href": "chapters/03-Descriptive.html#task-3-violin-plots",
    "title": "03 Descriptive Statistics",
    "section": "7.3 Task 3 Violin plots",
    "text": "7.3 Task 3 Violin plots\nViolin plots are a useful way of showing the distribution of scores across different items. They can make distributions easy to compare, at a glance, and to give a sense of the relative frequency of different scores. In ggplot you can use geom_violin to produce plots. For example, you can compare the distribution of science scores in Spain and Portugal by gender (note the relatively long tail at the bottom of #####):\n\n# Create a data frame of Spain and Portugal science scores including gender\nPISAsubset &lt;- PISA_2022%&gt;%\n  select(CNT, PV1SCIE, ST004D01T)%&gt;%\n  filter(CNT == \"Spain\" | CNT == \"Portugal\")\n\n# Set up the country on the x axis, and score on the y, setting colour by gender\nggplot(PISAsubset, aes(x=CNT, y=PV1SCIE, fill=ST004D01T))+\n  geom_violin()+\n  xlab(\"Country\")+\n  ylab(\"Science Score\")\n\n\n\n\n\n\n\n\nYou can rotate the plot using +coord_flip() and add black dots for the mean using: stat_summary(fun = \"mean\", geom = \"point\", color = \"black\"). You can also try geom= \"crossbar\". Because we have two groups (male and female), we need to add position = position_dodge(width=0.9) to make the dots appear in the right place\n\n# Create a data frame of country science scores including gender\n\nPISAsubset&lt;-PISA_2022%&gt;%\n  select(CNT, PV1SCIE, ST004D01T)%&gt;%\n  filter(CNT == \"United Kingdom\" | CNT == \"Ireland\" |\n         CNT == \"Qatar\" | CNT == \"Brazil\" | CNT == \"Kazakhstan\" |\n           CNT == \"Korea\" | CNT == \"Panama\")\n\n# Set up the country on the x axis, and score on the y, setting colour by gender, flip the axes and add points for the mean\n\nggplot(PISAsubset, aes(x = CNT, y = PV1SCIE, fill = ST004D01T))+\n  geom_violin()+\n  xlab(\"Country\")+\n  ylab(\"Science Score\")+\n  coord_flip()+\n  stat_summary(fun = \"mean\", geom = \"point\", color = \"black\",\n               position = position_dodge(width=0.9))\n\n\n\n\n\n\n\n\n\nPlot violin plots of PISA HOMEPOS scores, by gender, for the UK, US, Sweden and Finland.\n\n\n\nAnswer\n# Create a data frame of WEALTH scores for the 4 countries including gender\nPISAsubset&lt;-PISA_2022%&gt;%\n  select(CNT, HOMEPOS, ST004D01T)%&gt;%\n  filter(CNT == \"United Kingdom\" | CNT == \"Sweden\" | \n           CNT == \"Finland\" | CNT == \"United States\")\n\n# Set up the country on the x axis, and score on the y, setting colour by gender\nggplot(PISAsubset, aes(x=CNT, y=HOMEPOS, fill=ST004D01T))+\n  geom_violin()+\n  xlab(\"Country\")+\n  ylab(\"PISA Wealth measure\")",
    "crumbs": [
      "03 Descriptive Statistics"
    ]
  },
  {
    "objectID": "chapters/02-4-Intro_to_graphs.html",
    "href": "chapters/02-4-Intro_to_graphs.html",
    "title": "Making graphs",
    "section": "",
    "text": "The tidyverse includes the incredibly powerful ggplot2 package. This package is pretty much the industry standard for making graphs for publication. ggplot2 is built on the grammar of graphics where you build graphs by specifying underlying attributes and layering geometric objects on top of each other. In the diagram below you can see how a graph is built from geometric objects (the things that are plotted such as points and bars) a scale, and plot annotations (e.g. a key, title etc). You can then apply faceting to the graph to automatically split one graph into multiple plots, allowing you to easily compare different groupings. Publications, such as the Financial Times, make daily use of ggplot2.",
    "crumbs": [
      "02 Introduction to R",
      "Making graphs"
    ]
  },
  {
    "objectID": "chapters/02-4-Intro_to_graphs.html#sec-geom_point",
    "href": "chapters/02-4-Intro_to_graphs.html#sec-geom_point",
    "title": "Making graphs",
    "section": "2.1 geom_point",
    "text": "2.1 geom_point\nRather unsurprisingly, geom_point allows us to plot a layer of points using x and y coordinates. The below example shows how we can specify within the ggplot function data=country_plot_data. We then define the aesthetic attributes of the graph, passing the x x=NumberOfBoys and y y=NumberOfGirls values. Once these have been declared in the ggplot(...) function, their values are passed down to any subsequent geom_, in this case geom_point will use the data and x and y values that have been specified in ggplot(...)\n\n# create a new dataframe of maths and reading scores by country and OECD status\n1country_plot_data &lt;- PISA_2022 %&gt;%\n2  group_by(OECD, CNT) %&gt;%\n3  summarise(mean_maths = mean(PV1MATH),\n            mean_read = mean(PV1READ),\n            sz = n())\n\n# using this new dataframe, show the relationship between maths and reading score\n# using geom_points\n4ggplot(data=country_plot_data,\n5       aes(x=mean_maths, y=mean_read)) +\n6  geom_point(aes(size=sz, colour=OECD), alpha = 0.6)\n\n\n1\n\npipe the large data.frame PISA_2022 to apply a number of functions.\n\n2\n\ngroups by OECD (a Yes or No indicating membership) and CNT (the name of the country).\n\n3\n\ncalculate the mean mathematics and reading score, and create new variables (mean_maths, and mean_read) for their values. In addition, in line 6, the variables sz is created which counts the number of responses per country through the n() command. This whole pipe is then saved to the country_plot_data object, using the &lt;- on line 2\n\n4\n\nIn ggplot we specifiy the data that should be plotted - the new dataframe country_plot_data\n\n5\n\nWe pass the x and y variables, mean_maths, and mean_read, inside the aesthetic function. These values will be passed to any subsequent geom_\n\n6\n\nWe make a number of tweaks to the points: first setting the aesthetics - the size of the points is linked to the sz variable we created, the number of responses per country, and the colour is linked to OECD membership. Finally (and note this is outside the aes brackets, we set an alpha value which makes the point slightly transparent, which is more visually appealing where points overlap.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nDefining things inside aes mean that they will change with the dataset you use, if you define them outside aes then they will be constant values. For example\n\n# plotting number of boys as x, number of girls as y and % disadvantaged as size,\n# all inside aes, so each point is a table row\nggplot(data=PISA_2022_school) +\n  geom_point(aes(x = SC002Q01TA,\n                 y = SC002Q02TA,\n                 size=SC211Q03JA))\n\n\n\n\n\n\n\n\nHowever, there is an error if we put size outside the aes(), and set it a value from the dataset, it can’t find value:\n\nggplot(data=PISA_2022_school) +\n  geom_point(aes(x = SC002Q01TA,\n                 y = SC002Q02TA),\n             size=SC211Q03JA)  # this is now outside the aes\n\nError: object 'SC211Q03JA' not found\n\n\nbut if we set the size explicitly to 3, outside the aes(), then all points will be that size\n\nggplot(data=PISA_2022_school) +\n  geom_point(aes(x = SC002Q01TA,\n                 y = SC002Q02TA),\n             size=3)\n\n\n\n\n\n\n\n\n\n\n\n2.1.1 Questions\n\n\nSpot the three errors in this graph code\n\n\nggplot(adta=diamonds, x=depth, y=price) +\n  geom_point() %&gt;% \n  ggtitle(\"diamond graph\")\n\n\n\nanswer\n#1 data not adta; #2 x and y need to be inside aes\nggplot(data=diamonds, aes(x=depth, y=price)) +\n  geom_point() + #3 %&gt;% instead of +\n  ggtitle(\"diamond graph\")\n\n\n\nUsing the PISA_2022 dataset, plot a graph for students from Norway to look at the relationship between Home Possessions (WLE) HOMEPOS and reading grade PV1READ. Colour each point with the gender ST004D01T of the student. Give the graph sensible x and y labels by using xlab(\"label\") and ylab(\"label\")\n\n\n\nanswer dataframe\ngraph_data &lt;- PISA_2022 %&gt;% filter(CNT == \"Norway\")\n\n\n\n\nanswer graph\nggplot(graph_data,\n       aes(x=HOMEPOS,\n           y=PV1READ)) +\n  geom_point(aes(colour=ST004D01T)) +\n  xlab(\"Home possessions\") +\n  ylab(\"Reading grade\")\n\n\n\nUsing the PISA_2022 dataset for each country CNT, create a graph to explore how the median of the sense of school belonging BELONG relates to the median of the disciplinary climate in mathematics DISCLIM, adjust the colour of each point to reflect the mean of students in each country ESCS.\n\nHINT: You’ll need create a new data frame with summarised variables for median_belong, median_discipline and mean_wealth.\n\n\nanswer dataframe\ngraph_data &lt;- PISA_2022 %&gt;%\n  group_by(OECD, CNT) %&gt;%\n  summarise(median_belong = median(BELONG, na.rm=TRUE),\n            median_discipline = median(DISCLIM, na.rm=TRUE),\n            mean_wealth = mean(ESCS, na.rm=TRUE))\n\n\nHINT: To make your colours stand out more, add + scale_color_gradientn(colours = rainbow(3)) to the end of your plot.\n\n\nanswer graph\n# display a graph of the results\nggplot(data = graph_data, \n       aes(x = median_belong, \n           y = median_discipline)) +\n  geom_point(aes(colour = mean_wealth)) + \n  scale_color_gradientn(colours = rainbow(3))",
    "crumbs": [
      "02 Introduction to R",
      "Making graphs"
    ]
  },
  {
    "objectID": "chapters/02-4-Intro_to_graphs.html#sec-geom_bar",
    "href": "chapters/02-4-Intro_to_graphs.html#sec-geom_bar",
    "title": "Making graphs",
    "section": "2.2 geom_bar",
    "text": "2.2 geom_bar\nThe geom_bar function is versatile, allowing the creation of bar, multiple bar, stacked bar charts and histograms. This first example shows how we can use bar charts to represent the number of cars in a household ST251Q01JA:\n\n1plot_cars &lt;- PISA_2022 %&gt;% filter(!is.na(ST251Q01JA))\n\n2ggplot(data = plot_cars,\n3       aes(x=ST251Q01JA)) +\n4  geom_bar()\n\n\n1\n\nget the PISA_2022 dataset and remove all rows where ST251Q01JA is NA, storing this new dataset as plot_cars\n\n2\n\npass the plot_cars to ggplot, as the dataset we are going to plot\n\n3\n\nspecify the x values to be the values stored in ST251Q01JA, i.e. we will have a bar for each response given in ST251Q01JA: None, One, Two, Three or more.\n\n4\n\ngeom_bar tell ggplot to make bars, it uses the aesthetic from line 5, to plot the x axis, note we haven’t given it a y value, this is auto-calculated from the number of students in each x group.\n\n\n\n\n\n\n\n\n\n\n\nWe can choose to let ggplot split the results into different groups for us by setting a fill option, in this case on the OECD status of the country, i.e. do students in OECD countries have more cars than those not in OECD countries, to do this, we add fill=OECD to the aes on line 2 below:\n\nggplot(data = plot_cars, \n       aes(x=ST251Q01JA, fill=OECD)) + \n  geom_bar()\n\n\n\n\n\n\n\n\nThe bars are now coloured with a key, but, annoyingly, the bars are on top of each other which makes it hard to make direct comparisons. To compare different groups we need the bars to not be stacked, we want them next to each other, or in ggplot language, we want the bars to dodge each other, to do this we add the position=position_dodge() command to line 3 below:\n\n\n\n\n\n\n\n\n\n\n2.2.1 Raising the bars yourself\nggplot can do a lot of the hard work when putting together bar charts, e.g. counting the number of students in each group, but there might also be times when you want to use pipes to calculate summary values that you then want plot. That is, you want to specify the heights of the bars yourself. To do this we will specify the y axis in the aes and use stat=\"indentity\" to tell ggplot that’s what we’re doing. Take the example where you want to find the overall percentage of students for a range of countries getting over 500 in PV1SCIE:\n\n1plot_data &lt;- PISA_2022 %&gt;%\n  group_by(OECD, CNT) %&gt;%\n  summarise(all_students = n(),\n            upper_sci_per = sum(PV1SCIE &gt; 500) / n())\n\n2ggplot(data=plot_data,\n       aes(x=CNT, y=upper_sci_per)) +\n3  geom_bar(aes(fill=OECD),\n4           position=position_dodge(),\n5           stat=\"identity\") +\n6  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))\n\n\n1\n\ncreates a dataframe plot_data that calculates the percentage of students in each country CNT, that have a science grade PV1SCIE over 500\n\n2\n\nas we are setting the heights of the bars ourselves, we need to give the ggplot aes command a y value, in this case y=upper_sci_per\n\n3\n\nthe geom_bar is given a fill value of OECD, this will allow us to see how countries in and out of the OECD compare\n\n4\n\nwe use position=position_dodge() as we want the percentage grades of each country to be next to each other so we can look for differences in heights\n\n5\n\nstat=\"identity\" tells geom_bar that you have defined your own bar heights in the y attribute and not to count the number of rows.\n\n6\n\nthe theme command helps rotate the x-axis labels 90 degrees, so they don’t overlap.\n\n\n\n\n\n\n\n\n\n\n\nAlternatively, you can use the geom_col() function that can handle you setting the y values and not specifying stat=\"identity\"\n\nggplot(data=plot_data, \n       aes(x=CNT, y=upper_sci_per)) +\n  geom_col(aes(fill=OECD), \n           position=position_dodge()) +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))\n\n\n\n2.2.2 Questions\n\n\nCan you spot the 4 errors in this code.\n\n\nggplot(data=schools %&gt;% filter(Phase == \"Secondary\"), \n       x=Region +\n  geom_bar(aes(fill=Gender) position=\"full\") \n\n\n\nanswer\nggplot(data=schools %&gt;% filter(Phase == \"Secondary\"), \n       aes(x=Region)) + # 1 no aes() around the x value # 2 missing close brackets\n  geom_bar(aes(fill=Gender), position=\"fill\") # 3 missing comma # 4 position=\"full\" rather than fill \n\n\n\nCreate a bar chart showing the total number of students for each grouping of “How satisfied are you with each of the following: The way that you look” WB155Q02HA. Adjust this graph to see if there is a difference for this among females and males:\n\n\n\nanswer\nggplot(data=PISA_2022,\n       aes(x=WB155Q02HA)) +\n  geom_bar() +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))\n\n\n\n\nanswer with gender added\nggplot(data=PISA_2022 %&gt;% filter(!is.na(WB155Q02HA)),\n       aes(x=WB155Q02HA, fill=ST004D01T)) +\n  geom_bar(position=position_dodge()) +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))\n\n\n\nPlot bars for the number of Females and Males ST004D01T who answer each grouping for: “Confident can do in future: : Finding learning resources online on my own” ST355Q03JA. Make sure that the bars position_dodge() each other so we can compare the heights.\n\n\n\nanswer\ngraph_data &lt;- PISA_2022 %&gt;% filter(!is.na(ST355Q03JA))\n\n  ggplot(data=graph_data,\n       aes(x=ST355Q03JA, fill=ST004D01T)) +\n  geom_bar(position=position_dodge()) +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))\n\n\n\nFor France and the United Kingdom, plot the total number of students who gave each answer for ST324Q11JA “Agree/disagree: School has been a waste of time.”. Filter out all the NA values first !is.na(...)\n\n\n\nanswer dataframe\nplot_data &lt;- PISA_2022 %&gt;% \n  filter(CNT %in% c(\"France\", \"United Kingdom\"),\n         !is.na(ST324Q11JA))\n\n\n\n\nanswer\nggplot(plot_data,\n       aes(x=ST324Q11JA, fill=CNT)) +\n  geom_bar(position=position_dodge()) +\n  theme(legend.position = \"bottom\")\n\n\n\nUsing the PISA_2022_school dataset (available here create a table that stores for each country CNT\n\n\nthe total number of full-time teacher, SC018Q01TA01\nthe total number of full-time teachers with a bachelors qualification SC018Q08JA01\nthe total number of full-time teachers with a master’s qualification SC018Q01TA01\nthe total number of full-time teachers with a doctoral qualification SC018Q10JA01\n\nAdd an additional column working out the % of teachers with master’s in each country, call this per_MA\n\n\ncreating the dataframe\nplot_workforce &lt;- PISA_2022_school %&gt;% \n  group_by(CNT) %&gt;% \n  summarise(schools = n(),\n            total = sum(SC018Q01TA01, na.rm=TRUE),\n            BA =    sum(SC018Q08JA01, na.rm=TRUE),\n            PHD =   SC018Q10JA01 %&gt;% sum(na.rm=TRUE),\n            MA =    SC018Q09JA01 %&gt;% sum(na.rm=TRUE),\n            per_MA = MA *100 / total)\n\n\nUsing this dataframe plot a bar graph for each country of the per_MA, use the number of schools as a fill:\n\n\ncreating the graph\nggplot(data=plot_workforce,\n       aes(x=CNT, y=per_MA, fill=schools)) +\n  geom_bar(stat=\"identity\") +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +\n  theme(legend.position=\"top\")\n\n\n\n[Extension] Explore other patterns in the school and student Pisa datasets.",
    "crumbs": [
      "02 Introduction to R",
      "Making graphs"
    ]
  },
  {
    "objectID": "chapters/02-4-Intro_to_graphs.html#geom_text",
    "href": "chapters/02-4-Intro_to_graphs.html#geom_text",
    "title": "Making graphs",
    "section": "2.3 geom_text",
    "text": "2.3 geom_text\nOur bar charts look great, but finding the actual value of each bar can be a little clumsy if we have to get a ruler out and read off the y-axis. Better would be for us to have numbers listed at the top of each bar by adding a geom_text element:\n\nplot_cars &lt;- PISA_2022 %&gt;% filter(!is.na(ST251Q01JA))\n\nggplot(data = plot_cars, \n       aes(x=ST251Q01JA, fill=OECD)) + \n  geom_bar(position=position_dodge()) + \n1  geom_text(stat='count',\n2            aes(label=after_stat(count)),\n3            position = position_dodge(width=0.9),\n4            vjust=-0.5)\n\n\n1\n\nline 6 starts the geom_text command, telling the geom to use the count statistic from ggplot, this means it will be able to fetch the number of rows in each grouping.\n\n2\n\nas we want the label to change for each bar element, we put label=after_stat(count) inside aes. The x location of the labels is inherited from line 4 and the y location will be calculated from the height of each bar\n\n3\n\nwe want the labels to align to the bars, so we tell the geom_text to also position_dodge, passing a width=0.9 to the dodge function, so the labels line up above the columns,\n\n4\n\nfinally, on line 9, we vertically adjust the labels vjust, so they sit on top of the columns.\n\n\n\n\n\n\n\n\n\n\n\nRather than adding the count, you might want to add the percentage that each bar represents, we can do this by changing the value given to label on line 5, below:\n\nggplot(data = plot_cars, \n       aes(x=ST251Q01JA, fill=OECD)) + \n  geom_bar(position=position_dodge()) +\n  geom_text(stat='count', \n            aes(label=100*(after_stat(count)/sum(after_stat(count))) %&gt;% round(3), \n            group = OECD), \n            position = position_dodge(width=0.9),\n            vjust=-0.5)\n\n\n\n\n\n\n\n\nAdditionally, when we make graphs we often want to label the dataset, for example if we were to plot all the countries and their PV1MATH and PV1READ scores, we would get:\n\nplot_data &lt;- PISA_2022 %&gt;%\n  group_by(OECD, CNT) %&gt;%\n  summarise(m_read  = mean(PV1READ, na.rm=\"TRUE\"),\n            m_maths = mean(PV1MATH, na.rm=\"TRUE\"))\n\nggplot(data=plot_data, \n       aes(x=m_read, y=m_maths, colour=OECD)) +\n  geom_point() \n\n\n\n\n\n\n\n\nThis looks great, but we don’t actually know which countries are which. To get this data we need to add text to the graph, using geom_text.\n\nggplot(data=plot_data, \n       aes(x=m_read, y=m_maths, colour=OECD)) +\n  geom_point() +\n  geom_text(aes(label=CNT), \n            colour=\"black\", \n            check_overlap = TRUE)\n\n\n\n\n\n\n\n\nHere we have used colour=\"black\" outside the aes to define the colour for all the labels, and check_overlap = TRUE which removes any labels that are on top of each other. It’s still a little bit hard to understand, and maybe we want to focus on just a few of the labels for countries we are interested in. For example\n\n# make a vector of countries you want to have labels for\nfocus_cnt &lt;- c(\"United Kingdom\", \"France\", \"Argentina\")\n\n# add a new column to the plot_data where these countries are\nplot_data &lt;- plot_data %&gt;% mutate(focus = CNT %in% focus_cnt)\n\nplot_data\n\n# A tibble: 80 × 5\n# Groups:   OECD [2]\n   OECD  CNT                  m_read m_maths focus\n   &lt;fct&gt; &lt;fct&gt;                 &lt;dbl&gt;   &lt;dbl&gt; &lt;lgl&gt;\n 1 No    Albania                359.    368. FALSE\n 2 No    United Arab Emirates   420.    434. FALSE\n 3 No    Argentina              413.    389. TRUE \n 4 No    Bulgaria               405.    418. FALSE\n 5 No    Brazil                 415.    380. FALSE\n 6 No    Brunei Darussalam      428.    440. FALSE\n 7 No    Dominican Republic     354.    340. FALSE\n 8 No    Georgia                374.    390. FALSE\n 9 No    Guatemala              377.    346. FALSE\n10 No    Hong Kong (China)      504.    545. FALSE\n# ℹ 70 more rows\n\n\nNow we can adjust out geom_text to only show those countries that we want to focus on:\n\nggplot(data=plot_data, \n       aes(x=m_read, y=m_maths, colour=OECD)) +\n  geom_point() +\n1  geom_text(data=plot_data %&gt;% filter(focus == TRUE),\n            aes(label=CNT), \n            colour=\"black\", \n            check_overlap = TRUE)\n\n\n1\n\nchanges the data that is being passed to the geom_text, it no longer uses the data defined in the ggplot command, but has a new dataset, that is filtered on focus == TRUE, i.e. only containing the countries that we want.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\ngeom_text is great, but you might find that ggrepel package useful as it’ll add lines connecting the text the data points. Using the plot_data from above:\n\nlibrary(ggrepel)\n\nggplot(data=plot_data, \n       aes(x=m_read, y=m_maths, colour=OECD)) +\n  geom_point() +\n  geom_text_repel(data=plot_data %&gt;% filter(focus == TRUE),\n            aes(label=CNT),\n            box.padding = 0.5,\n            max.overlaps = Inf,\n            colour=\"black\")",
    "crumbs": [
      "02 Introduction to R",
      "Making graphs"
    ]
  },
  {
    "objectID": "chapters/02-4-Intro_to_graphs.html#exporting-plots",
    "href": "chapters/02-4-Intro_to_graphs.html#exporting-plots",
    "title": "Making graphs",
    "section": "3.1 Exporting plots",
    "text": "3.1 Exporting plots\nggplot can export data in a variety of formats suitable for printing, publication and the web. Once you have created a graph and stored it in an object my_graph &lt;- ggplot(..., the command to save the graph to your hard drive is:\nggsave(&lt;file_location_name_and_extension&gt;, &lt;object_name&gt;, width = 5, height = 4, device=&lt;file_ext&gt;)\n\nggsave(\"my_graph.pdf\", my_graph, width = 5, height = 4, device=\"pdf\")\n\nIf you want to change the output format, just change the extension of the file you are saving:\n\n“poverty_size.pdf” perfect for publication and printing, potentially large file size\n“poverty_size.svg” the same as pdf, also suitable for putting on webpages\n“poverty_size.png” smaller file size, suitable for websites and presentations\n“poverty_size.jpg” similar output to png",
    "crumbs": [
      "02 Introduction to R",
      "Making graphs"
    ]
  },
  {
    "objectID": "chapters/02-4-Intro_to_graphs.html#using-r-to-do-descriptive-statistics-and-plot-graphs",
    "href": "chapters/02-4-Intro_to_graphs.html#using-r-to-do-descriptive-statistics-and-plot-graphs",
    "title": "Making graphs",
    "section": "4.1 Using R to do descriptive statistics and plot graphs",
    "text": "4.1 Using R to do descriptive statistics and plot graphs\n\n\nYou can find the code used in the video below:\n\n\nShow the code\n# Introduction to plotting graphs\n#\n# Download data from /Users/k1765032/Library/CloudStorage/GoogleDrive-richardandrewbrock@gmail.com/.shortcut-targets-by-id/1c3CkaEBOICzepArDfjQUP34W2BYhFjM4/PISR/Data/PISA/subset/Students_2022_RBDP_none_levels.rds\n# You want the file: Students_2022_RBDP_none_levels.rds\n# and place in your own file system\n# change loc to load the data directly. Loading into R might take a few minutes\nlibrary(tidyverse)\nloc &lt;- \"/Users/k1765032/Library/CloudStorage/GoogleDrive-richardandrewbrock@gmail.com/.shortcut-targets-by-id/1c3CkaEBOICzepArDfjQUP34W2BYhFjM4/PISR/Data/PISA/subset/Students_2022_RBDP_none_levels.rds\"\nPISA_2022 &lt;- read_rds(loc)\n\n# Calculating means of groups\n# The PISA_2022 dataframe is piped to a new dataframe MeanPISA\n# The data are grouped by the country variable (CNT)\n# The countries of interest are chosen (UK, France, Germany and the US)\n# The summarise function is used to output the mean and standard deviation score for each country\n# on the Science Plausible Value (PV1SCIE) and NAs are ignored na.rm=TRUE\n\nMeanPISA &lt;- PISA_2022 %&gt;%\n  group_by(CNT)  %&gt;%\n  filter(CNT==\"United Kingdom\" | CNT== \"France\" | CNT== \"Germany\" | CNT==\"United States\")  %&gt;%\n  summarise(mean_sci = mean(PV1SCIE, na.rm=TRUE), sd_sci= sd(PV1SCIE, na.rm=TRUE)) \nprint(MeanPISA)\n\n\n# To plot data we can use the ggplot function. \n# We will start by plotting a column graph use geom_col\n# We specify the data set for ggplot to use (MeanPisa) and then \n# define the x and y variables:\n# ggplot(MeanPISA,\n#       aes(x=CNT, y=mean_sci))\n# geom_col() (Note the plus is on the line before) plots the graph and the fill colour is set to red\n# The next three lines set the formatting of the axis text and add x and y axis labels\n\nggplot(MeanPISA,\n       aes(x=CNT, y=mean_sci))+\ngeom_col(fill=\"red\") +\n  theme(axis.text.x = element_text(angle = 90, hjust=0.95, vjust=0.2, size=10)) +\n  xlab(\"Country\") +\n  ylab(\"Science Score\")\n\n# For plotting a scatter plot or PISA reading scores against science scores\n#, first we make a managable data set\n# I will filter the data set to include only the UK data\n# and remove any NAs\n\nUKData &lt;- PISA_2022 %&gt;%\n  filter(CNT==\"United Kingdom\") %&gt;%\n  drop_na(PV1SCIE)\n\n# This time I will use ggplot to plot a scatter graph\n# I feed UKDATA to ggplot, specify the x (PISA Reading score)\n# And y (PISA science score). This time, I have linked the colour\n# to a variable (ST004D01T) which is the gender value, giving\n# plot points of different colours for boys and girls\n# To produce a scatter plot, I use geom_point to plot points,\n# Giving the size of point and the transparency (alpha=0.5) -\n# some transparency of points is helpful when plots become dense\n# The x and y lables are added\n# Finally, a line is plotted - geom_smooth(method='lm')\n# sets the line to a linear ('lm') line\n\n  ggplot(UKData,\n       aes(x=PV1READ, y=PV1SCIE, colour=ST004D01T)) +\n  geom_point(size=0.1, alpha=0.5) +\n  ylab(\"Science Score\") +\n  xlab(\"Reading Score\") +\n  geom_smooth(method='lm')\n  \n# Where R becomes very powerful is being able to produce multiple charts rapidly\n# In the code below, I plot reading against science scores as above, but this time\n# Use the entire data set - for the whole world!\n# All the steps are the same, except, I use the facet_wrap, a way to create multiple\n# graph panels - the instruction creates a set of graphs for each country  \n  \n  WorldData &lt;- PISA_2022 %&gt;%\n    drop_na(PV1SCIE)\n  \n  ggplot(WorldData,\n         aes(x=PV1READ, y=PV1SCIE, colour=ST004D01T)) +\n    geom_point(size=0.1, alpha=0.5) +\n    ylab(\"Science Score\") +\n    xlab(\"Reading Score\") +\n    geom_smooth(method='lm') +\n    facet_wrap(CNT~.)",
    "crumbs": [
      "02 Introduction to R",
      "Making graphs"
    ]
  },
  {
    "objectID": "chapters/06-T-testsPISA.html",
    "href": "chapters/06-T-testsPISA.html",
    "title": "06 T-tests",
    "section": "",
    "text": "Before the session, you might if find it helpful to read chapter 7, introduction to t-tests, in Geher and Hall (2014) available here.",
    "crumbs": [
      "06 T-tests"
    ]
  },
  {
    "objectID": "chapters/06-T-testsPISA.html#pre-reading",
    "href": "chapters/06-T-testsPISA.html#pre-reading",
    "title": "06 T-tests",
    "section": "",
    "text": "Before the session, you might if find it helpful to read chapter 7, introduction to t-tests, in Geher and Hall (2014) available here.",
    "crumbs": [
      "06 T-tests"
    ]
  },
  {
    "objectID": "chapters/06-T-testsPISA.html#conditions-of-t-tests",
    "href": "chapters/06-T-testsPISA.html#conditions-of-t-tests",
    "title": "06 T-tests",
    "section": "2.1 Conditions of t-tests",
    "text": "2.1 Conditions of t-tests\nThere are six conditions required for a t-test to be used:\n\nthe population data is continuous;\nthe sample size is small;\nthe sample was randomly sampled;\nthe variance of the data in each group is similar (homogeneity of variance);\nthe population data follows a normally distribution;\nthe observations are independent of one another.\n\n\n\n\n\n\n\nNote\n\n\n\nDue to the robustness of the t-test some of the conditions can be adjusted. For example,\n\nDiscrete interval data can be used (so long as there is sufficient granularity);\nThe sample data may be approximately normally distributed;\nVariances can be unequal (this is covered by Welch’s t-test);\nSample sizes can be large (this does not affect the validity of the test, but with a known population variance a z-test may be more appropriate).\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nA rule of thumb researchers use is that if the ratio of variances of the larger sample to the smaller is less than 4, then a t-test can be used.",
    "crumbs": [
      "06 T-tests"
    ]
  },
  {
    "objectID": "chapters/06-T-testsPISA.html#hypothesis-testing-and-t-tests",
    "href": "chapters/06-T-testsPISA.html#hypothesis-testing-and-t-tests",
    "title": "06 T-tests",
    "section": "2.2 Hypothesis Testing and t-tests",
    "text": "2.2 Hypothesis Testing and t-tests\nWhen using the t-test, we are testing the null hypothesis that there is no difference between the mean of a sample and, depending on the type of t-test, either the hypothesised value of the population mean or the mean of another sample. In other words, if it is equal.\n\n\nshow the code\n# Create random data sets of 10,000 boys' and girls' scores\ngirlscores &lt;- as.data.frame(rnorm(n = 10000, mean = 100, sd = 10))\n\ngirlscores &lt;- girlscores %&gt;%\n  mutate(gender=\"female\") %&gt;%\n  rename(Scores=\"rnorm(n = 10000, mean = 100, sd = 10)\")\n\nboysscores &lt;- as.data.frame(rnorm(n = 10000, mean = 105, sd = 10))\n\nboysscores &lt;- boysscores %&gt;%\n  mutate(gender=\"male\") %&gt;%\n  rename(Scores=\"rnorm(n = 10000, mean = 105, sd = 10)\")\n\n# Plot the data\ntotalscores &lt;- rbind(boysscores, girlscores)\n\nggplot(totalscores) +\n  geom_histogram(data = boysscores,\n                 aes(x = Scores, fill = gender, alpha=0.5), binwidth = 1) +\n  geom_histogram(data=girlscores,\n                 aes(x = Scores, fill = gender, alpha=0.5), binwidth = 1) +\n  geom_vline(xintercept = mean(boysscores$Scores), colour=\"turquoise4\", \n             linetype = 3) + # Add a vertical line for the mean scores\n  geom_vline(xintercept = mean(girlscores$Scores), colour=\"red2\", linetype=3) +\n  geom_segment(aes(x = mean(boysscores$Scores), y=440, # Add arrow between means\n                   xend = mean(girlscores$Scores),\n                   yend = 440), \n               arrow = arrow(length = unit(0.01, \"npc\"), ends = \"both\")) +\n  geom_text(x = 125, y = 440, label = \"Difference in means\") + # Add text label\n  xlab(\"score\") +\n  ylab(\"Numer of students\") +\n  guides(alpha=\"none\") # Remove alpha from the legend\n\n\n\n\n\n\n\n\n\nThe alternative hypothesis then depends on whether we are testing if the mean of a sample is less than, greater than, or not equal to the hypothesised value of the population mean or mean of another sample. In other words, if it less than or greater than, then it’s a one-tailed test (since it is only considering one direction of the mean), and if it’s not equal to, then it’s a two-tailed test (since it is considering both sides of the mean).\n\n\nCode\nlibrary(gridExtra) # for grid.arrange\n\nplot1 &lt;- data.frame(y = rnorm(n = 1000, mean = 100, sd = 10), group = \"A\")\nplot2 &lt;- data.frame(y = rnorm(n = 1000, mean = 130, sd = 10), group = \"B\")\nplot3 &lt;- data.frame(y = rnorm(n = 1000, mean = 70,  sd = 10), group = \"C\")\nplot4 &lt;- data.frame(y = rnorm(n = 1000, mean = 100, sd = 10), group = \"D\")\nplot5 &lt;- plot3\n\nplot5$group&lt;-\"E\"\nplot5$y &lt;- plot5$y + 60\nonetail &lt;- rbind(plot1, plot2)\ntwotail &lt;- rbind(plot3, plot4, plot5)\n\np1&lt;-ggplot(onetail, aes(x = y, fill = group)) +\n  geom_density(alpha = 0.5) +\n  geom_segment(aes(x = mean(plot1$y), y = 0.045, # Add an arrow between means\n                   xend = mean(plot2$y),\n                   yend = 0.045), \n               arrow = arrow(length = unit(0.01, \"npc\"), ends = \"both\"))+\n  geom_vline(xintercept = mean(plot1$y), linetype=\"dashed\")+\n  geom_vline(xintercept = mean(plot2$y), linetype=\"dashed\")+\n  ggtitle(\"One tailed tests look for differences in one direction\")\n\np2 &lt;- ggplot(twotail, aes(x = y, fill = group)) +\n  geom_density(alpha = 0.5) +\n  geom_segment(aes(x = mean(plot3$y), y = 0.043, # Add an arrow between means\n                   xend = mean(plot4$y),\n                   yend = 0.043), \n               arrow = arrow(length = unit(0.01, \"npc\"), ends = \"both\")) +\n  geom_segment(aes(x = mean(plot4$y), y=0.045, # Add an arrow between means\n                   xend = mean(plot5$y),\n                   yend = 0.045), \n               arrow = arrow(length = unit(0.01, \"npc\"), ends = \"both\"))+\n  geom_vline(xintercept = mean(plot3$y), linetype=\"dashed\")+\n  geom_vline(xintercept = mean(plot4$y), linetype=\"dashed\")+\n  geom_vline(xintercept = mean(plot5$y), linetype=\"dashed\")+\n  ggtitle(\"Two tailed tests look for differences in two directions\")\n\ngrid.arrange(p1, p2)\n\n\n\n\n\n\n\n\n\nTo determine the outcome of the t-test we need to decide a sufficiently low enough probability (p-value) that, if it’s below this, then it is unlikely that the null hypothesis is true and so we reject the null hypothesis. Typically, this is set to 0.05, or 5%, but in other cases it might be as high as 0.1 or as low as 0.01 or 0.001 depending on the circumstances. Therefore, if the p-value is greater than 0.05 we accept the null hypothesis and if it less than 0.05 we reject the null hypothesis and accept the alternative hypothesis.\nWhen considering the number of tails, we then need to consider the p-value here also. If we set the overall probability to be 0.05 for the threshold that we reject the null hypothesis, then for a one-tailed test we compare our result with 0.05. However, with a two-tailed test, since we are looking at a two-tailed test, then the probability of each of the tails is 0.025 and therefore we compare our value with 0.025 instead.\nConventionally, we use 0.05 (1 in 20) as the cut off for statistical significance (a convention that has been much critiqued e.g. (Jacob Cohen 1994; Baker 2016)).",
    "crumbs": [
      "06 T-tests"
    ]
  },
  {
    "objectID": "chapters/06-T-testsPISA.html#types-of-t-test",
    "href": "chapters/06-T-testsPISA.html#types-of-t-test",
    "title": "06 T-tests",
    "section": "2.3 Types of t-test",
    "text": "2.3 Types of t-test\nThere are a two main types of t-tests:\n\nOne sample t-test - checks if the mean of a sample is different to a hypothesised value for the population mean.\nTwo sample t-test - checks if the mean of one sample is different to the mean of another sample. There are two main types:\nPaired tests - compares the means of measurements from the same individual or object (e.g. in a pre- and post-test - the comparison of means and before and after scores compares the same student’s scores in the first test with the second).\nUnpaired t-tests - compares the means of two unrelated groups (for example, are the mean science scores of boys and girls in a school different).\n\nFor more information on t-tests, see chapter 13, in Navaro’s Learning Statistics with R.",
    "crumbs": [
      "06 T-tests"
    ]
  },
  {
    "objectID": "chapters/06-T-testsPISA.html#one-sample-t-tests",
    "href": "chapters/06-T-testsPISA.html#one-sample-t-tests",
    "title": "06 T-tests",
    "section": "2.4 One Sample t-tests",
    "text": "2.4 One Sample t-tests\nOne sample t-tests are used to compare the mean of a sample of a data set with a value. This value is usually a known population mean or a theoretical population mean depending on the context of the test.\nFor a two-tailed test, the hypotheses are as follows\n\nNull hypothesis: sample mean = population mean;\nAlternative hypothesis: sample mean ≠ population mean.\n\nFor a one-tailed test, the hypotheses are as follows (depending on the direction of the test)\nEither,\n\nNull hypothesis: sample mean = population mean;\nAlternative hypothesis: sample mean &gt; population mean.\n\nOr,\n\nNull hypothesis: sample mean = population mean;\nAlternative hypothesis: sample mean &lt; population mean.\n\nExample: Are Females’ Reading Scores in the UK the Same or Different on Average to the UK Average?\nLet’s look at an example of where we might want to consider a sample, in this case females’ reading scores in the UK, with a presumed population mean, the average reading score in the UK. This is a presumed mean, since we don’t know the true population mean here, but we do know the average reading score from the PISA data, which is 494 (taken from PISA 2022).\nFollowing the steps for performing a hypothesis test, we will start by selecting the appropriate test. Since we are comparing the mean of one sample with a population mean, then we need to use a one sample t-test.\nFirst, you will need to load the PISA data:\n\n# Load PISA Data\nPISA_2022 &lt;- read_parquet(r\"[add the link to your data file]\")\n\nTo ensure we can use this test we need to make sure the conditions are met. Since PISA tests are constructed in a way which means they are normally distributed, then it is likely our sample is also normally distributed. However, it is good practice to check the distribution using a histogram (or qqplot) at the very least, and where appropriate, a normality test. Due to the large sample size normality testing isn’t usually required, so we will just consider a histogram (or qqplot) here.\n\n# Define PISA UK Girls Dataset\nPISA_2022_Read_Girls &lt;- PISA_2022 %&gt;%\n2  select(CNT, PV1READ, ST004D01T) %&gt;%\n3  filter(CNT == \"United Kingdom\" & ST004D01T == \"Female\")\n\n# Plot histogram\n4ggplot(data = PISA_2022_Read_Girls,\n5       aes(x = PV1READ)) +\n6  geom_histogram(binwidth = 5, fill = \"darkseagreen4\")\n\n\n2\n\nselect the variables of interest\n\n3\n\nfilter for the UK and for girls\n\n4\n\npass the data to ggplot\n\n5\n\nput reading scores (PV1READ) on the x-axis\n\n6\n\nuse geom_histogram to create a histogram. We can define that the reading data is divided into bins of width 5 points (binwidth = 5) and set the colour of the bars (fill = \"darkseagreen4\")\n\n\n\n\n\n\n\n\n\n\n\nWe can see from the histogram that the sample is approximately normally distributed (as it follows a bell shaped curve).\nNext, we state the null and alternative hypotheses. Since we are determining whether the average reading score is the same or different, we are using a two-tailed test. This gives us the following hypotheses:\n\nNull hypothesis: mean reading score for females in UK = mean reading score in UK\nAlternative hypothesis: mean reading score for females in UK ≠ mean reading score in UK\n\nHaving set up the hypotheses, we now need to calculate the probability of the null hypothesis being true. To do this, we use R’s t.test function and compare the scores for females in reading in the UK with the OECD average score for reading, which is defined as 476 (OECD website).\n\nOECD_ave_read_UK &lt;-(476)\nt.test(PISA_2022_Read_Girls$PV1READ, mu=OECD_ave_read_UK)\n\n\n    One Sample t-test\n\ndata:  PISA_2022_Read_Girls$PV1READ\nt = 19.064, df = 6396, p-value &lt; 2.2e-16\nalternative hypothesis: true mean is not equal to 476\n95 percent confidence interval:\n 497.7143 502.6918\nsample estimates:\nmean of x \n  500.203 \n\n\nWe can see from the result that we get a p-value of &lt; 2.2e-16, which is very small. As this is lower than 0.025 (for a two-tailed test) we reject the null hypothesis.\nTherefore, we accept the null hypothesis that the average reading score for females in the UK is different to the overall average reading score in the UK. Looking at the average stated in the t-test, the average score is higher for girls, at 500.23.",
    "crumbs": [
      "06 T-tests"
    ]
  },
  {
    "objectID": "chapters/06-T-testsPISA.html#unpaired-two-sample-t-tests",
    "href": "chapters/06-T-testsPISA.html#unpaired-two-sample-t-tests",
    "title": "06 T-tests",
    "section": "2.5 Unpaired Two Sample t-tests",
    "text": "2.5 Unpaired Two Sample t-tests\nUnpaired two sample t-tests are used to compare the means of two, unconnected samples. They are unconnected in the sense that the samples taken are independent and are measurements of two unrelated groups.\nFor a two-tailed test, the hypotheses are as follows\n\nNull hypothesis: sample mean of first group = sample mean of second group;\nAlternative hypothesis: sample mean of first group ≠ sample mean of second group.\n\nFor a one-tailed test, the hypotheses are as follows (depending on the direction of the test)\nEither,\n\nNull hypothesis: sample mean of first group = sample mean of second group;\nAlternative hypothesis: sample mean of first group &gt; sample mean of second group.\n\nOr,\n\nNull hypothesis: sample mean of first group = sample mean of second group;\nAlternative hypothesis: sample mean of first group &lt; sample mean of second group.\n\nExample: Are Males’ and Females’ Maths Scores in the USA the Same or Different to One Another?\nLet’s say we want to discern if the average maths score differ for males and females in the USA. We want to test to see if there is a statistical difference between the means.\nFollowing the steps for performing a hypothesis test, we will start by selecting the appropriate test. Since we are comparing the means of two, unrelated samples (since they are the measurements of two different groups that are not connected) then we use an unpaired t-test.\nAgain, we need to check if the groups are approximately normally distributed so check the histogram of each group.\n\n# Create a US maths subsets\nUSMATH &lt;- PISA_2022 %&gt;%\n2  select(CNT, PV1MATH,ST004D01T) %&gt;%\n3  filter(CNT == \"United States\")\n\nUSMATHGIRLS &lt;- USMATH %&gt;%\n4  filter(ST004D01T == \"Female\")\n\nUSMATHBOYS &lt;- USMATH %&gt;%\n6  filter(ST004D01T == \"Male\")\n# Plot histogram\n# For girls\n7ggplot(data = USMATHGIRLS,\n8       aes(x = PV1MATH)) +\n  geom_histogram(binwidth = 5, fill = \"darkseagreen4\")\n\n\n2\n\nselect the variables of interest, country, maths scores, and gender\n\n3\n\nfilter for the US\n\n4\n\ncreate a new data frame USMATHGIRLS of the data for girls\n\n6\n\npass the data to ggplot\n\n7\n\nput maths scores (PV1MATH) on the x-axis\n\n8\n\nuse geom_histogram to create a histogram. We can define that the reading data is divided into bins of width 5 points (binwidth = 5) and set the colour of the bars (fill = \"darkseagreen4\")\n\n\n\n\n\n\n\n\n\n\n# For boys\nggplot(data=USMATHBOYS,\n       aes(x=PV1MATH)) +\n  geom_histogram(binwidth = 5, fill = \"red\")\n\n\n\n\n\n\n\n\nAgain, we can see both samples of males and females are approximately normally distributed.\nNext, we state the null and alternative hypotheses. Since we are determining whether the average maths scores are the same or different, we are using a two-tailed test. This gives us the following hypotheses:\n\nNull hypothesis: mean maths score for males in US = mean maths score for females in UK\nAlternative hypothesis: mean maths score for males in US ≠ mean maths score for females in UK.\n\nNext, we calculate the probability of the null hypothesis being true. As before, we use R’s t.test function and compare the mean scores of males and females in the US.\n\n# Plot a two-sided, unpaired t-test\nt.test(PV1MATH ~ ST004D01T, data = USMATH,\n       alternative = \"two.sided\")\n\n\n    Welch Two Sample t-test\n\ndata:  PV1MATH by ST004D01T\nt = -3.9455, df = 4499.5, p-value = 8.086e-05\nalternative hypothesis: true difference in means between group Female and group Male is not equal to 0\n95 percent confidence interval:\n -16.59477  -5.57744\nsample estimates:\nmean in group Female   mean in group Male \n            456.1248             467.2109 \n\n\nWe can see from the t-test result that the p-value returned is 8.086e-05. As this is lower than 0.025 (for a two-tailed test) we reject the null hypothesis.\nAs such, we accept the alternative hypothesis that the average scores for males and females in the US are statistically different, with the average score for males being higher than average score for females.",
    "crumbs": [
      "06 T-tests"
    ]
  },
  {
    "objectID": "chapters/06-T-testsPISA.html#paired-two-sample-t-tests",
    "href": "chapters/06-T-testsPISA.html#paired-two-sample-t-tests",
    "title": "06 T-tests",
    "section": "2.6 Paired Two Sample t-tests",
    "text": "2.6 Paired Two Sample t-tests\nPaired two sample t-tests compare the mean of a sample to the mean of a related sample. Usually, this is where there is a repeated measure taken of the same individuals or objects, such as a pre and post test. It can also be used for comparing a pair of measurements taken of the same individuals or objects.\nFor a two-tailed test, the hypotheses are as follows\n\nNull hypothesis: sample mean of first group = sample mean of second group;\nAlternative hypothesis: sample mean of first group ≠ sample mean of second group.\n\nFor a one-tailed test, the hypotheses are as follows (depending on the direction of the test)\nEither,\n\nNull hypothesis: sample mean of first group = sample mean of second group;\nAlternative hypothesis: sample mean of first group &gt; sample mean of second group.\n\nOr,\n\nNull hypothesis: sample mean of first group = sample mean of second group;\nAlternative hypothesis: sample mean of first group &lt; sample mean of second group.\n\nExample: Are there differences between science and maths scores on average in the UK?\nLet’s say we want to compare the science and maths scores of students in the UK to see if there is a difference in their average score or not.\nFollowing the steps for performing a hypothesis test, we will start by selecting the appropriate test. Since we are comparing the means of two, related samples (since they are two measurements of the same students, therefore related) then we use a paired t-test.\nAgain, we need to check if the groups are approximately normally distributed so check the histogram of each group.\n\n# Create a US maths subsets\nUKMATH&lt;-PISA_2022 %&gt;%\n  select(CNT, PV1MATH,ST004D01T) %&gt;%\n  filter(CNT == \"United Kingdom\")\n\nUKSCIENCE&lt;-PISA_2022 %&gt;%\n  select(CNT, PV1SCIE, ST004D01T) %&gt;%\n  filter(CNT == \"United Kingdom\")\n\n# Plot histogram\nggplot(data = UKMATH,\n       aes(x = PV1MATH)) +\n  geom_histogram(binwidth = 5, fill = \"darkseagreen4\")\n\n\n\n\n\n\n\nggplot(data = UKSCIENCE,\n       aes(x = PV1SCIE)) +\n  geom_histogram(binwidth = 5, fill = \"red\")\n\n\n\n\n\n\n\n\nAgain, we can see the two samples are approximately distributed so can use the t-test.\nNext, we state the null and alternative hypotheses. Since we are determining whether the average maths score is the same or different to the average science score, we are using a two-tailed test. This gives us the following hypotheses:\n\nNull hypothesis: mean maths score in UK = mean science score in UK\nAlternative hypothesis: mean maths score in UK ≠ mean science score in UK\n\nHaving set up the hypotheses, we now need to calculate the probability of the null hypothesis being true. Again, we use R’s t.test function and compare the average maths scores with the average science scores.\n\n# Perform a two-sided, paired t-test\nt.test(UKMATH$PV1MATH, UKSCIENCE$PV1SCIE, \n       paired = TRUE, alternative = \"two.sided\")\n\n\n    Paired t-test\n\ndata:  UKMATH$PV1MATH and UKSCIENCE$PV1SCIE\nt = -21.651, df = 12971, p-value &lt; 2.2e-16\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n -10.602602  -8.842174\nsample estimates:\nmean difference \n      -9.722388 \n\n\nWe return a p-value of &lt; 2.2e-16, which is less than 0.025 (for a two-tailed test), meaning we reject the null hypothesis that there is no difference between the average score in maths and science.\nTherefore, we accept the alternative hypothesis that there is a difference in scores in maths and science in the UK. This difference is approximately 1.5 points.\n\n\n\n\n\n\nTip\n\n\n\nIn R, there are often multiple ways of doing the same tests. Note with t.test there are two forms you can use, depending on the format of the data you want to test.\nFirst, in the example above, we had two data frames, for math scores, and science scores, so we can pass two data frames to t.test.\n\n# Carry out a two-sided, paired t-test\nt.test(UKMATH$PV1MATH, UKSCIENCE$PV1SCIE, \n       paired = TRUE, alternative = \"two.sided\")\n\n\n    Paired t-test\n\ndata:  UKMATH$PV1MATH and UKSCIENCE$PV1SCIE\nt = -21.651, df = 12971, p-value &lt; 2.2e-16\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n -10.602602  -8.842174\nsample estimates:\nmean difference \n      -9.722388 \n\n\nAlternatively, our data might be in one data frame, with a variable indicating the two groups. For example, if we wanted to perform a test of UK science scores, we might create a single data frame in which the two groups are indicated by the column ST004D01T, gender. In that case, we can use the ~ operator to do a t.test on the PISAUK$PV1SCIE (i.e. the science scores) by (~) gender.\n\nUKSci&lt;-PISA_2022 %&gt;%\n  select(CNT, PV1SCIE, ST004D01T) %&gt;%\n  filter(CNT==\"United Kingdom\")\n\n# Plot a two-sided, unpaired t-test\nt.test(UKSci$PV1SCIE ~ ST004D01T, data = UKSci,\n       alternative = \"two.sided\")\n\n\n    Welch Two Sample t-test\n\ndata:  UKSci$PV1SCIE by ST004D01T\nt = -3.9298, df = 12964, p-value = 8.547e-05\nalternative hypothesis: true difference in means between group Female and group Male is not equal to 0\n95 percent confidence interval:\n -10.553500  -3.529142\nsample estimates:\nmean in group Female   mean in group Male \n            488.6962             495.7375",
    "crumbs": [
      "06 T-tests"
    ]
  },
  {
    "objectID": "chapters/06-T-testsPISA.html#eta-squared",
    "href": "chapters/06-T-testsPISA.html#eta-squared",
    "title": "06 T-tests",
    "section": "3.1 Eta-squared",
    "text": "3.1 Eta-squared\nIf we have found out, from an anova that there are significant differences between the two groups, we can next determine how much variation is explained by each group To do this we calculate a variable called eta-squared.\nEta-squared gives the proportion of variance explained by each variable. The eta squared function is in the package lsr so we will install lsr, and then use the result of our anova (resaov) to calculate the eta squared variable using the function etaSquared. To report the value of eta as a percentage we need to multiply the output of eta by 100.\nEta squared tells us the proportion of the total variance that is explained by a variable (you can also think of it as an effect size). An eta squared value of 1 indicates all the variance of a sample is explain by some variable and 0 means the variable is not responsible for any of the observed variance. We can multiply the eta-squared score by 100 to get a value for the percentage of variance explained.\nThe percentage of variance explained is a useful figure. For example, it has been reported that schools only account for 14% of the variance in progress 8 scores, whilst family explains 43% (Wilkinson, Bryson, and Stokes (2018)).\n\nlibrary(lsr)\neta &lt;- as.data.frame(etaSquared(resaov))\neta &lt;- eta*100\neta\n\n      eta.sq eta.sq.part\nCNT 28.45522    28.45522\n\n\nThe important column here is the eta.sq column - it tells us that the country explains 28% of the variance in test scores. (The second column contains information about partial eta-squared, which we won’t go into, but are used when the results of each measure are not independent i.e. one result influences another).\n\n\n\n\n\n\nNote\n\n\n\nInterpretations of effect size vary. In some fields, 2% - 13% is read as small, 13% -26% medium and over 26% large (Shevlin and Miles 2000; J. Cohen 1988). In educational research, effect sizes are typically small, hence different categorisations are applied.\n\n\n\n\n\n\n\n\nInterpretation\nEffect Size(Kraft 2020)\nEffect Size (Sanders, Mitchell, and Ni Chonaire 2020)\n\n\n\n\nSmall\n&lt; 5%\n3% - 10%\n\n\nMedium\n5% to 20%\n10% - 20%\n\n\nLarge\n&gt; 20%\n&gt; 20%",
    "crumbs": [
      "06 T-tests"
    ]
  },
  {
    "objectID": "chapters/06-T-testsPISA.html#tukeys-hsd",
    "href": "chapters/06-T-testsPISA.html#tukeys-hsd",
    "title": "06 T-tests",
    "section": "3.2 Tukey’s HSD",
    "text": "3.2 Tukey’s HSD\nWhen an anova test reports that are some statistically significant differences between groups, it does not imply there are statistically significant differences between all subgroups. For example, if the anova reports statistically significant differences by age, statistically significant differences might exist between 11, 12 and 13-year old students, but not between 13 and 14-year olds.\nWe can use an additional anova test, Tukey’s Honest Significant Difference test (or Tukey’s HSD for short), to find out which pairs of subgroups have statistically significant differences in means.\nConsider the question: Are there statistically significant differences in the variance of science scores of the UK, US, France and Germany? To determine if such differences exist, we create a new subset for those countries’ science scores, and then run an anova test by country, reporting the eta squared value.\n\nPISAMULTI &lt;- PISA_2022 %&gt;%\n1  select(CNT, PV1SCIE) %&gt;%\n2  filter(CNT == \"United Kingdom\" | CNT == \"United States\" |\n           CNT == \"Germany\" | CNT == \"France\")\n\n3resaov&lt;-aov(PV1SCIE ~ CNT, data = PISAMULTI)\n4sumresaov&lt;-summary(resaov)\nsumresaov\n\n5eta&lt;-as.data.frame(etaSquared(resaov))\n6eta&lt;-eta*100\n7eta\n\n\n1\n\nselect the variables of interest, country, and maths scores\n\n2\n\nfilter for countries of interest. Note a shorter way to do the filter is filter(CNT %in% c(\"United Kingdom\", \"United States\", \"Germany\", \"France\"))\n\n3\n\nuse aov to perform the anova calculation. We set the data we are passing (data = ALLPISAMATH) and set that we want to determine the variance in maths scores by country (PV1MATH ~ CNT) - we put the output into a new variable resaov\n\n4\n\nproduce a summary of resaov\n\n5\n\nuse etaSquared(resaov) to find the eta squared value. We convert this to a data frame so we can perform the next steps\n\n6\n\nto convert the eta squared value into a percentage of variance explained, we multiply by 100\n\n\n7\n\nprint the result\n\n\n\n\n               Df    Sum Sq Mean Sq F value Pr(&gt;F)    \nCNT             3    993358  331119   30.24 &lt;2e-16 ***\nResiduals   30406 332902262   10949                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n       eta.sq eta.sq.part\nCNT 0.2975057   0.2975057\n\n\nThe anova results tell us there are significant differences between the countries, which account for 0.3 % of variance in scores. We can then run a Tukey HSD test to determine which countries have significant differences between mean scores.\n\nTukeyHSD(resaov)\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = PV1SCIE ~ CNT, data = PISAMULTI)\n\n$CNT\n                                   diff        lwr       upr     p adj\nFrance-Germany               -13.871343 -18.613536 -9.129150 0.0000000\nUnited Kingdom-Germany        -2.989572  -7.159141  1.179997 0.2536226\nUnited States-Germany          2.995899  -2.266149  8.257948 0.4602611\nUnited Kingdom-France         10.881771   6.851391 14.912151 0.0000000\nUnited States-France          16.867243  11.714786 22.019699 0.0000000\nUnited States-United Kingdom   5.985472   1.354627 10.616316 0.0049773\n\n\nFrom that we get a table with p values (p adj) for different pairs of countries. Note that these are below 0.05 for France-Germany, UK-France, US-UK and US-France, but greater than 0.05 for UK-Germany, US-Germany. So we can conclude there are significant differences in science scores between France-Germany, UK-France, US-UK and US-France but not between the UK and Germany, and the US and Germany.",
    "crumbs": [
      "06 T-tests"
    ]
  },
  {
    "objectID": "chapters/06-T-testsPISA.html#task-1---choice-of-tests",
    "href": "chapters/06-T-testsPISA.html#task-1---choice-of-tests",
    "title": "06 T-tests",
    "section": "4.1 Task 1 - Choice of tests",
    "text": "4.1 Task 1 - Choice of tests\nConsider the following scenarios. Which (if any) of the t-tests would be most of appropriate, including whether it would be a one or two tailed test. Your answer should choose from one of the following options:\n\nunpaired, one-tailed test\nunpaired, two-tailed test\npaired, one-tailed test\npaired, two-tailed test\n\n\n\n\n\n\n\nNote\n\n\n\nOne and two-tailed tests\nRemember that a one-tailed test only looks for differences in one direction from the mean (for example, that one sample has a higher mean than the other). A two-tailed tests tests for the possibility of the means of the two groups being higher or lower than each other.\n\n\n\n\nAn educational researcher wants to test a teaching approach with a group of 12 students to see if an intervention increases performance in their year 6 SATs results. Pupils are given a SATS paper before the intervention and again after. The results of these are normalised and then compared.\nA teacher wants to see if their pupils’ GCSE computer science test scores are in line with the national average or not. The tests are out of 180 marks.\nThe DfE want to compare uptake of STEM subjects pre and post pandemic to see if there has been any change in the percentage of students studying at least one STEM subject for A level.\nA school wants to compare salaries of staff between this academic year and last academic year to see whether there has been a significant increase.\nThe same school as in d) wants to compare salaries of support staff and teaching staff to see if there is a significant difference.\nA researcher wants to find out how much time pupils spend looking at screens during lesson time, to see if there is a difference between year 7 and year 10 students. 10 pupils in year 7 and 10 pupils in year 10 are randomly selected across a school and observed throughout a school day in November. The times are recorded to the nearest minute.\nA business manager wants to check if the financial expenditure on STEM teachers per year is similar to the national average (based on average numbers of pupils on role)\n\n\n\n\nAnswer\n# Answers\n\n# a)  An educational researcher wants to test a teaching approach with a group of 12 students to see if an intervention increases performance in their year 6 SATs results. Pupils are given a SATS paper before the intervention and again after. The results of these are normalised and then compared.\n\n# Paired (because we compare pairs of results (before and after) for the same student) and two-tailed (because we are interested in the means being higher or lower)\n\n# b)  A teacher wants to see if their pupils' GCSE computer science test scores are in line with the national average or not. The tests are out of 180 marks.\n\n# Unpaired (the teacher compares their students with another pool) and two-tailed (because we are interested in the means being higher or lower)\n\n# c)  The DfE want to compare uptake of STEM subjects pre and post pandemic to see if there has been any change in the percentage of students studying at least one STEM subject for A level.\n\n# Unpaired (the students taking STEM subjects before and after the pandemic will be different individuals from different cohorts) and two-tailed (because we are interested in the means being higher or lower)\n\n# d)  A school wants to compare salaries of staff between this academic year and last academic year to see whether there has been a significant increase.\n\n# Possibly paired (if the staff body has remained the same), and two-tailed (because we are interested in the means being higher or lower)\n\n# e)  The same school as in d) wants to compare salaries of support staff and teaching staff to see if there is a significant difference.\n\n# Unpaired (because there are two different groups, teachers and support staff), and two-tailed (because we are interested in the mean salaries being higher or lower)\n\n# f)  A researcher wants to find out how much time pupils spend looking at screens during lesson time, to see if there is a difference between year 7 and year 10 students. 10 pupils in year 7 and 10 pupils in year 10 are randomly selected across a school and observed  throughout a school day in November. The times are recorded to the nearest minute.\n\n# Unpaired (because there are two different groups, Y7 and Y10), and two-tailed (because we are interested in the means of times being higher or lower)\n\n# g)  A business manager wants to check if the financial expenditure on STEM teachers per year is similar to the national average (based on average numbers of pupils on role)\n\n# Unpaired (because there are two different groups, the school and the national cohort), and two-tailed (because we are interested in the expenditure means being higher or lower)",
    "crumbs": [
      "06 T-tests"
    ]
  },
  {
    "objectID": "chapters/06-T-testsPISA.html#task-2---one-sample-t-tests",
    "href": "chapters/06-T-testsPISA.html#task-2---one-sample-t-tests",
    "title": "06 T-tests",
    "section": "4.2 Task 2 - One Sample T-tests",
    "text": "4.2 Task 2 - One Sample T-tests\n\n\nUse the PISA dataset and the PV1SCIE (Science score) variable to perform a two-sided, one sample t-test to determine if students in the UK perform similarly or differently from the OECD average of 468 points.\n\n\n\nAnswer\n# Are there differences between the mean scores of UK students and the OECD average of 468 in science?\n\n# Select the science score columns (PV1SCIE)\n# Filter the data to select UK responses\n\nSCIEUK &lt;- PISA_2022 %&gt;%\n  select(CNT, PV1SCIE) %&gt;%\n  filter(CNT == 'United Kingdom')\n\n# The conditions to do a t-test include that the data are normally distributed\n# Let us check the conditions are met by calculating if the data sets is normally\n# distributed using a histogram or qqplot\nggplot(data=SCIEUK,\n       aes(x=PV1SCIE)) +\n  geom_histogram(binwidth = 5, fill=\"darkseagreen4\")\n\nqqnorm(SCIEUK$PV1SCIE)\nqqline(SCIEUK$PV1SCIE, col = \"red\")\n\n# The plots produces relatively straight lines so the distributions can be assumed to be normal\n\n# Plot a two-sided one sample t-test to compare with OECD Science average of 468\nt.test(SCIEUK$PV1SCIE, mu = 468)\n\n\n# The p-value is &lt;0.05 (2.2e-16) meaning we reject the null hypothesis that there is no statistical differences between the UK and OECD average and that instead accept the alternative hypothesis that there is a statistical difference\n\n\n\nChoose a different country of interest to their scores with one of the OECD averages for either PV1MATH (472 points), PV1READ (476 points) or PV1SCIE (468 points).\n\n\n\nAnswer\n# Are there differences between the mean score in Korea and the OECD in mathematics?\n# Select the maths score columns (PV1MATH)\n# Filter the data to select Korea responses\n\nMATHKOR &lt;- PISA_2022 %&gt;%\n  select(CNT, PV1MATH) %&gt;%\n  filter(CNT == 'Korea')\n\n# The conditions to do a t-test include that the data are normally distributed\n# Let us check the conditions are met by calculating if the data sets is normally\n# distributed using a histogram or qqplot\nggplot(data=MATHKOR,\n       aes(x=PV1MATH)) +\n  geom_histogram(binwidth = 5, fill=\"darkseagreen4\")\n\nqqnorm(MATHKOR$PV1MATH)\nqqline(MATHKOR$PV1MATH, col = \"red\")\n\n# The plots produces relatively straight lines so the distributions can be assumed to be normal\n\n# Plot a two-sided one sample t-test to compare with OECD Science average of 468\nt.test(MATHKOR$PV1MATH, mu = 472)\n\n\n# The p-value is &lt;0.05 (2.2e-16) meaning we reject the null hypothesis that there is no statistical differences between Korea and OECD average and that instead accept the alternative hypothesis that there is a statistical difference",
    "crumbs": [
      "06 T-tests"
    ]
  },
  {
    "objectID": "chapters/06-T-testsPISA.html#task-3---two-sample-unpaired-t-tests",
    "href": "chapters/06-T-testsPISA.html#task-3---two-sample-unpaired-t-tests",
    "title": "06 T-tests",
    "section": "4.3 Task 3 - Two Sample Unpaired T-tests",
    "text": "4.3 Task 3 - Two Sample Unpaired T-tests\n\n\nUse the PISA dataset and the gender ST004D01T and PV1SCIE (Science score) variables to perform a two-sided, unpaired t-test to determine if boys and girls perform differently on the test in the UK.\n\n\n\nAnswer\n# Are there differences between the mean scores of UK boys and girls in PISA mathematics?\n\n# Select the gender (ST004D01T) and maths score columns (PV1MATH)\n# Filter the data to select UK responses\n\nMaleUK &lt;- PISA_2022 %&gt;%\n  select(CNT, ST004D01T, PV1SCIE) %&gt;%\n  filter(CNT == 'United Kingdom',\n         ST004D01T == 'Male')\n\nFemaleUK &lt;- PISA_2022 %&gt;%\n  select(CNT, ST004D01T, PV1SCIE) %&gt;%\n  filter(CNT == 'United Kingdom',\n         ST004D01T == 'Female')\n\n# The conditions to do a t-test include that the data are normally distributed\n# and there is homogeneity (similarity) of the variances (the squared standard deviations)\n# Let us check the conditions are met by calculating first if the data sets are normally\n# distributed using a histogram or qqplot\nggplot(data=MaleUK,\n       aes(x=PV1SCIE)) +\n  geom_histogram(binwidth = 5, fill=\"darkseagreen4\")\n\nggplot(data=FemaleUK,\n       aes(x=PV1SCIE)) +\n  geom_histogram(binwidth = 5, fill=\"darkseagreen4\")\n\nqqnorm(MaleUK$PV1SCIE)\nqqline(MaleUK$PV1SCIE, col = \"red\")\n\nqqnorm(FemaleUK$PV1SCIE)\nqqline(FemaleUK$PV1SCIE, col = \"red\")\n\n# The plots produces relatively straight lines so the distributions can be assumed to be normal\n#\n# We will then check the variances of the two data sets\n\nVarM &lt;- var(MaleUK$PV1SCIE, na.rm = TRUE)\nVarF &lt;- var(FemaleUK$PV1SCIE, na.rm = TRUE)\nVarM / VarF\n\n# The variance ratio is close to 1 (1.1)\n# So our two conditions are met and can we can perform the t-test\n\n\n# Plot a two-sided, unpaired t-test\nt.test(MaleUK$PV1SCIE, FemaleUK$PV1SCIE, \n       paired = FALSE, alternative = \"two.sided\")\n\n# The p-value is &lt;0.05 (8.547e-05) meaning we reject the null hypothesis that there is no statistical differences between boys and girls on average and accept the null hypothesis that there is a statistical difference.\n\n\n\nChoose a different country of interest to compare performance in males and females in that country in either mathematics, reading or science.\n\n\n\nAnswer\n# Are there differences between the mean scores of boys and girls in Japan PISA mathematics?\n#\n# Select the gender (ST004D01T) and math score columns (PV1MATH)\n# Filter the data to select UK responses\n\nMaleJapan &lt;- PISA_2022 %&gt;%\n  select(CNT, ST004D01T, PV1MATH) %&gt;%\n  filter(CNT == 'Japan', ST004D01T == 'Male')\n\nFemaleJapan &lt;- PISA_2022 %&gt;%\n  select(CNT, ST004D01T, PV1MATH) %&gt;%\n  filter(CNT == 'Japan', ST004D01T == 'Female')\n\n# The conditions to do a t-test include that the data are normally distributed\n\n\nqqnorm(MaleJapan$PV1MATH)\nqqline(MaleJapan$PV1MATH, col = \"red\")\n\nqqnorm(FemaleJapan$PV1MATH)\nqqline(FemaleJapan$PV1MATH, col = \"red\")\n\n\n# The plots produces relatively straight lines so the distributions can be # assumed to be normal\n#\n# We will then check the variances of the two data sets\n\nVarM&lt;-var(MaleJapan$PV1MATH, na.rm = TRUE)\nVarF&lt;-var(FemaleJapan$PV1MATH, na.rm = TRUE)\nVarM/VarF\n\n# The variance ratio is close to 1 (1.26)\n# So our two conditions are met and can we can perform the t-test\n\n# Create a Japan Math subset\nCHIMATH &lt;- PISA_2022 %&gt;%\n  select(CNT, PV1MATH, ST004D01T) %&gt;%\n  filter(CNT == \"Japan\")\n# Plot a two-sided, unpaired t-test\nt.test(MaleJapan$PV1MATH, FemaleJapan$PV1MATH,  \n       paired = FALSE, alternative = \"two.sided\")\n\n# The p-value is &lt;0.025 (0.0004128) suggesting there are statistically\n# differences between boys and girls in mathematics in Japan\n\n\n\nNow try to compare the performance of males and females in Maths in all the OECD countries in the PISA data. You may need to think about how to do this using R without repeating the test for each country.\n\n\n\nAnswer\nMaleOECD &lt;- PISA_2022 %&gt;%\n  select(OECD, ST004D01T, PV1MATH) %&gt;%\n  filter(OECD == 'Yes', ST004D01T == 'Male')\n\nFemaleOECD &lt;- PISA_2022 %&gt;%\n  select(OECD, ST004D01T, PV1MATH) %&gt;%\n  filter(OECD == 'Yes', ST004D01T == 'Female')\n\nqqnorm(MaleOECD$PV1MATH)\nqqline(MaleOECD$PV1MATH, col = \"red\")\n\nqqnorm(FemaleOECD$PV1MATH)\nqqline(FemaleOECD$PV1MATH, col = \"red\")\n\n\n# The plots produces relatively straight lines so the distributions can be assumed to be normal\n\n# We will then check the variances of the two data sets\n\nVarM &lt;- var(MaleOECD$PV1MATH, na.rm = TRUE)\nVarF &lt;- var(FemaleOECD$PV1MATH, na.rm = TRUE)\nVarM / VarF\n\n# The variance ratio is close to 1 (1.18)\n# So our two conditions are met and can we can perform the t-test\n\n# The p-value is &lt;0.05 (&lt;2.2e-16) suggesting there are statistically\n# differences between boys and girls\n\nOECD &lt;- PISA_2022 %&gt;%\n  select(OECD, ST004D01T, PV1MATH) %&gt;%\n  filter(OECD=='Yes')\n\nt.test(MaleOECD$PV1MATH, FemaleOECD$PV1MATH, \n       paired = FALSE, alternative = \"two.sided\")",
    "crumbs": [
      "06 T-tests"
    ]
  },
  {
    "objectID": "chapters/06-T-testsPISA.html#task-4---two-sample-paired-t-tests",
    "href": "chapters/06-T-testsPISA.html#task-4---two-sample-paired-t-tests",
    "title": "06 T-tests",
    "section": "4.4 Task 4 - Two Sample Paired T-tests",
    "text": "4.4 Task 4 - Two Sample Paired T-tests\n\n\nUse the PISA dataset and the PV1MATH (Maths score) and PV1SCIE (Science score) variables to perform a two-sided, two sample paired t-test to determine if there is a difference in mathematics and science scores for students or not in the United Kingdom.\n\n\n\nAnswer\n# Are there differences between scores in maths and science for students in the UK or not.\n\n# Select the maths score column (PV1MATH) and the science score columns (PV1SCIE)\n# Filter the data to select UK responses\n\nMATHSCIUK &lt;- PISA_2022 %&gt;%\n  select(CNT, PV1MATH,PV1SCIE) %&gt;%\n  filter(CNT == 'United Kingdom')\n\n# The conditions to do a t-test include that the data are normally distributed\n# and there is homogeneity (similarity) of the variances (the squared standard deviations)\n# Let us check the conditions are met by calculating first if the data sets are normally\n# distributed using a histogram or qqplot\nggplot(data=MATHSCIUK,\n       aes(x=PV1MATH)) +\n  geom_histogram(binwidth = 5, fill=\"darkseagreen4\")\n\nggplot(data=MATHSCIUK,\n       aes(x=PV1SCIE)) +\n  geom_histogram(binwidth = 5, fill=\"darkseagreen4\")\n\nqqnorm(MATHSCIUK$PV1MATH)\nqqline(MATHSCIUK$PV1MATH, col = \"red\")\n\nqqnorm(MATHSCIUK$PV1SCIE)\nqqline(MATHSCIUK$PV1SCIE, col = \"red\")\n\n# The plots produces relatively straight lines so the distributions can be assumed to be normal\n#\n# We will then check the variances of the two data sets\n\nVarM &lt;- var(MATHSCIUK$PV1MATH, na.rm = TRUE)\nVarF &lt;- var(MATHSCIUK$PV1SCIE, na.rm = TRUE)\nVarM / VarF\n\n# The variance ratio is close to 1 -ish (0.86)\n# So our two conditions are met and can we can perform the t-test \n\n# Conduct a two-sided two sample paired t-test to compare maths and science scores\nt.test(MATHSCIUK$PV1MATH,MATHSCIUK$PV1SCIE,paired=TRUE)\n\n# The p-value is &lt;0.05 (2.2e-16) meaning we reject the null hypothesis that there is no differences between maths and science scores for students in the UK, meaning we accept the alternative hypothesis that there is a difference on average.\n\n\n\nUse the PISA dataset and the PV1MATH (Maths score) and PV1SCIE (Science score) variables to perform a two-sided, two sample paired t-test to determine if there is a difference in mathematics and science scores for students in the whole PISA set.\n\n\n\nAnswer\n# Are there differences between scores in maths and science for students in the UK or not.\n\n# Select the maths score column (PV1MATH) and the science score columns (PV1SCIE)\n\nMATHSCIPISA &lt;- PISA_2022 %&gt;%\n  select(PV1MATH,PV1SCIE) \n\n# The conditions to do a t-test include that the data are normally distributed\n# and there is homogeneity (similarity) of the variances (the squared standard deviations)\n# Let us check the conditions are met by calculating first if the data sets are normally\n# distributed using a histogram or qqplot\nggplot(data=MATHSCIPISA,\n       aes(x=PV1MATH)) +\n  geom_histogram(binwidth = 5, fill=\"darkseagreen4\")\n\nggplot(data=MATHSCIPISA,\n       aes(x=PV1SCIE)) +\n  geom_histogram(binwidth = 5, fill=\"darkseagreen4\")\n\nqqnorm(MATHSCIPISA$PV1MATH)\nqqline(MATHSCIPISA$PV1MATH, col = \"red\")\n\nqqnorm(MATHSCIPISA$PV1SCIE)\nqqline(MATHSCIPISA$PV1SCIE, col = \"red\")\n\n# The plots produces relatively straight lines so the distributions can be assumed to be normal\n#\n# We will then check the variances of the two data sets\n\nVarM &lt;- var(MATHSCIPISA$PV1MATH, na.rm = TRUE)\nVarF &lt;- var(MATHSCIPISA$PV1SCIE, na.rm = TRUE)\nVarM / VarF\n\n# The variance ratio is close to 1 -ish (0.94)\n\n# Conduct a two-sided two sample paired t-test to compare maths and science scores\nt.test(MATHSCIPISA$PV1MATH,MATHSCIPISA$PV1SCIE,paired=TRUE)\n\n# The p-value is &lt;0.05 (2.2e-16) meaning we reject the null hypothesis that there is no differences between maths and science scores, meaning we accept the alternative hypothesis that there is a difference on average.",
    "crumbs": [
      "06 T-tests"
    ]
  },
  {
    "objectID": "chapters/06-T-testsPISA.html#task-5---multiple-groups-comparisons-with-anova",
    "href": "chapters/06-T-testsPISA.html#task-5---multiple-groups-comparisons-with-anova",
    "title": "06 T-tests",
    "section": "4.5 Task 5 - Multiple groups comparisons with anova",
    "text": "4.5 Task 5 - Multiple groups comparisons with anova\n\n\nFor the UK, France, Thailand, and the US determine if there are statistically significant differences in variation in mathematics scores.\n\n\n\nanswer\nPISAMULTI&lt;-PISA_2022 %&gt;%\n  select(CNT, PV1MATH)%&gt;%\n  filter(CNT == \"United Kingdom\" | CNT == \"Thailand\" | CNT == \"United States\" |\n         CNT == \"France\")\n\n\nresaov&lt;-aov(PV1MATH ~ CNT, data = PISAMULTI)\nsumresaov&lt;-summary(resaov)\nsumresaov\n\n\n               Df    Sum Sq Mean Sq F value Pr(&gt;F)    \nCNT             3  24352745 8117582   905.3 &lt;2e-16 ***\nResiduals   32785 293984339    8967                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nanswer\neta&lt;-as.data.frame(etaSquared(resaov))\neta&lt;-eta*100\neta\n\n\n      eta.sq eta.sq.part\nCNT 7.649987    7.649987\n\n\nanswer\n# the differences between countries explains 7.6 % of the variance in scores\n\nTukeyHSD(resaov)\n\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = PV1MATH ~ CNT, data = PISAMULTI)\n\n$CNT\n                                   diff       lwr        upr     p adj\nUnited Kingdom-France         14.447781  10.80031  18.095251 0.0000000\nThailand-France              -53.254801 -57.21819 -49.291415 0.0000000\nUnited States-France          -6.221682 -10.88462  -1.558739 0.0034071\nThailand-United Kingdom      -67.702582 -71.09801 -64.307154 0.0000000\nUnited States-United Kingdom -20.669463 -24.86035 -16.478575 0.0000000\nUnited States-Thailand        47.033119  42.56457  51.501668 0.0000000\n\n\nanswer\n# There are statistically significant differences in mathematics scores for all pairs of countries\n\n\n\nFor the UK, are there statistically significant differences in reading score by students who speak different languages (LANGN)\n\n\n\nanswer\n# Create a data frame with Reading and school type variables, filte for the uK\nUKLangRead&lt;-PISA_2022 %&gt;%\n  select(CNT, PV1READ, LANGN) %&gt;%\n  filter(CNT == \"United Kingdom\")\n\n# Perform an anova test for reading scores, school type\n\nresaov&lt;-aov(PV1READ ~ LANGN, data = UKLangRead)\nsumresaov&lt;-summary(resaov)\nsumresaov\n\n\n               Df    Sum Sq Mean Sq F value Pr(&gt;F)    \nLANGN           9   3653767  405974   37.84 &lt;2e-16 ***\nResiduals   12962 139057822   10728                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nanswer\n# p&lt;2e-16 so there are statistically significant differences in reading scores between speakers of different languages \n\n# Calculate eta squared\n\neta&lt;-as.data.frame(etaSquared(resaov))\neta&lt;-eta*100\neta\n\n\n        eta.sq eta.sq.part\nLANGN 2.560245    2.560245\n\n\nanswer\n# Differences between language speakers explains 2.6% of the total variance in scores\n\n\n# Perform the post-hoc Tukey test to determine between which language speaker groups significant differences lie\n\nTukeyHSD(resaov)\n\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = PV1READ ~ LANGN, data = UKLangRead)\n\n$LANGN\n                                                                     diff\nEnglish-Scots                                                 62.84014574\nWelsh-Scots                                                  -12.93526998\nScottish Gaelic-Scots                                         57.85860281\nIrish-Scots                                                  -33.91929005\nOther European languages (QSC)-Scots                          51.39604436\nUlster Scots-Scots                                            20.20519166\nA non-European Union language-Scots                           23.91065526\nAnother language (QUK)-Scots                                  51.46413115\nMissing-Scots                                                 31.77456179\nWelsh-English                                                -75.77541571\n                                                                     lwr\nEnglish-Scots                                                  45.851374\nWelsh-Scots                                                   -45.517499\nScottish Gaelic-Scots                                         -67.131182\nIrish-Scots                                                   -98.058036\nOther European languages (QSC)-Scots                           20.170235\nUlster Scots-Scots                                            -33.622454\nA non-European Union language-Scots                            -9.506853\nAnother language (QUK)-Scots                                   31.207521\nMissing-Scots                                                  13.175387\nWelsh-English                                                -103.973070\n                                                                    upr\nEnglish-Scots                                                 79.828918\nWelsh-Scots                                                   19.646959\nScottish Gaelic-Scots                                        182.848388\nIrish-Scots                                                   30.219456\nOther European languages (QSC)-Scots                          82.621854\nUlster Scots-Scots                                            74.032838\nA non-European Union language-Scots                           57.328163\nAnother language (QUK)-Scots                                  71.720741\nMissing-Scots                                                 50.373737\nWelsh-English                                                -47.577761\n                                                                 p adj\nEnglish-Scots                                                0.0000000\nWelsh-Scots                                                  0.9629532\nScottish Gaelic-Scots                                        0.9059913\nIrish-Scots                                                  0.8106915\nOther European languages (QSC)-Scots                         0.0000086\nUlster Scots-Scots                                           0.9743577\nA non-European Union language-Scots                          0.4128165\nAnother language (QUK)-Scots                                 0.0000000\nMissing-Scots                                                0.0000029\nWelsh-English                                                0.0000000\n [ reached getOption(\"max.print\") -- omitted 35 rows ]\n\n\nanswer\n# There are statistically significant differences in reading scores between speakers of some languages. For example, English-Scots (p = 0.0000000), Irish-English (p=0.0000354) but not for others, for example, Welsh-Scots (p=0.9629532)\n\n\n\nFor the UK, use ifelse on the HOMEPOS variable to create categories for four quartiles (divide the data into top; upper-mid; lower-mid; and bottom). Use anova to determine between which groups there are statistically significant differences in science scores\n\n\n\n\n\n\n\nHINT\n\n\n\nHINT: You can use quantiles &lt;- quantile(UKSci$PV1SCIE, prob=c(.25,.5,.75), na.rm=TRUE) to give the values of PV1SCIE that account for 25%, 50% and 75% of the responses.\n\n\n\n\nanswer\n# Create a data frame of UK science scores and Wealth data\n# Drop levels to remove other countries\nUKSci &lt;- PISA_2022 %&gt;%\n  select(CNT, PV1SCIE, HOMEPOS) %&gt;%\n  filter(CNT == \"United Kingdom\") %&gt;%\n  na.omit() %&gt;%\n  droplevels() %&gt;%\n  select(PV1SCIE, HOMEPOS)\n\n# Find the cut of points for 25%, 50% and 75% (quantiles) of HOMEPOS\n\nquantiles &lt;- quantile(UKSci$HOMEPOS, prob = c(.25,.5,.75), na.rm=TRUE)\n\n# Note the results are stored in quantiles[1] (25%), quantiles[2] \n# (50%), quantiles[3] (75%)\n\n# Mutate the HOMEPOS column, using ifelse, to substitute the labels, \"Bottom\",\n# \"Mid\", \"upper-mid\" and \"top\" for the quantiles.\n\nUKSci&lt;-UKSci%&gt;%\n  mutate(HOMEPOS = ifelse(HOMEPOS&lt;quantiles[1], \"Bottom\", \n                        ifelse(HOMEPOS &lt; quantiles[2], \"Lower-mid\",\n                               ifelse(HOMEPOS &lt; quantiles[3],\n                                      \"Upper-mid\",\"Top\"))))\n\n# Perform the avova for science scores by wealth, categories into 4 groups\n\nresaov&lt;-aov(PV1SCIE ~ HOMEPOS, data = UKSci)\nsumresaov&lt;-summary(resaov)\nsumresaov\n\n\n               Df    Sum Sq Mean Sq F value Pr(&gt;F)    \nHOMEPOS         3  13965393 4655131   484.5 &lt;2e-16 ***\nResiduals   11483 110321087    9607                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nanswer\n# p is &lt;2e-16 so significant differences exist between wealth groups on science\n# scores\n\n# perform the post hoc Tukey test to find out where statistically signficant differences exist\n\nTukeyHSD(resaov)\n\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = PV1SCIE ~ HOMEPOS, data = UKSci)\n\n$HOMEPOS\n                         diff       lwr       upr p adj\nLower-mid-Bottom     30.44388  23.79735  37.09042     0\nTop-Bottom           94.24677  87.60024 100.89330     0\nUpper-mid-Bottom     59.32648  52.67995  65.97302     0\nTop-Lower-mid        63.80289  57.15693  70.44885     0\nUpper-mid-Lower-mid  28.88260  22.23665  35.52856     0\nUpper-mid-Top       -34.92029 -41.56624 -28.27433     0\n\n\nanswer\n# There are statistically significant differences in science scores in the UK between all groups by wealth",
    "crumbs": [
      "06 T-tests"
    ]
  },
  {
    "objectID": "chapters/06-T-testsPISA.html#recreating-a-paper-in-r",
    "href": "chapters/06-T-testsPISA.html#recreating-a-paper-in-r",
    "title": "06 T-tests",
    "section": "5.1 Recreating a paper in R",
    "text": "5.1 Recreating a paper in R\n\nLooking at Cook (2014), consider the following\n\n\nIs it possible to replicate the results using the PISA 2018 data set? Make a graph showing the difference in male and female PV1MATH results for each country CNT. To do this we are going to have to:\n\nwork out the mean() maths score PV1MATH for each country CNT and gender ST004D01T grouping, call this meanmath and create a new data frame to store this\nfrom this data frame, create two new data frames, one for males only and one for females only\nrename() (see ?@sec-renaming) the meanmath score in each data frame to male_mean and female_mean\nbind the data frames together using using column bind function cbind(&lt;male_df&gt;, &lt;female_df&gt;) and store this in a new dataframe called Mathgendergap. NOTE: cbind only accepts tables with different names, so you’ll need to select select(CNT, male_mean) from the male dataframe and select(female_mean) from the female dataframe.\nuse mutate (see ?@sec-mutate) to calculate the difference in male and female mean maths scores for each country\nplot the results for each country\n\n\n\n\ncreating difference dataset\n# A relatively simple recreation (without significance testing)\nMathgendergap &lt;- PISA_2022 %&gt;%\n  select(CNT, PV1MATH, ST004D01T) %&gt;%\n  group_by(CNT, ST004D01T) %&gt;%\n  summarise(meanmath=mean(PV1MATH)) %&gt;%\n  ungroup()\n\n# alternative, using column binding, cbind():\nMathgendergap&lt;-  cbind(Mathgendergap %&gt;% \n                           filter(ST004D01T == \"Male\") %&gt;%\n                           rename(male_mean = meanmath) %&gt;%\n                             select(CNT, male_mean),\n                        Mathgendergap %&gt;%\n                           filter(ST004D01T == \"Female\") %&gt;%\n                             rename(female_mean = meanmath) %&gt;%\n                             select(female_mean))\n\n# alternatively you can use pivot_wider\n# Mathgendergap &lt;- pivot_wider(Mathgendergap, names_from = ST004D01T, values_from = meanmath)\n\nMathgendergap &lt;- Mathgendergap %&gt;%\n  mutate(difference = female_mean - male_mean) %&gt;%\n  arrange(desc(difference))\n\n\nThe above code doesn’t include the t-test results for each country, to do this we need to run some more complex code, you can see how it works below:\n\n\ncode\n# A fuller recreation with t-tests\n# conduct a ttest across countries on a specified column\nlibrary(broom)\n\nttest_by_country &lt;- function(data, column = PV1MATH){\n\n  # work out which countries have full 30+ datasets for this ttest\n  countries &lt;- data %&gt;% ungroup() %&gt;%\n    filter(!is.na({{column}})) %&gt;%    # {{column}} allows you to change the field of focus\n    select(CNT, ST004D01T, {{column}}) %&gt;%\n    group_by(CNT) %&gt;%\n    filter(n() &gt; 30) %&gt;%\n    pull(CNT) %&gt;%  # the pull command returns the column as a vector, not a table\n    unique()\n \n  # list the countries that don't meet that criteria\n  message(\"dropping: \", setdiff(unique(data$CNT), countries), \" as too few entries for ttest\")\n \n  # reduce the dataset to only those countries with 30+ entries\n  data &lt;- data %&gt;%\n    filter(CNT %in% countries)\n\n  # for each country in this new dataset perform a set of calculations\n  test_result &lt;- map_df(unique(data$CNT),\n                        function(x){\n   \n                            # make a subset of the data just for that country\n                            df &lt;- data %&gt;% filter(CNT == x)\n                           \n                            # get the results pull({{column}}) for females and males as two separate vectors\n                            f_data &lt;- df %&gt;% filter(ST004D01T == \"Female\") %&gt;% pull({{column}})\n                            m_data &lt;- df %&gt;% filter(ST004D01T == \"Male\") %&gt;% pull({{column}})\n                           \n                            # tell us the number of results\n                            message(x, \" f:\", length(f_data), \" m:\", length(m_data))\n                           \n                            # work out the means of each vector\n                            f_mean &lt;- mean(f_data)\n                            m_mean &lt;- mean(m_data)\n                           \n                            t.test(m_data, f_data) %&gt;%  # conduct a ttest on the male and female results\n                              tidy() %&gt;%      # convert the ttest result into a dataframe\n                              mutate(CNT = x,           # add columns to record the country\n                                     f_mean = f_mean,   # the mean female grade\n                                     m_mean = m_mean,   # the mean male grade\n                                     gender_diff = m_mean - f_mean,  # the difference between the two\n                                     prop_male = length(m_data) / (length(m_data) + length(f_data)))\n                                     # and the proportion who are male in the dataset\n    })\n  return(test_result)\n}\n\nplot_ttest_by_country &lt;- function(data, column = \"PV1MATH\"){\n\n  ggplot(data %&gt;% mutate(sig = p.value &lt; 0.05),\n         aes(x=reorder(CNT, gender_diff), y=gender_diff, colour=sig))+\n    geom_point(aes(size = prop_male)) +  \n    geom_hline(yintercept = 0, lty=2) +  # add a line on 0\n    coord_flip() +     # rotate the graph\n    xlab(\"country\") +\n    ylab(\"mean(male - female)\") +\n    ggtitle(paste(\"gender differences for:\", column)) +\n    theme(axis.text.x = element_text(angle = 90, vjust = 0.5,\n                                     hjust=1, size=5))\n}\n\n# run the first function using 2018 data and the PV1MATH column\nttest_results &lt;- ttest_by_country(PISA_2022, PV1MATH)\n\n#plot the results\nplot_ttest_by_country(ttest_results, \"PV1MATH\")\n\n\n\n\n\n\n\n\n\ncode\n# Alternatively, you could run the following:\n# run a ttest for each country\n# ttest_results &lt;- PISA_2022 %&gt;%\n#     filter(!is.na(PV1MATH)) %&gt;% # Vietnam no results?!\n#     select(CNT, ST004D01T, PV1MATH) %&gt;%\n#     group_by(CNT) %&gt;%\n#     nest(data = c(ST004D01T, PV1MATH)) %&gt;% #create a dataframe of gender results for each country\n#     summarise(tt = map(data, function(df){ # apply a ttest to each country\n#       t.test(df %&gt;% filter(ST004D01T == \"Female\") %$% PV1MATH,\n#              df %&gt;% filter(ST004D01T == \"Male\") %$% PV1MATH) %&gt;%\n#         tidy() # convert results into a dataframe\n#     })) %&gt;%\n#     unnest(tt)\n\n\n\nWhat issues are there with using a t-test for the context given in the paper?\nHow do your findings from question 3 and the 2018 dataset compare with those in the paper? Are there any differences or disagreements with your findings?\nHow could the paper be improved?",
    "crumbs": [
      "06 T-tests"
    ]
  },
  {
    "objectID": "chapters/A6-QandA.html",
    "href": "chapters/A6-QandA.html",
    "title": "Questions and Answers",
    "section": "",
    "text": "When you are loading packages, sometimes different packages have the same function names in them, and the functions themselves will do very different things. For example, there is a select function in the tidyverse, but also another select function in the package MASS that does something very different. If we load the tidyverse before loading MASS, then the MASS version of select is the one that will be used?!\n\nlibrary(tidyverse)\nlibrary(MASS)\n\ndiamonds %&gt;% select(carat, cut, color)\n\nTo get around this make sure that you load the tidyverse after MASS, to be safe you should always load the tidyverse last.\n\nlibrary(MASS) \nlibrary(tidyverse)\n\ndiamonds %&gt;% select(carat, cut, color)\n\n# A tibble: 53,940 × 3\n   carat cut       color\n   &lt;dbl&gt; &lt;ord&gt;     &lt;ord&gt;\n 1  0.23 Ideal     E    \n 2  0.21 Premium   E    \n 3  0.23 Good      E    \n 4  0.29 Premium   I    \n 5  0.31 Good      J    \n 6  0.24 Very Good J    \n 7  0.24 Very Good I    \n 8  0.26 Very Good H    \n 9  0.22 Fair      E    \n10  0.23 Very Good H    \n# ℹ 53,930 more rows\n\n\nyou can also specify the package that select comes from (in this case from a package within the tidyverse called dplyr):\n\ndiamonds %&gt;% dplyr::select(carat, cut, color)\n\n# A tibble: 53,940 × 3\n   carat cut       color\n   &lt;dbl&gt; &lt;ord&gt;     &lt;ord&gt;\n 1  0.23 Ideal     E    \n 2  0.21 Premium   E    \n 3  0.23 Good      E    \n 4  0.29 Premium   I    \n 5  0.31 Good      J    \n 6  0.24 Very Good J    \n 7  0.24 Very Good I    \n 8  0.26 Very Good H    \n 9  0.22 Fair      E    \n10  0.23 Very Good H    \n# ℹ 53,930 more rows\n\n\nFinally, there is a package that helps your deal with conflicts called conflicted. At the top of your script you can define which version of a function you prefer, this will be the version that will always be used. If you want to specify another version of a function, you can still use other versions of the function using the :: notation:\n\nlibrary(conflicted)\nconflicts_prefer(dplyr::select)\nconflicts_prefer(dplyr::mutate)\nconflicts_prefer(dplyr::summarise)\nconflicts_prefer(dplyr::filter)\n\ndf %&gt;% select(name, age) # uses select from dplyr\ndf %&gt;% MASS::select(name) # uses select from MASS\n\nTo find out if you have any conflicts, you can run conflict_scout().\n\nIf you are finding yourself with a conflict as mentioned above and want to unload packages, then you need to run the following code:\n\n# adapted from: @mmfrgmpds https://stackoverflow.com/questions/7505547/detach-all-packages-while-working-in-r\nwhile(!is.null(sessionInfo()$loadedOnly)){\n  lapply(names(sessionInfo()$loadedOnly), require, character.only = TRUE)\n  invisible(lapply(paste0('package:', names(sessionInfo()$otherPkgs)), detach, character.only=TRUE, unload=TRUE, force=TRUE))    \n}\n\n\nThe pipe operator %&gt;% is loaded when you load the tidyverse package - make sure you have installed tidyverse and loaded it\n\ninstall.packages(\"tidyverse\")  # install\nlibrary(tidyverse)             # load\n\n\nThis may be caused by having a bracket after the geom rather than before it\n\ndata&lt;-data.frame(x=5:1,\n                 y=10:6)\nggplot(data, aes(x, y) +           # Reproduce error message\n         geom_point())\n\n\ndata&lt;-data.frame(x=5:1,\n                 y=10:6)\nggplot(data, aes(x, y)) +           # Fixed error by moving bracket\n         geom_point()\n\n\nIf you want to use long axis titles you may find they overrun the space available\n\n# Make a sample data frame\ndata&lt;-data.frame(x=5:1,\n                 y=10:6)\n\n# plot the data\nggplot(data, aes(x=x, y=y)) +           \n         geom_col()+\n  ylab(\"A very long description for the y-axis label that will overflow and not look very nice\")\n\n\n\n\n\n\n\nTo insert a line break in the axis label, add \\n to the text where you want line breaks.\n\n# Make a sample data frame\ndata&lt;-data.frame(x=5:1,\n                 y=10:6)\n\n# plot the data\nggplot(data, aes(x=x, y=y)) +           \n         geom_col()+\n  ylab(\"A very long description \\n for the y-axis label that will \\n overflow and not look very nice\")\n\n\n\n\n\n\n\n\nThe code below will give you a list of all the item labels\n\n# You may want to set the maximun print output to see all the labels\noptions(max.print = 1300)\n\nlapply(PISA_2022, attr, \"label\")\n\n\nYou can use the gt package to convert data frames to aesthetically pleasing outputs.\n\n# load the gt package - you will need to run install.packages(\"gt\") the first time\n# install.packages(\"gt\")\nlibrary(gt)\n\n# Make the data frame you want you want to output\nscience_mean_scores &lt;- PISA_2022 %&gt;%\n  group_by(CNT) %&gt;%\n  summarise(mean_science_score = mean(PV1SCIE, na.rm = TRUE),\n            sd_science = sd(PV1SCIE, na.rm =TRUE))\n\n# Use gt to produce an output - you can copy and paste the table from the\n# viewer window to your report\n\ngt(science_mean_scores)\n\n\n\n\n\nCountry code 3-character\nmean_science_score\nsd_science\n\n\n\nAlbania\n375.8650\n81.17499\n\n\nUnited Arab Emirates\n435.9609\n108.04562\n\n\nArgentina\n415.0584\n86.30466\n\n\nAustralia\n507.7795\n106.78340\n\n\nAustria\n494.0894\n99.10689\n\n\nBelgium\n495.0015\n99.89222\n\n\nBulgaria\n421.9872\n94.68480\n\n\nBrazil\n406.3370\n93.33488\n\n\nBrunei Darussalam\n444.8849\n93.49958\n\n\nCanada\n499.4697\n98.78625\n\n\nSwitzerland\n501.4123\n97.88277\n\n\nChile\n463.1057\n94.91051\n\n\nColombia\n420.9458\n88.24887\n\n\nCosta Rica\n411.2082\n80.40614\n\n\nCzech Republic\n510.7872\n102.76484\n\n\nGermany\n495.2547\n105.42084\n\n\nDenmark\n480.3369\n96.87209\n\n\nDominican Republic\n361.6200\n68.71457\n\n\nSpain\n492.9236\n90.06178\n\n\nEstonia\n527.3109\n87.67284\n\n\nFinland\n497.9649\n111.47589\n\n\nFrance\n481.3834\n105.72320\n\n\nUnited Kingdom\n492.2651\n102.15378\n\n\nGeorgia\n385.6145\n81.63218\n\n\nGreece\n445.4408\n88.95744\n\n\nGuatemala\n374.5886\n65.37109\n\n\nHong Kong (China)\n524.5497\n91.06857\n\n\nCroatia\n483.1283\n91.97320\n\n\nHungary\n492.1069\n94.69703\n\n\nIndonesia\n394.9906\n69.89182\n\n\nIreland\n504.3750\n91.95203\n\n\nIceland\n448.0546\n94.76950\n\n\nIsrael\n464.0777\n108.57084\n\n\nItaly\n481.3281\n91.97045\n\n\nJamaica\n395.7114\n91.97299\n\n\nJordan\n374.6990\n73.68470\n\n\nJapan\n545.5399\n92.72193\n\n\nKazakhstan\n440.9755\n84.44319\n\n\nCambodia\n340.4659\n50.34331\n\n\nKorea\n530.6552\n103.99342\n\n\nKosovo\n353.5723\n64.84509\n\n\nLithuania\n480.0535\n92.51359\n\n\nLatvia\n492.5822\n84.61410\n\n\nMacao (China)\n543.1331\n86.61414\n\n\nMorocco\n363.4098\n66.20574\n\n\nRepublic of Moldova\n416.8691\n82.50639\n\n\nMexico\n410.7969\n74.97042\n\n\nNorth Macedonia\n382.3574\n82.77203\n\n\nMalta\n469.8360\n101.83745\n\n\nMontenegro\n404.9706\n83.35015\n\n\nMongolia\n411.4142\n77.72520\n\n\nMalaysia\n417.1980\n77.85995\n\n\nNetherlands\n486.8380\n111.77833\n\n\nNorway\n478.9396\n106.09425\n\n\nNew Zealand\n504.8458\n107.85424\n\n\nPanama\n385.0859\n84.92427\n\n\nPeru\n410.8352\n85.35240\n\n\nPhilippines\n353.7724\n76.99187\n\n\nPoland\n505.1500\n94.16577\n\n\nPortugal\n488.2668\n89.70144\n\n\nParaguay\n371.6893\n74.52611\n\n\nPalestinian Authority\n367.0259\n70.91610\n\n\nQatar\n428.8246\n96.25937\n\n\nBaku (Azerbaijan)\n381.5571\n78.67151\n\n\nUkrainian regions (18 of 27)\n454.4918\n88.72635\n\n\nRomania\n436.4904\n96.24036\n\n\nSaudi Arabia\n390.1679\n72.21294\n\n\nSingapore\n560.8252\n99.60358\n\n\nEl Salvador\n374.9843\n73.44363\n\n\nSerbia\n446.7715\n88.26844\n\n\nSlovak Republic\n467.2694\n102.95534\n\n\nSlovenia\n487.1098\n93.85904\n\n\nSweden\n494.1717\n107.51162\n\n\nChinese Taipei\n526.8225\n102.25648\n\n\nThailand\n429.1863\n93.12958\n\n\nTürkiye\n476.0276\n89.06750\n\n\nUruguay\n433.2891\n92.41654\n\n\nUnited States\n498.2506\n108.85390\n\n\nUzbekistan\n355.3407\n63.34434\n\n\nViet Nam\n473.3375\n78.42436\n\n\n\n\n\n# You can see more options on formating the table here: https://gt.rstudio.com\n# For example to add a heading\n\ngt(science_mean_scores) %&gt;% tab_header(\n    title = \"Mean science scores\",\n    subtitle = \"PISA 2022 data\")\n\n\n\n\n\n\nMean science scores\n\n\nPISA 2022 data\n\n\nCountry code 3-character\nmean_science_score\nsd_science\n\n\n\n\nAlbania\n375.8650\n81.17499\n\n\nUnited Arab Emirates\n435.9609\n108.04562\n\n\nArgentina\n415.0584\n86.30466\n\n\nAustralia\n507.7795\n106.78340\n\n\nAustria\n494.0894\n99.10689\n\n\nBelgium\n495.0015\n99.89222\n\n\nBulgaria\n421.9872\n94.68480\n\n\nBrazil\n406.3370\n93.33488\n\n\nBrunei Darussalam\n444.8849\n93.49958\n\n\nCanada\n499.4697\n98.78625\n\n\nSwitzerland\n501.4123\n97.88277\n\n\nChile\n463.1057\n94.91051\n\n\nColombia\n420.9458\n88.24887\n\n\nCosta Rica\n411.2082\n80.40614\n\n\nCzech Republic\n510.7872\n102.76484\n\n\nGermany\n495.2547\n105.42084\n\n\nDenmark\n480.3369\n96.87209\n\n\nDominican Republic\n361.6200\n68.71457\n\n\nSpain\n492.9236\n90.06178\n\n\nEstonia\n527.3109\n87.67284\n\n\nFinland\n497.9649\n111.47589\n\n\nFrance\n481.3834\n105.72320\n\n\nUnited Kingdom\n492.2651\n102.15378\n\n\nGeorgia\n385.6145\n81.63218\n\n\nGreece\n445.4408\n88.95744\n\n\nGuatemala\n374.5886\n65.37109\n\n\nHong Kong (China)\n524.5497\n91.06857\n\n\nCroatia\n483.1283\n91.97320\n\n\nHungary\n492.1069\n94.69703\n\n\nIndonesia\n394.9906\n69.89182\n\n\nIreland\n504.3750\n91.95203\n\n\nIceland\n448.0546\n94.76950\n\n\nIsrael\n464.0777\n108.57084\n\n\nItaly\n481.3281\n91.97045\n\n\nJamaica\n395.7114\n91.97299\n\n\nJordan\n374.6990\n73.68470\n\n\nJapan\n545.5399\n92.72193\n\n\nKazakhstan\n440.9755\n84.44319\n\n\nCambodia\n340.4659\n50.34331\n\n\nKorea\n530.6552\n103.99342\n\n\nKosovo\n353.5723\n64.84509\n\n\nLithuania\n480.0535\n92.51359\n\n\nLatvia\n492.5822\n84.61410\n\n\nMacao (China)\n543.1331\n86.61414\n\n\nMorocco\n363.4098\n66.20574\n\n\nRepublic of Moldova\n416.8691\n82.50639\n\n\nMexico\n410.7969\n74.97042\n\n\nNorth Macedonia\n382.3574\n82.77203\n\n\nMalta\n469.8360\n101.83745\n\n\nMontenegro\n404.9706\n83.35015\n\n\nMongolia\n411.4142\n77.72520\n\n\nMalaysia\n417.1980\n77.85995\n\n\nNetherlands\n486.8380\n111.77833\n\n\nNorway\n478.9396\n106.09425\n\n\nNew Zealand\n504.8458\n107.85424\n\n\nPanama\n385.0859\n84.92427\n\n\nPeru\n410.8352\n85.35240\n\n\nPhilippines\n353.7724\n76.99187\n\n\nPoland\n505.1500\n94.16577\n\n\nPortugal\n488.2668\n89.70144\n\n\nParaguay\n371.6893\n74.52611\n\n\nPalestinian Authority\n367.0259\n70.91610\n\n\nQatar\n428.8246\n96.25937\n\n\nBaku (Azerbaijan)\n381.5571\n78.67151\n\n\nUkrainian regions (18 of 27)\n454.4918\n88.72635\n\n\nRomania\n436.4904\n96.24036\n\n\nSaudi Arabia\n390.1679\n72.21294\n\n\nSingapore\n560.8252\n99.60358\n\n\nEl Salvador\n374.9843\n73.44363\n\n\nSerbia\n446.7715\n88.26844\n\n\nSlovak Republic\n467.2694\n102.95534\n\n\nSlovenia\n487.1098\n93.85904\n\n\nSweden\n494.1717\n107.51162\n\n\nChinese Taipei\n526.8225\n102.25648\n\n\nThailand\n429.1863\n93.12958\n\n\nTürkiye\n476.0276\n89.06750\n\n\nUruguay\n433.2891\n92.41654\n\n\nUnited States\n498.2506\n108.85390\n\n\nUzbekistan\n355.3407\n63.34434\n\n\nViet Nam\n473.3375\n78.42436\n\n\n\n\n\n# Or to change the number of decimal places and a column name\n\ngt(science_mean_scores) %&gt;% tab_header(\n  title = \"Mean science scores\",\n  subtitle = \"PISA 2022 data\") %&gt;%\n  fmt_number(columns = c(mean_science_score , sd_science), decimals = 1) %&gt;%\n  cols_label(\"CNT\" = md(\"**Country**\"))\n\n\n\n\n\n\nMean science scores\n\n\nPISA 2022 data\n\n\nCountry\nmean_science_score\nsd_science\n\n\n\n\nAlbania\n375.9\n81.2\n\n\nUnited Arab Emirates\n436.0\n108.0\n\n\nArgentina\n415.1\n86.3\n\n\nAustralia\n507.8\n106.8\n\n\nAustria\n494.1\n99.1\n\n\nBelgium\n495.0\n99.9\n\n\nBulgaria\n422.0\n94.7\n\n\nBrazil\n406.3\n93.3\n\n\nBrunei Darussalam\n444.9\n93.5\n\n\nCanada\n499.5\n98.8\n\n\nSwitzerland\n501.4\n97.9\n\n\nChile\n463.1\n94.9\n\n\nColombia\n420.9\n88.2\n\n\nCosta Rica\n411.2\n80.4\n\n\nCzech Republic\n510.8\n102.8\n\n\nGermany\n495.3\n105.4\n\n\nDenmark\n480.3\n96.9\n\n\nDominican Republic\n361.6\n68.7\n\n\nSpain\n492.9\n90.1\n\n\nEstonia\n527.3\n87.7\n\n\nFinland\n498.0\n111.5\n\n\nFrance\n481.4\n105.7\n\n\nUnited Kingdom\n492.3\n102.2\n\n\nGeorgia\n385.6\n81.6\n\n\nGreece\n445.4\n89.0\n\n\nGuatemala\n374.6\n65.4\n\n\nHong Kong (China)\n524.5\n91.1\n\n\nCroatia\n483.1\n92.0\n\n\nHungary\n492.1\n94.7\n\n\nIndonesia\n395.0\n69.9\n\n\nIreland\n504.4\n92.0\n\n\nIceland\n448.1\n94.8\n\n\nIsrael\n464.1\n108.6\n\n\nItaly\n481.3\n92.0\n\n\nJamaica\n395.7\n92.0\n\n\nJordan\n374.7\n73.7\n\n\nJapan\n545.5\n92.7\n\n\nKazakhstan\n441.0\n84.4\n\n\nCambodia\n340.5\n50.3\n\n\nKorea\n530.7\n104.0\n\n\nKosovo\n353.6\n64.8\n\n\nLithuania\n480.1\n92.5\n\n\nLatvia\n492.6\n84.6\n\n\nMacao (China)\n543.1\n86.6\n\n\nMorocco\n363.4\n66.2\n\n\nRepublic of Moldova\n416.9\n82.5\n\n\nMexico\n410.8\n75.0\n\n\nNorth Macedonia\n382.4\n82.8\n\n\nMalta\n469.8\n101.8\n\n\nMontenegro\n405.0\n83.4\n\n\nMongolia\n411.4\n77.7\n\n\nMalaysia\n417.2\n77.9\n\n\nNetherlands\n486.8\n111.8\n\n\nNorway\n478.9\n106.1\n\n\nNew Zealand\n504.8\n107.9\n\n\nPanama\n385.1\n84.9\n\n\nPeru\n410.8\n85.4\n\n\nPhilippines\n353.8\n77.0\n\n\nPoland\n505.1\n94.2\n\n\nPortugal\n488.3\n89.7\n\n\nParaguay\n371.7\n74.5\n\n\nPalestinian Authority\n367.0\n70.9\n\n\nQatar\n428.8\n96.3\n\n\nBaku (Azerbaijan)\n381.6\n78.7\n\n\nUkrainian regions (18 of 27)\n454.5\n88.7\n\n\nRomania\n436.5\n96.2\n\n\nSaudi Arabia\n390.2\n72.2\n\n\nSingapore\n560.8\n99.6\n\n\nEl Salvador\n375.0\n73.4\n\n\nSerbia\n446.8\n88.3\n\n\nSlovak Republic\n467.3\n103.0\n\n\nSlovenia\n487.1\n93.9\n\n\nSweden\n494.2\n107.5\n\n\nChinese Taipei\n526.8\n102.3\n\n\nThailand\n429.2\n93.1\n\n\nTürkiye\n476.0\n89.1\n\n\nUruguay\n433.3\n92.4\n\n\nUnited States\n498.3\n108.9\n\n\nUzbekistan\n355.3\n63.3\n\n\nViet Nam\n473.3\n78.4\n\n\n\n\n\n## If you have an output from a linear model, there is an additional step to do before using gt\n# You need to use the broom package, which has the `tidy` function which gets the output of `lm`\n# Into a suitable format for turing into a table\n# install.packages(\"broom\")\n\nlibrary(broom)\n\n# Create example dataframe\n\nUK_PISA &lt;- PISA_2022 %&gt;%\n  select(PV1SCIE, PV1MATH, CNT) %&gt;%\n  filter(CNT == \"United Kingdom\")\n\n# Run the model\n\nuk_mod &lt;- lm(data = UK_PISA, PV1SCIE ~ PV1MATH)\n\n# tidy the model\n\nuk_mod_tidy &lt;- tidy(uk_mod)\n\n# pass to gt to produce nice output\n\ngt(uk_mod_tidy) %&gt;% \n  fmt_number(columns=c(\"p.value\"), \n              decimals = 3) %&gt;%\n  fmt_number(columns=c(\"estimate\", \"std.error\", \"statistic\"), \n              decimals = 2)\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n(Intercept)\n42.33\n2.30\n18.37\n0.000\n\n\nPV1MATH\n0.93\n0.00\n199.00\n0.000\n\n\n\n\n\n\n\nWhen you have run some tests, the outputs (for example the degrees of freedom, test statistic and p-value) should be formatted in your paper in line with the citation convention of the journal or assessment (for example, KCL assignments follow the American Psychological Association (APA) citation style). You can find a general guide to presenting your results in APA style here: APA numbers and statistics style guide.\nFor example, to report a chi-square result:\n\n# Create example dataframe\n\nUK_gender_differences &lt;- PISA_2022 %&gt;%\n  select(CNT, ST004D01T) %&gt;%\n  filter(CNT == \"United Kingdom\") %&gt;% \n  droplevels()\n\ncont_tab &lt;- xtabs(data = UK_gender_differences, ~ ST004D01T)\n\n# Run a chi sqaure goodness of fit test\n\nchisq.test(cont_tab, p = c(0.5, 0.5))\n\n\n    Chi-squared test for given probabilities\n\ndata:  cont_tab\nX-squared = 2.4425, df = 1, p-value = 0.1181\n\n\nA chi-square test of goodness-of-fit was conducted to compare the observed frequencies in the contingency table to the expected frequencies (equal numbers of boys and girls). The result was not statistically significant, χ²(1, N = 12973) = 2.44, p = .12, indicating no significant difference between the observed and expected frequencies.\nTo report a t-test of the mathematics scores of girls and boys in the UK:\n\n# Create example dataframe\n\nUK_PISA &lt;- PISA_2022 %&gt;%\n  select(PV1MATH, CNT, ST004D01T) %&gt;%\n  filter(CNT == \"United Kingdom\")\n\n# Run a t-test\n\nt.test(data = UK_PISA, PV1MATH ~ ST004D01T)\n\n\n    Welch Two Sample t-test\n\ndata:  PV1MATH by ST004D01T\nt = -8.2246, df = 12942, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means between group Female and group Male is not equal to 0\n95 percent confidence interval:\n -16.9470 -10.4238\nsample estimates:\nmean in group Female   mean in group Male \n            475.6061             489.2915 \n\n\nThe output of that test would be reported as follows:\nThe results of a Welch’s t-test indicated a statistically significant difference in mean mathematics scores between UK females (M = 475.61) and UK males (M = 489.29), t(12,942) = -8.22, p &lt; .001, 95% CI [-16.95, -10.42].\nAlternatively, consider the output of an anova to look at the difference in wealth scores between Finland, Norway, and Sweden:\n\n# Create example dataframe\n\nwealth_scores &lt;- PISA_2022 %&gt;%\n  select(HOMEPOS, CNT) %&gt;%\n  filter(CNT == \"Finland\" | CNT == \"Norway\" | CNT == \"Sweden\")\n\n# Run an anova and summarise\n\naov_out &lt;- aov(data = wealth_scores, HOMEPOS ~ CNT)\nsummary(aov_out)\n\n               Df Sum Sq Mean Sq F value Pr(&gt;F)    \nCNT             2    575  287.61   356.7 &lt;2e-16 ***\nResiduals   22335  18008    0.81                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n584 observations deleted due to missingness\n\nTukeyHSD(aov_out)\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = HOMEPOS ~ CNT, data = wealth_scores)\n\n$CNT\n                     diff        lwr        upr p adj\nNorway-Finland  0.3846629  0.3508747  0.4184511     0\nSweden-Finland  0.1645141  0.1301168  0.1989114     0\nSweden-Norway  -0.2201488 -0.2581530 -0.1821445     0\n\n\nA one-way ANOVA was conducted to compare levels of home possessions (HOMEPOS) across three countries (CNT: Finland, Norway, and Sweden). The analysis revealed a statistically significant effect of country on home possessions, F(2, 22,335) = 356.7, p &lt; .001, η² = .031.\nPost hoc Tukey’s HSD tests indicated the following pairwise differences:\nNorway had significantly higher HOMEPOS scores than Finland (M difference = 0.38, 95% CI [0.35, 0.42], p &lt; .001). Sweden had significantly higher HOMEPOS scores than Finland (M difference = 0.16, 95% CI [0.13, 0.20], p &lt; .001). Sweden had significantly lower HOMEPOS scores than Norway (M difference = -0.22, 95% CI [-0.26, -0.18], p &lt; .001). A total of 584 observations were excluded due to missing data.\nAlternatively, you can use the report function in the easystats package to give a summary of an output.\n\nlibrary(easystats)\n\n# Get a summary of an anova\n\nreport(aov_out)\n\nThe ANOVA (formula: HOMEPOS ~ CNT) suggests that:\n\n  - The main effect of CNT is statistically significant and small (F(2, 22335) =\n356.72, p &lt; .001; Eta2 = 0.03, 95% CI [0.03, 1.00])\n\nEffect sizes were labelled following Field's (2013) recommendations.\n\n# And of a linear model\n\nmod1 &lt;- lm(data = wealth_scores, HOMEPOS ~ CNT)\n\nreport(mod1)\n\nWe fitted a linear model (estimated using OLS) to predict HOMEPOS with CNT\n(formula: HOMEPOS ~ CNT). The model explains a statistically significant and\nweak proportion of variance (R2 = 0.03, F(2, 22335) = 356.72, p &lt; .001, adj. R2\n= 0.03). The model's intercept, corresponding to CNT = Albania, is at 0.16 (95%\nCI [0.14, 0.18], t(22335) = 18.13, p &lt; .001). Within this model:\n\n  - The effect of CNT [Norway] is statistically significant and positive (beta =\n0.38, 95% CI [0.36, 0.41], t(22335) = 26.68, p &lt; .001; Std. beta = 0.42, 95% CI\n[0.39, 0.45])\n  - The effect of CNT [Sweden] is statistically significant and positive (beta =\n0.16, 95% CI [0.14, 0.19], t(22335) = 11.21, p &lt; .001; Std. beta = 0.18, 95% CI\n[0.15, 0.21])\n\nStandardized parameters were obtained by fitting the model on a standardized\nversion of the dataset. 95% Confidence Intervals (CIs) and p-values were\ncomputed using a Wald t-distribution approximation.\n\n\nThe report function will work on other test outputs, for example, on a t-test:\n\n# Create example data frame\n\nUK_PISA &lt;- PISA_2022 %&gt;%\n  select(PV1MATH, CNT, ST004D01T) %&gt;%\n  filter(CNT == \"United Kingdom\") %&gt;%\n  droplevels()\n\n# Use report on a t-test\n\nreport(t.test(data = UK_PISA, PV1MATH ~ ST004D01T))\n\nEffect sizes were labelled following Cohen's (1988) recommendations.\n\nThe Welch Two Sample t-test testing the difference of PV1MATH by ST004D01T\n(mean in group Female = 475.61, mean in group Male = 489.29) suggests that the\neffect is negative, statistically significant, and very small (difference =\n-13.69, 95% CI [-16.95, -10.42], t(12942.17) = -8.22, p &lt; .001; Cohen's d =\n-0.14, 95% CI [-0.18, -0.11])\n\n\nTo produce tables in APA format, you can use the apa.aov.table (for anovas) or apa.reg.table (for linear model outputs) functions from the apaTables package. You will need to install the package first using install.packages(\"apaTables\").\n\nlibrary(apaTables)\n\n# Get a summary table from an anova\n\napa.aov.table(aov_out)\n\n\n\nANOVA results using HOMEPOS as the dependent variable\n \n\n   Predictor       SS    df     MS      F    p partial_eta2 CI_90_partial_eta2\n (Intercept)   264.91     1 264.91 328.56 .000                                \n         CNT   575.22     2 287.61 356.72 .000          .03         [.03, .03]\n       Error 18007.84 22335   0.81                                            \n\nNote: Values in square brackets indicate the bounds of the 90% confidence interval for partial eta-squared \n\n# And of a linear model\n\napa.reg.table(mod1)\n\n\n\nRegression results using HOMEPOS as the criterion\n \n\n   Predictor      b     b_95%_CI sr2 sr2_95%_CI             Fit\n (Intercept) 0.16** [0.14, 0.18]                               \n   CNTNorway 0.38** [0.36, 0.41] .03 [.03, .04]                \n   CNTSweden 0.16** [0.14, 0.19] .01 [.00, .01]                \n                                                    R2 = .031**\n                                                95% CI[.03,.04]\n                                                               \n\nNote. A significant b-weight indicates the semi-partial correlation is also significant.\nb represents unstandardized regression weights. \nsr2 represents the semi-partial correlation squared.\nSquare brackets are used to enclose the lower and upper limits of a confidence interval.\n* indicates p &lt; .05. ** indicates p &lt; .01.\n \n\n\nYou can get more aesthetically pleasing versions of both tables using the gt function in the gt package. Before passing the outputs of avo of lm to gt, you will need to use the tidy fucntion from the broom package to tidy the output.\n\nlibrary(gt)\nlibrary(broom)\n\n# Tidy the outputs\n\ntidied_aov &lt;- tidy(aov_out)\ntidied_mod1 &lt;- tidy(mod1)\n\n\n# Produced a nicely formatted table from an anova\n\ngt(tidied_aov)\n\n\n\n\n\nterm\ndf\nsumsq\nmeansq\nstatistic\np.value\n\n\n\nCNT\n2\n575.2171\n287.6085570\n356.719\n3.175047e-153\n\n\nResiduals\n22335\n18007.8370\n0.8062609\nNA\nNA\n\n\n\n\n\n# And of a linear model\n\ngt(tidied_mod1)\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n(Intercept)\n0.1622658\n0.008951941\n18.12632\n6.584384e-73\n\n\nCNTNorway\n0.3846629\n0.014415658\n26.68369\n1.915252e-154\n\n\nCNTSweden\n0.1645141\n0.014675508\n11.21011\n4.349919e-29\n\n\n\n\n\n\n\nThere are a number of helpful packages that can add data to charts. First ggpubr lets you add data about the regression line to your plot using the stat_regline_equation() function. You will need to tweak the coordinates (label.x and label.y) to appear appropiately on your chart.\n\n# Load the ggpbur library (you will need to run install.packages(\"ggpubr\") the first time you use it)\nlibrary(ggpubr)\n\n# Create example dataframe\n\nUK_wealth_reading &lt;- PISA_2022 %&gt;%\n  select(CNT, PV1READ, HOMEPOS) %&gt;%\n  filter(CNT == \"United Kingdom\") \n\n# Plot a scatter plot with the regression equation\n\nggplot(UK_wealth_reading, aes(x = HOMEPOS, y = PV1READ)) +\n  geom_point(colour = \"lightgreen\", size = 0.1) +\n  geom_smooth(method = \"lm\") +\n  stat_regline_equation(label.x = -5, label.y = 600)  # Add regression equation\n\n\n\n\n\n\n\nYou can also use stat_regline_equation to add additional information like the p-value of the model and the R2 value:\n\n# Load the ggpbur library (you will need to run install.packages(\"ggpubr\") the first time you use it)\nlibrary(ggpubr)\n\n# Create example dataframe\n\nUK_wealth_reading &lt;- PISA_2022 %&gt;%\n  select(CNT, PV1READ, HOMEPOS) %&gt;%\n  filter(CNT == \"United Kingdom\") \n\n# Plot a scatter plot with the regression equation\n\nggplot(UK_wealth_reading, aes(x = HOMEPOS, y = PV1READ)) +\n  geom_point(colour = \"lightgreen\", size = 0.1) +\n  geom_smooth(method = \"lm\", formula = y ~ x) + # Ensure formula is specified here too\n  stat_regline_equation(\n    aes(label = paste(..eq.label.., ..adj.rr.label.., sep = \"~~~~\")), # Indicate you want the equation and R2 value and the seperator text\n    label.x = -10, label.y = 600,\n    formula = y ~ x)\n\n\n\n\n\n\n\nAnother powerful package for adding data to graphs is ggstatsplot. For example, it can anotate a plot with anova data. For example, if you want compare the science scores of the UK, Japan and the US:\n\n# Load the ggstatplot library (you will need to run install.packages(\"ggstatsplot\") the first time you use it)\nlibrary(ggstatsplot)\n\n# Create example dataframe\n\ncountry_sci_data &lt;- PISA_2022 %&gt;%\n  select(CNT, PV1SCIE) %&gt;%\n  filter(CNT == \"United Kingdom\" | CNT == \"Japan\" | CNT == \"United States\")\n\n# Use ggstatplot to create an annotated plot with an anova result\n\nggbetweenstats(\n  data  = country_sci_data,\n  x     = CNT,\n  y     = PV1SCIE,\n  title = \"Science scores in the UK, US and Japan\",\n  type  = \"parametric\" # Forces the test to be ANOVA\n)\n\n\n\n\n\n\n\n\nYou can use the gt package to convert data frames to aesthetically pleasing outputs.\n\n# load the gt package - you will need to run install.packages(\"gt\") the first time\n# install.packages(\"gt\")\nlibrary(gt)\n\n# Make the data frame you want you want to output\nscience_mean_scores &lt;- PISA_2022 %&gt;%\n  group_by(CNT) %&gt;%\n  summarise(mean_science_score = mean(PV1SCIE, na.rm = TRUE),\n            sd_science = sd(PV1SCIE, na.rm =TRUE)) %&gt;%\n  filter(CNT == \"United Kingdom\" | CNT == \"United States\" | CNT == \"Germany\")\n\n# Use gt to produce an output - you can copy and paste the table from the\n# viewer window to your report\n\ngt(science_mean_scores)\n\n\n\n\n\nCountry code 3-character\nmean_science_score\nsd_science\n\n\n\nGermany\n495.2547\n105.4208\n\n\nUnited Kingdom\n492.2651\n102.1538\n\n\nUnited States\n498.2506\n108.8539\n\n\n\n\n\n# You can see more options on formatting the table here: https://gt.rstudio.com\n# For example to add a heading\n\ngt(science_mean_scores) %&gt;% tab_header(\n    title = \"Mean science scores\",\n    subtitle = \"PISA 2022 data\")\n\n\n\n\n\n\nMean science scores\n\n\nPISA 2022 data\n\n\nCountry code 3-character\nmean_science_score\nsd_science\n\n\n\n\nGermany\n495.2547\n105.4208\n\n\nUnited Kingdom\n492.2651\n102.1538\n\n\nUnited States\n498.2506\n108.8539\n\n\n\n\n\n# Or to change the number of decimal places and a column name\n\ngt(science_mean_scores) %&gt;% tab_header(\n  title = \"Mean science scores\",\n  subtitle = \"PISA 2022 data\") %&gt;%\n  fmt_number(columns = c(mean_science_score , sd_science), decimals = 1) %&gt;%\n  cols_label(\"CNT\" = md(\"**Country**\")) # Here the **Country** makes Country bold\n\n\n\n\n\n\nMean science scores\n\n\nPISA 2022 data\n\n\nCountry\nmean_science_score\nsd_science\n\n\n\n\nGermany\n495.3\n105.4\n\n\nUnited Kingdom\n492.3\n102.2\n\n\nUnited States\n498.3\n108.9\n\n\n\n\n\n\n\n## If you have an output from a linear model, there is an additional step to do before using gt\n# You need to use the broom package, which has the `tidy` function which gets the output of `lm`\n# Into a suitable format for turing into a table\n# install.packages(\"broom\")\n\nlibrary(broom)\n\n# Create example dataframe\n\nUK_PISA &lt;- PISA_2022 %&gt;%\n  select(PV1SCIE, PV1MATH, CNT) %&gt;%\n  filter(CNT == \"United Kingdom\")\n\n# Run the model\n\nuk_mod &lt;- lm(data = UK_PISA, PV1SCIE ~ PV1MATH)\n\n# tidy the model\n\nuk_mod_tidy &lt;- tidy(uk_mod)\n\n# pass to gt to produce nice output\n\ngt(uk_mod_tidy)\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n(Intercept)\n42.3335278\n2.304412214\n18.37064\n1.978594e-74\n\n\nPV1MATH\n0.9324181\n0.004685464\n199.00232\n0.000000e+00\n\n\n\n\n\n\n\nggplot will use a default palette - you can sometimes identify plots in papers as being produced by ggplot from the distinctive green and pink colour! If you want to move away from these, you can use the scale_fill_manual and scale_colour_manual functions.\nFor example, if you have a bar graph of the number of boys and girls in the UK, you can change the fill colours using scale_fill_manual and defining the colours for the categories (in this case Male and Female).\n\nUK_PISA &lt;- PISA_2022 %&gt;%\n  select(ST004D01T, CNT) %&gt;%\n  filter(CNT == \"United Kingdom\")\n\nggplot(UK_PISA, aes(x = ST004D01T, fill = ST004D01T)) +\n  geom_bar() +\n  scale_fill_manual(values = c(\"Male\" = \"orange\", \"Female\" = \"lightblue\"))  # manually set the values for male and female\n\n\n\n\n\n\n\nYou need to match the scale manual command to the aesthetic you want to change. For example, when using geom_point you use the colour aesthetic to change the colour of points. In that case, you use scale_colour_manual.\n\nUK_PISA &lt;- PISA_2022 %&gt;%\n  select(ST004D01T, CNT, PV1SCIE, PV1MATH) %&gt;%\n  filter(CNT == \"United Kingdom\")\n\nggplot(UK_PISA, aes(x = PV1MATH, y = PV1SCIE, colour = ST004D01T)) +\n  geom_point(size = 0.1, alpha = 0.6) +\n  scale_colour_manual(values = c(\"Male\" = \"lightgreen\", \"Female\" = \"red\")) # manually set the colour values for male and female",
    "crumbs": [
      "Appendicies",
      "Questions and Answers"
    ]
  },
  {
    "objectID": "chapters/A6-QandA.html#why-doesnt-my-selectfilter-statement-work",
    "href": "chapters/A6-QandA.html#why-doesnt-my-selectfilter-statement-work",
    "title": "Questions and Answers",
    "section": "",
    "text": "When you are loading packages, sometimes different packages have the same function names in them, and the functions themselves will do very different things. For example, there is a select function in the tidyverse, but also another select function in the package MASS that does something very different. If we load the tidyverse before loading MASS, then the MASS version of select is the one that will be used?!\n\nlibrary(tidyverse)\nlibrary(MASS)\n\ndiamonds %&gt;% select(carat, cut, color)\n\nTo get around this make sure that you load the tidyverse after MASS, to be safe you should always load the tidyverse last.\n\nlibrary(MASS) \nlibrary(tidyverse)\n\ndiamonds %&gt;% select(carat, cut, color)\n\n# A tibble: 53,940 × 3\n   carat cut       color\n   &lt;dbl&gt; &lt;ord&gt;     &lt;ord&gt;\n 1  0.23 Ideal     E    \n 2  0.21 Premium   E    \n 3  0.23 Good      E    \n 4  0.29 Premium   I    \n 5  0.31 Good      J    \n 6  0.24 Very Good J    \n 7  0.24 Very Good I    \n 8  0.26 Very Good H    \n 9  0.22 Fair      E    \n10  0.23 Very Good H    \n# ℹ 53,930 more rows\n\n\nyou can also specify the package that select comes from (in this case from a package within the tidyverse called dplyr):\n\ndiamonds %&gt;% dplyr::select(carat, cut, color)\n\n# A tibble: 53,940 × 3\n   carat cut       color\n   &lt;dbl&gt; &lt;ord&gt;     &lt;ord&gt;\n 1  0.23 Ideal     E    \n 2  0.21 Premium   E    \n 3  0.23 Good      E    \n 4  0.29 Premium   I    \n 5  0.31 Good      J    \n 6  0.24 Very Good J    \n 7  0.24 Very Good I    \n 8  0.26 Very Good H    \n 9  0.22 Fair      E    \n10  0.23 Very Good H    \n# ℹ 53,930 more rows\n\n\nFinally, there is a package that helps your deal with conflicts called conflicted. At the top of your script you can define which version of a function you prefer, this will be the version that will always be used. If you want to specify another version of a function, you can still use other versions of the function using the :: notation:\n\nlibrary(conflicted)\nconflicts_prefer(dplyr::select)\nconflicts_prefer(dplyr::mutate)\nconflicts_prefer(dplyr::summarise)\nconflicts_prefer(dplyr::filter)\n\ndf %&gt;% select(name, age) # uses select from dplyr\ndf %&gt;% MASS::select(name) # uses select from MASS\n\nTo find out if you have any conflicts, you can run conflict_scout().",
    "crumbs": [
      "Appendicies",
      "Questions and Answers"
    ]
  },
  {
    "objectID": "chapters/A6-QandA.html#how-can-i-unload-packages",
    "href": "chapters/A6-QandA.html#how-can-i-unload-packages",
    "title": "Questions and Answers",
    "section": "",
    "text": "If you are finding yourself with a conflict as mentioned above and want to unload packages, then you need to run the following code:\n\n# adapted from: @mmfrgmpds https://stackoverflow.com/questions/7505547/detach-all-packages-while-working-in-r\nwhile(!is.null(sessionInfo()$loadedOnly)){\n  lapply(names(sessionInfo()$loadedOnly), require, character.only = TRUE)\n  invisible(lapply(paste0('package:', names(sessionInfo()$otherPkgs)), detach, character.only=TRUE, unload=TRUE, force=TRUE))    \n}",
    "crumbs": [
      "Appendicies",
      "Questions and Answers"
    ]
  },
  {
    "objectID": "chapters/A6-QandA.html#why-am-i-getting-the-error-could-not-find-function",
    "href": "chapters/A6-QandA.html#why-am-i-getting-the-error-could-not-find-function",
    "title": "Questions and Answers",
    "section": "",
    "text": "The pipe operator %&gt;% is loaded when you load the tidyverse package - make sure you have installed tidyverse and loaded it\n\ninstall.packages(\"tidyverse\")  # install\nlibrary(tidyverse)             # load",
    "crumbs": [
      "Appendicies",
      "Questions and Answers"
    ]
  },
  {
    "objectID": "chapters/A6-QandA.html#i-am-getting-the-error-error-mapping-should-be-created-with-aes-or-aes_.-when-using-ggplot",
    "href": "chapters/A6-QandA.html#i-am-getting-the-error-error-mapping-should-be-created-with-aes-or-aes_.-when-using-ggplot",
    "title": "Questions and Answers",
    "section": "",
    "text": "This may be caused by having a bracket after the geom rather than before it\n\ndata&lt;-data.frame(x=5:1,\n                 y=10:6)\nggplot(data, aes(x, y) +           # Reproduce error message\n         geom_point())\n\n\ndata&lt;-data.frame(x=5:1,\n                 y=10:6)\nggplot(data, aes(x, y)) +           # Fixed error by moving bracket\n         geom_point()",
    "crumbs": [
      "Appendicies",
      "Questions and Answers"
    ]
  },
  {
    "objectID": "chapters/A6-QandA.html#my-axis-labels-are-too-long",
    "href": "chapters/A6-QandA.html#my-axis-labels-are-too-long",
    "title": "Questions and Answers",
    "section": "",
    "text": "If you want to use long axis titles you may find they overrun the space available\n\n# Make a sample data frame\ndata&lt;-data.frame(x=5:1,\n                 y=10:6)\n\n# plot the data\nggplot(data, aes(x=x, y=y)) +           \n         geom_col()+\n  ylab(\"A very long description for the y-axis label that will overflow and not look very nice\")\n\n\n\n\n\n\n\nTo insert a line break in the axis label, add \\n to the text where you want line breaks.\n\n# Make a sample data frame\ndata&lt;-data.frame(x=5:1,\n                 y=10:6)\n\n# plot the data\nggplot(data, aes(x=x, y=y)) +           \n         geom_col()+\n  ylab(\"A very long description \\n for the y-axis label that will \\n overflow and not look very nice\")",
    "crumbs": [
      "Appendicies",
      "Questions and Answers"
    ]
  },
  {
    "objectID": "chapters/A6-QandA.html#how-can-i-find-out-the-full-item-labels-in-the-pisa-data-frame",
    "href": "chapters/A6-QandA.html#how-can-i-find-out-the-full-item-labels-in-the-pisa-data-frame",
    "title": "Questions and Answers",
    "section": "",
    "text": "The code below will give you a list of all the item labels\n\n# You may want to set the maximun print output to see all the labels\noptions(max.print = 1300)\n\nlapply(PISA_2022, attr, \"label\")",
    "crumbs": [
      "Appendicies",
      "Questions and Answers"
    ]
  },
  {
    "objectID": "chapters/A6-QandA.html#how-do-i-turn-a-data-frame-into-a-form-i-can-put-into-an-assignment-or-paper",
    "href": "chapters/A6-QandA.html#how-do-i-turn-a-data-frame-into-a-form-i-can-put-into-an-assignment-or-paper",
    "title": "Questions and Answers",
    "section": "",
    "text": "You can use the gt package to convert data frames to aesthetically pleasing outputs.\n\n# load the gt package - you will need to run install.packages(\"gt\") the first time\n# install.packages(\"gt\")\nlibrary(gt)\n\n# Make the data frame you want you want to output\nscience_mean_scores &lt;- PISA_2022 %&gt;%\n  group_by(CNT) %&gt;%\n  summarise(mean_science_score = mean(PV1SCIE, na.rm = TRUE),\n            sd_science = sd(PV1SCIE, na.rm =TRUE))\n\n# Use gt to produce an output - you can copy and paste the table from the\n# viewer window to your report\n\ngt(science_mean_scores)\n\n\n\n\n\nCountry code 3-character\nmean_science_score\nsd_science\n\n\n\nAlbania\n375.8650\n81.17499\n\n\nUnited Arab Emirates\n435.9609\n108.04562\n\n\nArgentina\n415.0584\n86.30466\n\n\nAustralia\n507.7795\n106.78340\n\n\nAustria\n494.0894\n99.10689\n\n\nBelgium\n495.0015\n99.89222\n\n\nBulgaria\n421.9872\n94.68480\n\n\nBrazil\n406.3370\n93.33488\n\n\nBrunei Darussalam\n444.8849\n93.49958\n\n\nCanada\n499.4697\n98.78625\n\n\nSwitzerland\n501.4123\n97.88277\n\n\nChile\n463.1057\n94.91051\n\n\nColombia\n420.9458\n88.24887\n\n\nCosta Rica\n411.2082\n80.40614\n\n\nCzech Republic\n510.7872\n102.76484\n\n\nGermany\n495.2547\n105.42084\n\n\nDenmark\n480.3369\n96.87209\n\n\nDominican Republic\n361.6200\n68.71457\n\n\nSpain\n492.9236\n90.06178\n\n\nEstonia\n527.3109\n87.67284\n\n\nFinland\n497.9649\n111.47589\n\n\nFrance\n481.3834\n105.72320\n\n\nUnited Kingdom\n492.2651\n102.15378\n\n\nGeorgia\n385.6145\n81.63218\n\n\nGreece\n445.4408\n88.95744\n\n\nGuatemala\n374.5886\n65.37109\n\n\nHong Kong (China)\n524.5497\n91.06857\n\n\nCroatia\n483.1283\n91.97320\n\n\nHungary\n492.1069\n94.69703\n\n\nIndonesia\n394.9906\n69.89182\n\n\nIreland\n504.3750\n91.95203\n\n\nIceland\n448.0546\n94.76950\n\n\nIsrael\n464.0777\n108.57084\n\n\nItaly\n481.3281\n91.97045\n\n\nJamaica\n395.7114\n91.97299\n\n\nJordan\n374.6990\n73.68470\n\n\nJapan\n545.5399\n92.72193\n\n\nKazakhstan\n440.9755\n84.44319\n\n\nCambodia\n340.4659\n50.34331\n\n\nKorea\n530.6552\n103.99342\n\n\nKosovo\n353.5723\n64.84509\n\n\nLithuania\n480.0535\n92.51359\n\n\nLatvia\n492.5822\n84.61410\n\n\nMacao (China)\n543.1331\n86.61414\n\n\nMorocco\n363.4098\n66.20574\n\n\nRepublic of Moldova\n416.8691\n82.50639\n\n\nMexico\n410.7969\n74.97042\n\n\nNorth Macedonia\n382.3574\n82.77203\n\n\nMalta\n469.8360\n101.83745\n\n\nMontenegro\n404.9706\n83.35015\n\n\nMongolia\n411.4142\n77.72520\n\n\nMalaysia\n417.1980\n77.85995\n\n\nNetherlands\n486.8380\n111.77833\n\n\nNorway\n478.9396\n106.09425\n\n\nNew Zealand\n504.8458\n107.85424\n\n\nPanama\n385.0859\n84.92427\n\n\nPeru\n410.8352\n85.35240\n\n\nPhilippines\n353.7724\n76.99187\n\n\nPoland\n505.1500\n94.16577\n\n\nPortugal\n488.2668\n89.70144\n\n\nParaguay\n371.6893\n74.52611\n\n\nPalestinian Authority\n367.0259\n70.91610\n\n\nQatar\n428.8246\n96.25937\n\n\nBaku (Azerbaijan)\n381.5571\n78.67151\n\n\nUkrainian regions (18 of 27)\n454.4918\n88.72635\n\n\nRomania\n436.4904\n96.24036\n\n\nSaudi Arabia\n390.1679\n72.21294\n\n\nSingapore\n560.8252\n99.60358\n\n\nEl Salvador\n374.9843\n73.44363\n\n\nSerbia\n446.7715\n88.26844\n\n\nSlovak Republic\n467.2694\n102.95534\n\n\nSlovenia\n487.1098\n93.85904\n\n\nSweden\n494.1717\n107.51162\n\n\nChinese Taipei\n526.8225\n102.25648\n\n\nThailand\n429.1863\n93.12958\n\n\nTürkiye\n476.0276\n89.06750\n\n\nUruguay\n433.2891\n92.41654\n\n\nUnited States\n498.2506\n108.85390\n\n\nUzbekistan\n355.3407\n63.34434\n\n\nViet Nam\n473.3375\n78.42436\n\n\n\n\n\n# You can see more options on formating the table here: https://gt.rstudio.com\n# For example to add a heading\n\ngt(science_mean_scores) %&gt;% tab_header(\n    title = \"Mean science scores\",\n    subtitle = \"PISA 2022 data\")\n\n\n\n\n\n\nMean science scores\n\n\nPISA 2022 data\n\n\nCountry code 3-character\nmean_science_score\nsd_science\n\n\n\n\nAlbania\n375.8650\n81.17499\n\n\nUnited Arab Emirates\n435.9609\n108.04562\n\n\nArgentina\n415.0584\n86.30466\n\n\nAustralia\n507.7795\n106.78340\n\n\nAustria\n494.0894\n99.10689\n\n\nBelgium\n495.0015\n99.89222\n\n\nBulgaria\n421.9872\n94.68480\n\n\nBrazil\n406.3370\n93.33488\n\n\nBrunei Darussalam\n444.8849\n93.49958\n\n\nCanada\n499.4697\n98.78625\n\n\nSwitzerland\n501.4123\n97.88277\n\n\nChile\n463.1057\n94.91051\n\n\nColombia\n420.9458\n88.24887\n\n\nCosta Rica\n411.2082\n80.40614\n\n\nCzech Republic\n510.7872\n102.76484\n\n\nGermany\n495.2547\n105.42084\n\n\nDenmark\n480.3369\n96.87209\n\n\nDominican Republic\n361.6200\n68.71457\n\n\nSpain\n492.9236\n90.06178\n\n\nEstonia\n527.3109\n87.67284\n\n\nFinland\n497.9649\n111.47589\n\n\nFrance\n481.3834\n105.72320\n\n\nUnited Kingdom\n492.2651\n102.15378\n\n\nGeorgia\n385.6145\n81.63218\n\n\nGreece\n445.4408\n88.95744\n\n\nGuatemala\n374.5886\n65.37109\n\n\nHong Kong (China)\n524.5497\n91.06857\n\n\nCroatia\n483.1283\n91.97320\n\n\nHungary\n492.1069\n94.69703\n\n\nIndonesia\n394.9906\n69.89182\n\n\nIreland\n504.3750\n91.95203\n\n\nIceland\n448.0546\n94.76950\n\n\nIsrael\n464.0777\n108.57084\n\n\nItaly\n481.3281\n91.97045\n\n\nJamaica\n395.7114\n91.97299\n\n\nJordan\n374.6990\n73.68470\n\n\nJapan\n545.5399\n92.72193\n\n\nKazakhstan\n440.9755\n84.44319\n\n\nCambodia\n340.4659\n50.34331\n\n\nKorea\n530.6552\n103.99342\n\n\nKosovo\n353.5723\n64.84509\n\n\nLithuania\n480.0535\n92.51359\n\n\nLatvia\n492.5822\n84.61410\n\n\nMacao (China)\n543.1331\n86.61414\n\n\nMorocco\n363.4098\n66.20574\n\n\nRepublic of Moldova\n416.8691\n82.50639\n\n\nMexico\n410.7969\n74.97042\n\n\nNorth Macedonia\n382.3574\n82.77203\n\n\nMalta\n469.8360\n101.83745\n\n\nMontenegro\n404.9706\n83.35015\n\n\nMongolia\n411.4142\n77.72520\n\n\nMalaysia\n417.1980\n77.85995\n\n\nNetherlands\n486.8380\n111.77833\n\n\nNorway\n478.9396\n106.09425\n\n\nNew Zealand\n504.8458\n107.85424\n\n\nPanama\n385.0859\n84.92427\n\n\nPeru\n410.8352\n85.35240\n\n\nPhilippines\n353.7724\n76.99187\n\n\nPoland\n505.1500\n94.16577\n\n\nPortugal\n488.2668\n89.70144\n\n\nParaguay\n371.6893\n74.52611\n\n\nPalestinian Authority\n367.0259\n70.91610\n\n\nQatar\n428.8246\n96.25937\n\n\nBaku (Azerbaijan)\n381.5571\n78.67151\n\n\nUkrainian regions (18 of 27)\n454.4918\n88.72635\n\n\nRomania\n436.4904\n96.24036\n\n\nSaudi Arabia\n390.1679\n72.21294\n\n\nSingapore\n560.8252\n99.60358\n\n\nEl Salvador\n374.9843\n73.44363\n\n\nSerbia\n446.7715\n88.26844\n\n\nSlovak Republic\n467.2694\n102.95534\n\n\nSlovenia\n487.1098\n93.85904\n\n\nSweden\n494.1717\n107.51162\n\n\nChinese Taipei\n526.8225\n102.25648\n\n\nThailand\n429.1863\n93.12958\n\n\nTürkiye\n476.0276\n89.06750\n\n\nUruguay\n433.2891\n92.41654\n\n\nUnited States\n498.2506\n108.85390\n\n\nUzbekistan\n355.3407\n63.34434\n\n\nViet Nam\n473.3375\n78.42436\n\n\n\n\n\n# Or to change the number of decimal places and a column name\n\ngt(science_mean_scores) %&gt;% tab_header(\n  title = \"Mean science scores\",\n  subtitle = \"PISA 2022 data\") %&gt;%\n  fmt_number(columns = c(mean_science_score , sd_science), decimals = 1) %&gt;%\n  cols_label(\"CNT\" = md(\"**Country**\"))\n\n\n\n\n\n\nMean science scores\n\n\nPISA 2022 data\n\n\nCountry\nmean_science_score\nsd_science\n\n\n\n\nAlbania\n375.9\n81.2\n\n\nUnited Arab Emirates\n436.0\n108.0\n\n\nArgentina\n415.1\n86.3\n\n\nAustralia\n507.8\n106.8\n\n\nAustria\n494.1\n99.1\n\n\nBelgium\n495.0\n99.9\n\n\nBulgaria\n422.0\n94.7\n\n\nBrazil\n406.3\n93.3\n\n\nBrunei Darussalam\n444.9\n93.5\n\n\nCanada\n499.5\n98.8\n\n\nSwitzerland\n501.4\n97.9\n\n\nChile\n463.1\n94.9\n\n\nColombia\n420.9\n88.2\n\n\nCosta Rica\n411.2\n80.4\n\n\nCzech Republic\n510.8\n102.8\n\n\nGermany\n495.3\n105.4\n\n\nDenmark\n480.3\n96.9\n\n\nDominican Republic\n361.6\n68.7\n\n\nSpain\n492.9\n90.1\n\n\nEstonia\n527.3\n87.7\n\n\nFinland\n498.0\n111.5\n\n\nFrance\n481.4\n105.7\n\n\nUnited Kingdom\n492.3\n102.2\n\n\nGeorgia\n385.6\n81.6\n\n\nGreece\n445.4\n89.0\n\n\nGuatemala\n374.6\n65.4\n\n\nHong Kong (China)\n524.5\n91.1\n\n\nCroatia\n483.1\n92.0\n\n\nHungary\n492.1\n94.7\n\n\nIndonesia\n395.0\n69.9\n\n\nIreland\n504.4\n92.0\n\n\nIceland\n448.1\n94.8\n\n\nIsrael\n464.1\n108.6\n\n\nItaly\n481.3\n92.0\n\n\nJamaica\n395.7\n92.0\n\n\nJordan\n374.7\n73.7\n\n\nJapan\n545.5\n92.7\n\n\nKazakhstan\n441.0\n84.4\n\n\nCambodia\n340.5\n50.3\n\n\nKorea\n530.7\n104.0\n\n\nKosovo\n353.6\n64.8\n\n\nLithuania\n480.1\n92.5\n\n\nLatvia\n492.6\n84.6\n\n\nMacao (China)\n543.1\n86.6\n\n\nMorocco\n363.4\n66.2\n\n\nRepublic of Moldova\n416.9\n82.5\n\n\nMexico\n410.8\n75.0\n\n\nNorth Macedonia\n382.4\n82.8\n\n\nMalta\n469.8\n101.8\n\n\nMontenegro\n405.0\n83.4\n\n\nMongolia\n411.4\n77.7\n\n\nMalaysia\n417.2\n77.9\n\n\nNetherlands\n486.8\n111.8\n\n\nNorway\n478.9\n106.1\n\n\nNew Zealand\n504.8\n107.9\n\n\nPanama\n385.1\n84.9\n\n\nPeru\n410.8\n85.4\n\n\nPhilippines\n353.8\n77.0\n\n\nPoland\n505.1\n94.2\n\n\nPortugal\n488.3\n89.7\n\n\nParaguay\n371.7\n74.5\n\n\nPalestinian Authority\n367.0\n70.9\n\n\nQatar\n428.8\n96.3\n\n\nBaku (Azerbaijan)\n381.6\n78.7\n\n\nUkrainian regions (18 of 27)\n454.5\n88.7\n\n\nRomania\n436.5\n96.2\n\n\nSaudi Arabia\n390.2\n72.2\n\n\nSingapore\n560.8\n99.6\n\n\nEl Salvador\n375.0\n73.4\n\n\nSerbia\n446.8\n88.3\n\n\nSlovak Republic\n467.3\n103.0\n\n\nSlovenia\n487.1\n93.9\n\n\nSweden\n494.2\n107.5\n\n\nChinese Taipei\n526.8\n102.3\n\n\nThailand\n429.2\n93.1\n\n\nTürkiye\n476.0\n89.1\n\n\nUruguay\n433.3\n92.4\n\n\nUnited States\n498.3\n108.9\n\n\nUzbekistan\n355.3\n63.3\n\n\nViet Nam\n473.3\n78.4\n\n\n\n\n\n## If you have an output from a linear model, there is an additional step to do before using gt\n# You need to use the broom package, which has the `tidy` function which gets the output of `lm`\n# Into a suitable format for turing into a table\n# install.packages(\"broom\")\n\nlibrary(broom)\n\n# Create example dataframe\n\nUK_PISA &lt;- PISA_2022 %&gt;%\n  select(PV1SCIE, PV1MATH, CNT) %&gt;%\n  filter(CNT == \"United Kingdom\")\n\n# Run the model\n\nuk_mod &lt;- lm(data = UK_PISA, PV1SCIE ~ PV1MATH)\n\n# tidy the model\n\nuk_mod_tidy &lt;- tidy(uk_mod)\n\n# pass to gt to produce nice output\n\ngt(uk_mod_tidy) %&gt;% \n  fmt_number(columns=c(\"p.value\"), \n              decimals = 3) %&gt;%\n  fmt_number(columns=c(\"estimate\", \"std.error\", \"statistic\"), \n              decimals = 2)\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n(Intercept)\n42.33\n2.30\n18.37\n0.000\n\n\nPV1MATH\n0.93\n0.00\n199.00\n0.000",
    "crumbs": [
      "Appendicies",
      "Questions and Answers"
    ]
  },
  {
    "objectID": "chapters/A6-QandA.html#how-do-i-report-the-results-of-tests-in-apa-format",
    "href": "chapters/A6-QandA.html#how-do-i-report-the-results-of-tests-in-apa-format",
    "title": "Questions and Answers",
    "section": "",
    "text": "When you have run some tests, the outputs (for example the degrees of freedom, test statistic and p-value) should be formatted in your paper in line with the citation convention of the journal or assessment (for example, KCL assignments follow the American Psychological Association (APA) citation style). You can find a general guide to presenting your results in APA style here: APA numbers and statistics style guide.\nFor example, to report a chi-square result:\n\n# Create example dataframe\n\nUK_gender_differences &lt;- PISA_2022 %&gt;%\n  select(CNT, ST004D01T) %&gt;%\n  filter(CNT == \"United Kingdom\") %&gt;% \n  droplevels()\n\ncont_tab &lt;- xtabs(data = UK_gender_differences, ~ ST004D01T)\n\n# Run a chi sqaure goodness of fit test\n\nchisq.test(cont_tab, p = c(0.5, 0.5))\n\n\n    Chi-squared test for given probabilities\n\ndata:  cont_tab\nX-squared = 2.4425, df = 1, p-value = 0.1181\n\n\nA chi-square test of goodness-of-fit was conducted to compare the observed frequencies in the contingency table to the expected frequencies (equal numbers of boys and girls). The result was not statistically significant, χ²(1, N = 12973) = 2.44, p = .12, indicating no significant difference between the observed and expected frequencies.\nTo report a t-test of the mathematics scores of girls and boys in the UK:\n\n# Create example dataframe\n\nUK_PISA &lt;- PISA_2022 %&gt;%\n  select(PV1MATH, CNT, ST004D01T) %&gt;%\n  filter(CNT == \"United Kingdom\")\n\n# Run a t-test\n\nt.test(data = UK_PISA, PV1MATH ~ ST004D01T)\n\n\n    Welch Two Sample t-test\n\ndata:  PV1MATH by ST004D01T\nt = -8.2246, df = 12942, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means between group Female and group Male is not equal to 0\n95 percent confidence interval:\n -16.9470 -10.4238\nsample estimates:\nmean in group Female   mean in group Male \n            475.6061             489.2915 \n\n\nThe output of that test would be reported as follows:\nThe results of a Welch’s t-test indicated a statistically significant difference in mean mathematics scores between UK females (M = 475.61) and UK males (M = 489.29), t(12,942) = -8.22, p &lt; .001, 95% CI [-16.95, -10.42].\nAlternatively, consider the output of an anova to look at the difference in wealth scores between Finland, Norway, and Sweden:\n\n# Create example dataframe\n\nwealth_scores &lt;- PISA_2022 %&gt;%\n  select(HOMEPOS, CNT) %&gt;%\n  filter(CNT == \"Finland\" | CNT == \"Norway\" | CNT == \"Sweden\")\n\n# Run an anova and summarise\n\naov_out &lt;- aov(data = wealth_scores, HOMEPOS ~ CNT)\nsummary(aov_out)\n\n               Df Sum Sq Mean Sq F value Pr(&gt;F)    \nCNT             2    575  287.61   356.7 &lt;2e-16 ***\nResiduals   22335  18008    0.81                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n584 observations deleted due to missingness\n\nTukeyHSD(aov_out)\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = HOMEPOS ~ CNT, data = wealth_scores)\n\n$CNT\n                     diff        lwr        upr p adj\nNorway-Finland  0.3846629  0.3508747  0.4184511     0\nSweden-Finland  0.1645141  0.1301168  0.1989114     0\nSweden-Norway  -0.2201488 -0.2581530 -0.1821445     0\n\n\nA one-way ANOVA was conducted to compare levels of home possessions (HOMEPOS) across three countries (CNT: Finland, Norway, and Sweden). The analysis revealed a statistically significant effect of country on home possessions, F(2, 22,335) = 356.7, p &lt; .001, η² = .031.\nPost hoc Tukey’s HSD tests indicated the following pairwise differences:\nNorway had significantly higher HOMEPOS scores than Finland (M difference = 0.38, 95% CI [0.35, 0.42], p &lt; .001). Sweden had significantly higher HOMEPOS scores than Finland (M difference = 0.16, 95% CI [0.13, 0.20], p &lt; .001). Sweden had significantly lower HOMEPOS scores than Norway (M difference = -0.22, 95% CI [-0.26, -0.18], p &lt; .001). A total of 584 observations were excluded due to missing data.\nAlternatively, you can use the report function in the easystats package to give a summary of an output.\n\nlibrary(easystats)\n\n# Get a summary of an anova\n\nreport(aov_out)\n\nThe ANOVA (formula: HOMEPOS ~ CNT) suggests that:\n\n  - The main effect of CNT is statistically significant and small (F(2, 22335) =\n356.72, p &lt; .001; Eta2 = 0.03, 95% CI [0.03, 1.00])\n\nEffect sizes were labelled following Field's (2013) recommendations.\n\n# And of a linear model\n\nmod1 &lt;- lm(data = wealth_scores, HOMEPOS ~ CNT)\n\nreport(mod1)\n\nWe fitted a linear model (estimated using OLS) to predict HOMEPOS with CNT\n(formula: HOMEPOS ~ CNT). The model explains a statistically significant and\nweak proportion of variance (R2 = 0.03, F(2, 22335) = 356.72, p &lt; .001, adj. R2\n= 0.03). The model's intercept, corresponding to CNT = Albania, is at 0.16 (95%\nCI [0.14, 0.18], t(22335) = 18.13, p &lt; .001). Within this model:\n\n  - The effect of CNT [Norway] is statistically significant and positive (beta =\n0.38, 95% CI [0.36, 0.41], t(22335) = 26.68, p &lt; .001; Std. beta = 0.42, 95% CI\n[0.39, 0.45])\n  - The effect of CNT [Sweden] is statistically significant and positive (beta =\n0.16, 95% CI [0.14, 0.19], t(22335) = 11.21, p &lt; .001; Std. beta = 0.18, 95% CI\n[0.15, 0.21])\n\nStandardized parameters were obtained by fitting the model on a standardized\nversion of the dataset. 95% Confidence Intervals (CIs) and p-values were\ncomputed using a Wald t-distribution approximation.\n\n\nThe report function will work on other test outputs, for example, on a t-test:\n\n# Create example data frame\n\nUK_PISA &lt;- PISA_2022 %&gt;%\n  select(PV1MATH, CNT, ST004D01T) %&gt;%\n  filter(CNT == \"United Kingdom\") %&gt;%\n  droplevels()\n\n# Use report on a t-test\n\nreport(t.test(data = UK_PISA, PV1MATH ~ ST004D01T))\n\nEffect sizes were labelled following Cohen's (1988) recommendations.\n\nThe Welch Two Sample t-test testing the difference of PV1MATH by ST004D01T\n(mean in group Female = 475.61, mean in group Male = 489.29) suggests that the\neffect is negative, statistically significant, and very small (difference =\n-13.69, 95% CI [-16.95, -10.42], t(12942.17) = -8.22, p &lt; .001; Cohen's d =\n-0.14, 95% CI [-0.18, -0.11])\n\n\nTo produce tables in APA format, you can use the apa.aov.table (for anovas) or apa.reg.table (for linear model outputs) functions from the apaTables package. You will need to install the package first using install.packages(\"apaTables\").\n\nlibrary(apaTables)\n\n# Get a summary table from an anova\n\napa.aov.table(aov_out)\n\n\n\nANOVA results using HOMEPOS as the dependent variable\n \n\n   Predictor       SS    df     MS      F    p partial_eta2 CI_90_partial_eta2\n (Intercept)   264.91     1 264.91 328.56 .000                                \n         CNT   575.22     2 287.61 356.72 .000          .03         [.03, .03]\n       Error 18007.84 22335   0.81                                            \n\nNote: Values in square brackets indicate the bounds of the 90% confidence interval for partial eta-squared \n\n# And of a linear model\n\napa.reg.table(mod1)\n\n\n\nRegression results using HOMEPOS as the criterion\n \n\n   Predictor      b     b_95%_CI sr2 sr2_95%_CI             Fit\n (Intercept) 0.16** [0.14, 0.18]                               \n   CNTNorway 0.38** [0.36, 0.41] .03 [.03, .04]                \n   CNTSweden 0.16** [0.14, 0.19] .01 [.00, .01]                \n                                                    R2 = .031**\n                                                95% CI[.03,.04]\n                                                               \n\nNote. A significant b-weight indicates the semi-partial correlation is also significant.\nb represents unstandardized regression weights. \nsr2 represents the semi-partial correlation squared.\nSquare brackets are used to enclose the lower and upper limits of a confidence interval.\n* indicates p &lt; .05. ** indicates p &lt; .01.\n \n\n\nYou can get more aesthetically pleasing versions of both tables using the gt function in the gt package. Before passing the outputs of avo of lm to gt, you will need to use the tidy fucntion from the broom package to tidy the output.\n\nlibrary(gt)\nlibrary(broom)\n\n# Tidy the outputs\n\ntidied_aov &lt;- tidy(aov_out)\ntidied_mod1 &lt;- tidy(mod1)\n\n\n# Produced a nicely formatted table from an anova\n\ngt(tidied_aov)\n\n\n\n\n\nterm\ndf\nsumsq\nmeansq\nstatistic\np.value\n\n\n\nCNT\n2\n575.2171\n287.6085570\n356.719\n3.175047e-153\n\n\nResiduals\n22335\n18007.8370\n0.8062609\nNA\nNA\n\n\n\n\n\n# And of a linear model\n\ngt(tidied_mod1)\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n(Intercept)\n0.1622658\n0.008951941\n18.12632\n6.584384e-73\n\n\nCNTNorway\n0.3846629\n0.014415658\n26.68369\n1.915252e-154\n\n\nCNTSweden\n0.1645141\n0.014675508\n11.21011\n4.349919e-29",
    "crumbs": [
      "Appendicies",
      "Questions and Answers"
    ]
  },
  {
    "objectID": "chapters/A6-QandA.html#how-do-i-add-the-results-from-statistical-tests-to-ggplot",
    "href": "chapters/A6-QandA.html#how-do-i-add-the-results-from-statistical-tests-to-ggplot",
    "title": "Questions and Answers",
    "section": "",
    "text": "There are a number of helpful packages that can add data to charts. First ggpubr lets you add data about the regression line to your plot using the stat_regline_equation() function. You will need to tweak the coordinates (label.x and label.y) to appear appropiately on your chart.\n\n# Load the ggpbur library (you will need to run install.packages(\"ggpubr\") the first time you use it)\nlibrary(ggpubr)\n\n# Create example dataframe\n\nUK_wealth_reading &lt;- PISA_2022 %&gt;%\n  select(CNT, PV1READ, HOMEPOS) %&gt;%\n  filter(CNT == \"United Kingdom\") \n\n# Plot a scatter plot with the regression equation\n\nggplot(UK_wealth_reading, aes(x = HOMEPOS, y = PV1READ)) +\n  geom_point(colour = \"lightgreen\", size = 0.1) +\n  geom_smooth(method = \"lm\") +\n  stat_regline_equation(label.x = -5, label.y = 600)  # Add regression equation\n\n\n\n\n\n\n\nYou can also use stat_regline_equation to add additional information like the p-value of the model and the R2 value:\n\n# Load the ggpbur library (you will need to run install.packages(\"ggpubr\") the first time you use it)\nlibrary(ggpubr)\n\n# Create example dataframe\n\nUK_wealth_reading &lt;- PISA_2022 %&gt;%\n  select(CNT, PV1READ, HOMEPOS) %&gt;%\n  filter(CNT == \"United Kingdom\") \n\n# Plot a scatter plot with the regression equation\n\nggplot(UK_wealth_reading, aes(x = HOMEPOS, y = PV1READ)) +\n  geom_point(colour = \"lightgreen\", size = 0.1) +\n  geom_smooth(method = \"lm\", formula = y ~ x) + # Ensure formula is specified here too\n  stat_regline_equation(\n    aes(label = paste(..eq.label.., ..adj.rr.label.., sep = \"~~~~\")), # Indicate you want the equation and R2 value and the seperator text\n    label.x = -10, label.y = 600,\n    formula = y ~ x)\n\n\n\n\n\n\n\nAnother powerful package for adding data to graphs is ggstatsplot. For example, it can anotate a plot with anova data. For example, if you want compare the science scores of the UK, Japan and the US:\n\n# Load the ggstatplot library (you will need to run install.packages(\"ggstatsplot\") the first time you use it)\nlibrary(ggstatsplot)\n\n# Create example dataframe\n\ncountry_sci_data &lt;- PISA_2022 %&gt;%\n  select(CNT, PV1SCIE) %&gt;%\n  filter(CNT == \"United Kingdom\" | CNT == \"Japan\" | CNT == \"United States\")\n\n# Use ggstatplot to create an annotated plot with an anova result\n\nggbetweenstats(\n  data  = country_sci_data,\n  x     = CNT,\n  y     = PV1SCIE,\n  title = \"Science scores in the UK, US and Japan\",\n  type  = \"parametric\" # Forces the test to be ANOVA\n)",
    "crumbs": [
      "Appendicies",
      "Questions and Answers"
    ]
  },
  {
    "objectID": "chapters/A6-QandA.html#how-do-i-turn-a-data-frame-into-a-form-i-can-put-into-an-assignment-or-paper-1",
    "href": "chapters/A6-QandA.html#how-do-i-turn-a-data-frame-into-a-form-i-can-put-into-an-assignment-or-paper-1",
    "title": "Questions and Answers",
    "section": "",
    "text": "You can use the gt package to convert data frames to aesthetically pleasing outputs.\n\n# load the gt package - you will need to run install.packages(\"gt\") the first time\n# install.packages(\"gt\")\nlibrary(gt)\n\n# Make the data frame you want you want to output\nscience_mean_scores &lt;- PISA_2022 %&gt;%\n  group_by(CNT) %&gt;%\n  summarise(mean_science_score = mean(PV1SCIE, na.rm = TRUE),\n            sd_science = sd(PV1SCIE, na.rm =TRUE)) %&gt;%\n  filter(CNT == \"United Kingdom\" | CNT == \"United States\" | CNT == \"Germany\")\n\n# Use gt to produce an output - you can copy and paste the table from the\n# viewer window to your report\n\ngt(science_mean_scores)\n\n\n\n\n\nCountry code 3-character\nmean_science_score\nsd_science\n\n\n\nGermany\n495.2547\n105.4208\n\n\nUnited Kingdom\n492.2651\n102.1538\n\n\nUnited States\n498.2506\n108.8539\n\n\n\n\n\n# You can see more options on formatting the table here: https://gt.rstudio.com\n# For example to add a heading\n\ngt(science_mean_scores) %&gt;% tab_header(\n    title = \"Mean science scores\",\n    subtitle = \"PISA 2022 data\")\n\n\n\n\n\n\nMean science scores\n\n\nPISA 2022 data\n\n\nCountry code 3-character\nmean_science_score\nsd_science\n\n\n\n\nGermany\n495.2547\n105.4208\n\n\nUnited Kingdom\n492.2651\n102.1538\n\n\nUnited States\n498.2506\n108.8539\n\n\n\n\n\n# Or to change the number of decimal places and a column name\n\ngt(science_mean_scores) %&gt;% tab_header(\n  title = \"Mean science scores\",\n  subtitle = \"PISA 2022 data\") %&gt;%\n  fmt_number(columns = c(mean_science_score , sd_science), decimals = 1) %&gt;%\n  cols_label(\"CNT\" = md(\"**Country**\")) # Here the **Country** makes Country bold\n\n\n\n\n\n\nMean science scores\n\n\nPISA 2022 data\n\n\nCountry\nmean_science_score\nsd_science\n\n\n\n\nGermany\n495.3\n105.4\n\n\nUnited Kingdom\n492.3\n102.2\n\n\nUnited States\n498.3\n108.9\n\n\n\n\n\n\n\n## If you have an output from a linear model, there is an additional step to do before using gt\n# You need to use the broom package, which has the `tidy` function which gets the output of `lm`\n# Into a suitable format for turing into a table\n# install.packages(\"broom\")\n\nlibrary(broom)\n\n# Create example dataframe\n\nUK_PISA &lt;- PISA_2022 %&gt;%\n  select(PV1SCIE, PV1MATH, CNT) %&gt;%\n  filter(CNT == \"United Kingdom\")\n\n# Run the model\n\nuk_mod &lt;- lm(data = UK_PISA, PV1SCIE ~ PV1MATH)\n\n# tidy the model\n\nuk_mod_tidy &lt;- tidy(uk_mod)\n\n# pass to gt to produce nice output\n\ngt(uk_mod_tidy)\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n(Intercept)\n42.3335278\n2.304412214\n18.37064\n1.978594e-74\n\n\nPV1MATH\n0.9324181\n0.004685464\n199.00232\n0.000000e+00",
    "crumbs": [
      "Appendicies",
      "Questions and Answers"
    ]
  },
  {
    "objectID": "chapters/A6-QandA.html#how-can-i-change-the-colours-of-a-plot-if-i-dont-want-the-default-colours",
    "href": "chapters/A6-QandA.html#how-can-i-change-the-colours-of-a-plot-if-i-dont-want-the-default-colours",
    "title": "Questions and Answers",
    "section": "",
    "text": "ggplot will use a default palette - you can sometimes identify plots in papers as being produced by ggplot from the distinctive green and pink colour! If you want to move away from these, you can use the scale_fill_manual and scale_colour_manual functions.\nFor example, if you have a bar graph of the number of boys and girls in the UK, you can change the fill colours using scale_fill_manual and defining the colours for the categories (in this case Male and Female).\n\nUK_PISA &lt;- PISA_2022 %&gt;%\n  select(ST004D01T, CNT) %&gt;%\n  filter(CNT == \"United Kingdom\")\n\nggplot(UK_PISA, aes(x = ST004D01T, fill = ST004D01T)) +\n  geom_bar() +\n  scale_fill_manual(values = c(\"Male\" = \"orange\", \"Female\" = \"lightblue\"))  # manually set the values for male and female\n\n\n\n\n\n\n\nYou need to match the scale manual command to the aesthetic you want to change. For example, when using geom_point you use the colour aesthetic to change the colour of points. In that case, you use scale_colour_manual.\n\nUK_PISA &lt;- PISA_2022 %&gt;%\n  select(ST004D01T, CNT, PV1SCIE, PV1MATH) %&gt;%\n  filter(CNT == \"United Kingdom\")\n\nggplot(UK_PISA, aes(x = PV1MATH, y = PV1SCIE, colour = ST004D01T)) +\n  geom_point(size = 0.1, alpha = 0.6) +\n  scale_colour_manual(values = c(\"Male\" = \"lightgreen\", \"Female\" = \"red\")) # manually set the colour values for male and female",
    "crumbs": [
      "Appendicies",
      "Questions and Answers"
    ]
  },
  {
    "objectID": "chapters/A1-PISA_analysis.html",
    "href": "chapters/A1-PISA_analysis.html",
    "title": "PISA",
    "section": "",
    "text": "The Programme for International Student Assessment (PISA) is an OECD initiative that looks at the reading, mathematics and science abilities of students aged 15 years old. Data is collected from ~38 OECD countries and other partner countries every three years.\n\n\nDataset\nDescription\n03\n06\n09\n12\n15\n18\n22\n\n\n\nStudent\ndemographic data on student participants\nx\nx\nx\n\nx\n\nx\nx\nx\n\n\nSchool\ndescriptive data about schools\nx\nx\nx\nx\nx\nx\nx\n\n\nParent\na survey for student’s parents including information about home environments and parental education\nx\nx\n\n\n\n\n\n\n\nTeacher\ndemographic, teaching, qualification and training data\n\n\n\nx\nx\nx\nx\n\n\nCognitive\nindividual results for each exam style question students took\nx\nx\nx\nx\nx\nx\n\n\n\n\nPISA datasets above can be found on the OECD website. The links in the table above will allow you to download .parquet versions of these files which we have created, though they might need additional editing, e.g. reducing the number of columns or changing the types of each column. If you want to find out more about what each field stores, take a look at the corresponding codebook: 2022, 2018, 2015.",
    "crumbs": [
      "Appendicies",
      "PISA"
    ]
  },
  {
    "objectID": "chapters/A1-PISA_analysis.html#sec-PV",
    "href": "chapters/A1-PISA_analysis.html#sec-PV",
    "title": "PISA",
    "section": "\n4.1 What are Plausible Values?",
    "text": "4.1 What are Plausible Values?\nIn the PISA dataset, the outcomes of student tests are reported as plausible values, for example, in the variables of the science test (PV1SCIE, PV2SCIE, PV3SCIE, PV3SCIE, and PV5SCIE). It might seem counter intuitive that there are five or ten values for a score on a test. (note PISA published five plausible values before 2015, when they increased the number of plausible values to ten)\nPlausible values (PVs) are a way of expressing the error in a measurement. The number of questions in the full PISA survey is very large, so students are randomly allocated to take a subset of questions (and even then, the test still takes two hours!). As no student completes the full set of questions (only 40% of students even answer questions in reading, science and mathematics OECD (2014)), estimating how a student would have performed on the full question set involves some error. Plausible values are a way of expressing the uncertainty in the estimation of student scores.\nOne way of thinking of the PV scores is that they represent five or ten different estimates of students’ abilities based on the questions they have answered. To decrease measurement error, five different approaches are applied to create five different estimates, the PV scores.\nThe PISA Data Analysis Manual suggests:\n\nPopulation statistics should be estimated using each plausible value separately. The reported population statistic is then the average of each plausible value statistic. For instance, if one is interested in the correlation coefficient between the social index and the reading performance in PISA, then five correlation coefficients should be computed and then averaged\nPlausible values should never be averaged at the student level, i.e. by computing in the dataset the mean of the five plausible values at the student level and then computing the statistic of interest once using that average PV value. Doing so would be equivalent to an EAP estimate, with a bias as described in the previous section.\n(Monseur et al. 2009, 100)\n\nThe actual PV values can differ substantially from each, for example if we work out the scaled (normalised) value for a PV value, that is how many standard deviations from the mean of other PV values a student gets we can see large fluctuations. For student 5, PV1SCIE is 0.147 standard deviations lower than the average of all students, whilst PV2SCIE is 1.10 standard deviations higher:\n\nPISA_2022 %&gt;% \n  mutate(PV1SCIE_z = scale(PV1SCIE),\n         PV2SCIE_z = scale(PV2SCIE)) %&gt;%\n  select(PV1SCIE_z,\n         PV2SCIE_z)\n\n# A tibble: 613,744 × 2\n   PV1SCIE_z[,1] PV2SCIE_z[,1]\n           &lt;dbl&gt;         &lt;dbl&gt;\n 1        -1.09         -1.47 \n 2        -1.29         -1.17 \n 3        -0.872        -1.00 \n 4        -2.24         -2.45 \n 5        -0.147         1.10 \n 6         0.272         0.298\n 7        -1.03         -1.52 \n 8        -1.22         -0.865\n 9        -0.854        -0.840\n10        -0.614        -0.221\n# ℹ 613,734 more rows\n\n\nThese differences make analysis at an individual student level hard to justify, though overall population or sub population scores will be more reliable. As suggested above, we could look at using the average (here, taken to be the mean) of several PV scores. To calculate the mean of ten PV values, do the following (it might take some time to complete this calculation!):\n\nPISA_2022 %&gt;% \n  rowwise() %&gt;%\n  mutate(PV_SCIE_z = mean(c_across(matches(\"PV[0-9]+SCIE\"))),\n         PV_MATH_z = mean(c_across(matches(\"PV[0-9]+MATH\"))),\n         PV_READ_z = mean(c_across(matches(\"PV[0-9]+READ\")))) %&gt;%\n  ungroup() %&gt;% # to get rid of the rowwise operator\n  select(PV_SCIE_z, PV_MATH_z, PV_READ_z)",
    "crumbs": [
      "Appendicies",
      "PISA"
    ]
  },
  {
    "objectID": "chapters/A1-PISA_analysis.html#what-are-weights",
    "href": "chapters/A1-PISA_analysis.html#what-are-weights",
    "title": "PISA",
    "section": "\n4.2 What are weights",
    "text": "4.2 What are weights\nThe PISA data set contains two weighting variables that allow you to look at student outcomes that represent a country population accurately, and to compare countries against each other.\n\n4.2.1 Student weights\nThe first weight is the student weight W_FSTUWT, which represents the probability of an individual student being selected within a given country. Taking mean results from students who took the test in a country might not be fully representative of all the students in a country. For example, in the UK we might have more students sampled in Scotland than in England, because the school population of England (~9.1 million) is much larger than Scotland (~790 thousand). This is the case with 4,763 students sampled in England and 3,257 sampled in Scotland; as a proportion the Scottish population is too big. For any calculation, we would want to reduce the impact of each Scottish student on the overall UK results, otherwise they would be over represented:\n\nCodePISA_2022 %&gt;% \n  filter(CNT == \"United Kingdom\") %&gt;%\n  group_by(REGION) %&gt;%\n  summarise(n=n(),\n            W_FSTUWT_mean = mean(W_FSTUWT)) %&gt;%\n  gt() %&gt;%\n  fmt_number(columns = \"n\", decimals = 0) %&gt;%\n  fmt_number(columns = \"W_FSTUWT_mean\", decimals = 2) %&gt;%\n  cols_align(columns = \"REGION\", align=\"left\")\n\n\n\n\n\nREGION\nn\nW_FSTUWT_mean\n\n\n\nGreat Britain: England\n4,763\n131.04\n\n\nGreat Britain: Northern Ireland\n2,384\n9.47\n\n\nGreat Britain: Wales\n2,568\n12.73\n\n\nGreat Britain: Scotland\n3,257\n15.91\n\n\n\n\n\n\nThe ratio of students in England to students in Scotland is roughly 9,100,100 : 790,000 or 11.5. Applying the students weights for England and Scotland we get:\n\n(4763 * 131.04) / (3257 * 15.91)\n\n[1] 12.04471\n\n\nThis is close but not quite the same as the population ratio. The reason is because there are other factors that influence the student weighting, including situations where certain school types are under represented and other types over represented, for example there being more urban schools in the sample than in the population, this would then require students in rural schools to be given a greater weighting than students in urban schools. The exact art of working out these weights is hard to come by.\nSo how do you use student weights in a calculation? Let’s look at the example of finding the mean poverty level of country, by looking at HOMEPOS. Calculating this without the weights gives us the following:\n\nCodePISA_2022 %&gt;% \n  group_by(CNT) %&gt;%\n  summarise(HOMEPOS_m = mean(HOMEPOS, na.rm=TRUE),\n            HOMEPOS_sd = sd(HOMEPOS, na.rm=TRUE)) %&gt;%\n  arrange(HOMEPOS_m)\n\n# A tibble: 80 × 3\n   CNT                   HOMEPOS_m HOMEPOS_sd\n   &lt;fct&gt;                     &lt;dbl&gt;      &lt;dbl&gt;\n 1 Cambodia                  -2.41      1.08 \n 2 Morocco                   -1.77      1.19 \n 3 Philippines               -1.75      1.13 \n 4 Indonesia                 -1.58      0.911\n 5 El Salvador               -1.57      1.08 \n 6 Guatemala                 -1.52      1.31 \n 7 Paraguay                  -1.52      1.13 \n 8 Palestinian Authority     -1.49      1.25 \n 9 Peru                      -1.40      1.20 \n10 Jordan                    -1.38      1.18 \n# ℹ 70 more rows\n\n\nNow to apply the weights, students in each country will have their HOMEPOS score adjusted before the\n\nCodePISA_2022 %&gt;% \n  group_by(CNT) %&gt;%\n  summarise(HOMEPOS_m = mean(HOMEPOS * W_FSTUWT, na.rm=TRUE) / mean(W_FSTUWT),\n            HOMEPOS_sd = sd(HOMEPOS * W_FSTUWT, na.rm=TRUE) / mean(W_FSTUWT)) %&gt;%\n  arrange(HOMEPOS_m)\n\n# A tibble: 80 × 3\n   CNT                   HOMEPOS_m HOMEPOS_sd\n   &lt;fct&gt;                     &lt;dbl&gt;      &lt;dbl&gt;\n 1 Cambodia                  -2.34       1.90\n 2 Philippines               -1.75       1.23\n 3 Morocco                   -1.74       1.22\n 4 Indonesia                 -1.70       2.31\n 5 El Salvador               -1.63       1.58\n 6 Paraguay                  -1.56       1.40\n 7 Guatemala                 -1.54       1.60\n 8 Palestinian Authority     -1.53       1.52\n 9 Peru                      -1.44       1.38\n10 Thailand                  -1.43       1.70\n# ℹ 70 more rows\n\n\n\n4.2.2 Senate weights\nThe data set contains another weighting variable, the senate weight [COL_ID]. To ensure that countries make equal contributions to regression models when they have different response rates, senate weights are published (Jerrim et al. 2017). Senate weights renormalise the weights within each country so that the total for a country sums to a constant value, giving each country the same weight in an overall analysis (Rijmen 2011).",
    "crumbs": [
      "Appendicies",
      "PISA"
    ]
  },
  {
    "objectID": "chapters/A1-PISA_analysis.html#how-do-i-use-the-plausible-values-and-weights-correctly",
    "href": "chapters/A1-PISA_analysis.html#how-do-i-use-the-plausible-values-and-weights-correctly",
    "title": "PISA",
    "section": "\n4.3 How do I use the plausible values and weights correctly?",
    "text": "4.3 How do I use the plausible values and weights correctly?\nTo simplify our teaching, we focus on using a single PV value, PV1___ in our calculations. This is not the recommended use, but simplifies our introduction to the PISA data. Here we set out how to perform a more complete analysis.\nThe first step in analysis is to apply the weights. In the code below, we select the needed columns, country, the student weight column (W_FSTUWT) and the ten PV values (in this case for math). The mutate(across line multiples each of the ten PV values by the value in W_FSTUWT, the student weight, and adds new columns with _weighted appended.\n\nPISA_2022 %&gt;%\n  select(CNT, W_FSTUWT, PV1MATH:PV10MATH) %&gt;%\n  mutate(across(PV1MATH:PV10MATH, ~ .x * W_FSTUWT, .names = \"{.col}_weighted\"))\n\nNext we group_by(CNT) and summarise to get a total_weight for each country, by adding all the individual student weights (W_FSTUWT). To get a mean PV1, PV2, etc score for each country, we then sum all the weighted PV1 scores and divide by the total weight, and do the same for PV2, Pv3 etc. These are given the names PV1MATH_weighted_mean, PV2MATH_weighted_mean, etc.\n\nPISA_2022 %&gt;%\n  select(CNT, W_FSTUWT, PV1MATH:PV10MATH) %&gt;%\n  mutate(across(PV1MATH:PV10MATH, ~ .x * W_FSTUWT, .names = \"{.col}_weighted\")) %&gt;%\n  group_by(CNT) %&gt;%\n  summarise(\n    total_weight = sum(W_FSTUWT, na.rm = TRUE),\n    across(PV1MATH_weighted:PV10MATH_weighted, ~ sum(.x, na.rm = TRUE) / total_weight, .names = \"{.col}_mean\"))\n\nFinally, we calculated the mean of the PV1MATH_weighted_mean, PV2MATH_weighted_mean, … PV10MATH_weighted_mean columns. I have arranged the results in descending order.\n\nPISA_2022 %&gt;%\n  select(CNT, W_FSTUWT, PV1MATH:PV10MATH) %&gt;%\n  mutate(across(PV1MATH:PV10MATH, ~ .x * W_FSTUWT, .names = \"{.col}_weighted\")) %&gt;%\n  group_by(CNT) %&gt;%\n  summarise(\n    total_weight = sum(W_FSTUWT, na.rm = TRUE),\n    across(PV1MATH_weighted:PV10MATH_weighted, ~ sum(.x, na.rm = TRUE) / total_weight, .names = \"{.col}_mean\")) %&gt;%\n  rowwise() %&gt;%\n  mutate(PV_mean_weighted = mean(c_across(ends_with(\"_mean\")), na.rm = TRUE)) %&gt;%\n  select(CNT, PV_mean_weighted) %&gt;%\n  mutate(PV_mean_weighted = round(PV_mean_weighted, digits = 1)) %&gt;%\n  arrange(desc(PV_mean_weighted))\n\n# A tibble: 80 × 2\n# Rowwise: \n   CNT               PV_mean_weighted\n   &lt;fct&gt;                        &lt;dbl&gt;\n 1 Singapore                     575.\n 2 Macao (China)                 552.\n 3 Chinese Taipei                547.\n 4 Hong Kong (China)             540.\n 5 Japan                         536.\n 6 Korea                         527.\n 7 Estonia                       510.\n 8 Switzerland                   508 \n 9 Canada                        497.\n10 Netherlands                   493.\n# ℹ 70 more rows\n\n\nThis output matches the PISA published values for 2022.\nWhen performing tests (for example, t-tests or linear regressions) the recommended approach is to:Rubin’s rules for multiple imputation as recommended by the OECD OECD (2009a) : a) estimate a statistic multiple times, once each for each plausible value; b) average the values produced; c) estimate the magnitude of the imputation error; and d) calculate the final standard error from the sampling error and the imputation error.\nHence, if you were performing a linear model you should a) weight the raw scores you intend to use; b) run the model ten times, once each for each of the plausible values; c) calculate the average outcome metrics. For example, your code might look like this:\n\n# a function that returns the models for a given formula\n# formula must include exactly one PV\nmulti_pv_lm &lt;- function(model_data,\n                        pv_formula,\n                        pv_vals = 1:10,\n                        weight_id = \"W_FSTUWT\"){\n\n  pv_focus_orig &lt;- str_extract(pv_formula, \"PV[0-9]+[A-Z]{4}\")\n  pv_focus &lt;- pv_focus_orig %&gt;% str_remove(\"PV[0-9]*\")\n  message(\"focusing on \", pv_focus)\n\n  if(weight_id %in% names(model_data)){\n    message(glue(\"Weighting by {weight_id}\"))\n  } else {\n    message(glue(\"No {weight_id} weight variable found\"))\n    return(NULL)\n  }\n  \n  # List of plausible value column names\n  pv_columns &lt;- paste0(\"PV\", pv_vals, pv_focus)\n  \n  results &lt;- map_dfr(pv_columns, \\(pv){\n    pv_formula_map &lt;- str_replace(pv_formula, pv_focus_orig, pv)\n\n    message(pv)\n    # run model\n    model &lt;- lm(as.formula(pv_formula_map), \n                data = model_data, \n                weights = model_data[[weight_id]])\n    # extract summary\n    model_summary &lt;- summary(model)\n    \n    # return rows\n    broom::tidy(model_summary) %&gt;% \n      mutate(R2 = model_summary$r.squared) %&gt;%\n      mutate(PV = pv)\n  })\n  \n  results_flat &lt;- results %&gt;% \n    mutate(term = ifelse(str_detect(term, \"PV[0-9]+[A-Z]{4}\"), \n                         glue(\"PV_{pv_focus}\"), \n                         term)) %&gt;%\n    group_by(term) %&gt;% \n    summarise(estimate_mean = mean(estimate),\n              estimate_sd = sd(estimate),\n              std_error_mean = mean(std.error),\n              std_error_sd = sd(std.error),\n              statistic_mean = mean(statistic),\n              statistic_sd = sd(statistic),\n              p_value_mean = mean(p.value),\n              p_value_sd = sd(p.value),\n              r2 = max(R2))\n  \n  return(list(results=results, \n              results_flat=results_flat))\n}\n\n# we can call the model comparison, like so:\nmdl_pvs_math &lt;- multi_pv_lm(PISA_2022, \"PV1MATH ~ HOMEPOS + ESCS\")\n\n# You can then access the full model responses through:\nmdl_pvs_math$results\n\n# A tibble: 30 × 7\n   term        estimate std.error statistic p.value    R2 PV     \n   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;  \n 1 (Intercept)    459.      0.131    3515.        0 0.290 PV1MATH\n 2 HOMEPOS         34.3     0.154     223.        0 0.290 PV1MATH\n 3 ESCS            10.7     0.153      69.8       0 0.290 PV1MATH\n 4 (Intercept)    459.      0.130    3524.        0 0.289 PV2MATH\n 5 HOMEPOS         34.4     0.154     224.        0 0.289 PV2MATH\n 6 ESCS            10.5     0.153      68.4       0 0.289 PV2MATH\n 7 (Intercept)    459.      0.130    3524.        0 0.290 PV3MATH\n 8 HOMEPOS         34.2     0.154     223.        0 0.290 PV3MATH\n 9 ESCS            10.8     0.153      70.6       0 0.290 PV3MATH\n10 (Intercept)    459.      0.130    3530.        0 0.291 PV4MATH\n# ℹ 20 more rows\n\n# or the mean values for model outcomes with:\nmdl_pvs_math$results_flat\n\n# A tibble: 3 × 10\n  term      estimate_mean estimate_sd std_error_mean std_error_sd statistic_mean\n  &lt;chr&gt;             &lt;dbl&gt;       &lt;dbl&gt;          &lt;dbl&gt;        &lt;dbl&gt;          &lt;dbl&gt;\n1 (Interce…         459.       0.128           0.130     0.000189         3523. \n2 ESCS               10.7      0.140           0.153     0.000221           69.9\n3 HOMEPOS            34.4      0.0896          0.154     0.000223          224. \n# ℹ 4 more variables: statistic_sd &lt;dbl&gt;, p_value_mean &lt;dbl&gt;, p_value_sd &lt;dbl&gt;,\n#   r2 &lt;dbl&gt;\n\nmdl_pvs_read &lt;- multi_pv_lm(PISA_2022, \"ESCS ~ HOMEPOS + PV1READ\")\n\n# TODO: https://bookdown.org/mwheymans/bookmi/rubins-rules.html",
    "crumbs": [
      "Appendicies",
      "PISA"
    ]
  },
  {
    "objectID": "chapters/A1-PISA_analysis.html#where-can-i-find-examples-of-pisa-test-items",
    "href": "chapters/A1-PISA_analysis.html#where-can-i-find-examples-of-pisa-test-items",
    "title": "PISA",
    "section": "\n4.4 Where can I find examples of PISA test items?",
    "text": "4.4 Where can I find examples of PISA test items?\nThe OECD do not release the full question set used in the PISA science, reading and mathematics tests in order to allow questions to be reused across cycles to allow valid inferences. However, you can find a document of items used in PISA 2000, 2003, 2006 and some test items here which give a flavour of the nature of the tests.",
    "crumbs": [
      "Appendicies",
      "PISA"
    ]
  },
  {
    "objectID": "chapters/A1-PISA_analysis.html#why-are-some-countries-oecd-countries-and-others-arent",
    "href": "chapters/A1-PISA_analysis.html#why-are-some-countries-oecd-countries-and-others-arent",
    "title": "PISA",
    "section": "\n4.5 Why are some countries OECD countries and others aren’t?",
    "text": "4.5 Why are some countries OECD countries and others aren’t?\nThe Organisation for Economic Co-operation and Development (OECD) has 38 member states. PISA is run by the OECD and its member states normally take part in each PISA cycle, but other countries are allowed to take part as Partners. You can find more details on participation here.\nResults for OECD members are generally higher than for Partner countries:\n\nPISA_2022 %&gt;% \n  group_by(OECD) %&gt;% \n  summarise(country_n = length(unique(CNT)),\n            math_mean = mean(PV1MATH, na.rm=TRUE),\n            math_sd = sd(PV1MATH, na.rm=TRUE),\n            students_n = n())\n\n# A tibble: 2 × 5\n  OECD  country_n math_mean math_sd students_n\n  &lt;fct&gt;     &lt;int&gt;     &lt;dbl&gt;   &lt;dbl&gt;      &lt;int&gt;\n1 No           43      409.    97.8     318587\n2 Yes          37      475.    95.0     295157",
    "crumbs": [
      "Appendicies",
      "PISA"
    ]
  },
  {
    "objectID": "chapters/A1-PISA_analysis.html#why-are-the-pv-grades-pivoting-around-the-500-mark",
    "href": "chapters/A1-PISA_analysis.html#why-are-the-pv-grades-pivoting-around-the-500-mark",
    "title": "PISA",
    "section": "\n4.6 Why are the PV grades pivoting around the ~500 mark?",
    "text": "4.6 Why are the PV grades pivoting around the ~500 mark?\nThe scores for students in mathematics, reading and science are scaled so that the mean of students in OECD countries is roughly 500 points with a standard deviation of 100 points. To see this, run the following code:\n\nPISA_2022 %&gt;% \n  filter(OECD==\"Yes\") %&gt;% \n  summarise(math_mean = mean(PV1MATH, na.rm=TRUE),\n            math_sd = sd(PV1MATH, na.rm=TRUE),\n            scie_mean = mean(PV1SCIE, na.rm=TRUE),\n            scie_sd = sd(PV1SCIE, na.rm=TRUE),\n            read_mean = mean(PV1READ, na.rm=TRUE),\n            read_sd = sd(PV1READ, na.rm=TRUE))\n\n# A tibble: 1 × 6\n  math_mean math_sd scie_mean scie_sd read_mean read_sd\n      &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1      475.    95.0      487.    101.      478.    104.",
    "crumbs": [
      "Appendicies",
      "PISA"
    ]
  },
  {
    "objectID": "chapters/A1-PISA_analysis.html#but-the-mean-pv-score-isnt-500",
    "href": "chapters/A1-PISA_analysis.html#but-the-mean-pv-score-isnt-500",
    "title": "PISA",
    "section": "\n4.7 But the mean PV score isn’t 500?!",
    "text": "4.7 But the mean PV score isn’t 500?!\nThe OECD’s initial plan (in the 2000 study) was that the mean PC score for OECD countries should be 500 and the standard deviation 100 (OECD 2019a). However, after the 2000 study, scores were scaled to be comparable with the first cycle of data, resulting in means differing from 500 (Pulkkinen and Rautopuro 2022). For example, by 2015, the mean for science had fallen to 493 in science and reading, and 490 in mathematics.",
    "crumbs": [
      "Appendicies",
      "PISA"
    ]
  },
  {
    "objectID": "chapters/A1-PISA_analysis.html#why-are-the-letters-ta-and-na-used-in-some-field-names",
    "href": "chapters/A1-PISA_analysis.html#why-are-the-letters-ta-and-na-used-in-some-field-names",
    "title": "PISA",
    "section": "\n4.8 Why are the letters TA and NA used in some field names?",
    "text": "4.8 Why are the letters TA and NA used in some field names?",
    "crumbs": [
      "Appendicies",
      "PISA"
    ]
  },
  {
    "objectID": "chapters/A1-PISA_analysis.html#how-do-i-find-fields-that-are-numeric",
    "href": "chapters/A1-PISA_analysis.html#how-do-i-find-fields-that-are-numeric",
    "title": "PISA",
    "section": "\n4.9 How do I find fields that are numeric?",
    "text": "4.9 How do I find fields that are numeric?\n\n# using the following code!\n\nnms &lt;- PISA_2022 %&gt;% select(where(is.numeric)) %&gt;% names()\nlbls &lt;- map_dfr(nms,\\(nme){\n  message(nme)\n  lbl &lt;- attr(PISA_2022[[nme]], \"label\")\n  row &lt;- c(nme, lbl)\n  names(row) &lt;- c(\"name\", \"label\")\n  return(row)\n})",
    "crumbs": [
      "Appendicies",
      "PISA"
    ]
  },
  {
    "objectID": "chapters/A1-PISA_analysis.html#how-are-students-selected-to-take-part-in-pisa",
    "href": "chapters/A1-PISA_analysis.html#how-are-students-selected-to-take-part-in-pisa",
    "title": "PISA",
    "section": "\n4.10 How are students selected to take part in PISA?",
    "text": "4.10 How are students selected to take part in PISA?\nThe students who take part in the PISA study are aged between 15 years and 3 (completed) months and 16 years and 2 (completed) months at the beginning of the testing period (OECD 2018). A number of classes of students are excluded from data collection:\n\nStudents classed as ‘functionally disabled’ so that they cannot participate in the test.\nJudged by teachers to have cognitive, emotional or behavioural difficulties that mean they cannot participate.\nThe student lacks language abilities to take the test in the assessment language.\nThere are no test material available in the student’s language\nAnother agreed reason\n\nThe OECD expect that 85% of schools in their original sample participate - nonparticipating schools can be replaced with a substitute, ‘replacement’ school. A minimum weighted response rate of 80% is required within schools.\nThe sampling strategy for PISA is a stratified two-stage sample design. That is schools are sampled to represent proportional distribution by size (referring to the number of enrolled 15-year-olds) sampling. Within schools, students are sampled with equal probability.\nStudents are selected by … (ref?)\nAdd Christian Bokhove papers https://bokhove.net/r-materials/\nFrom the data, you can see that 50% of schools entered fewer than 30 students into PISA.\n\nPISA_2022 %&gt;% \n  group_by(CNTSCHID) %&gt;%\n  summarise(size = n()) %&gt;%\n  mutate(quartile = ntile(size, 4)) %&gt;%\n  group_by(quartile) %&gt;%\n  summarise(Qmax = max(size),\n            Qmedian = median(size),\n            Qmean = mean(size))\n\n# A tibble: 4 × 4\n  quartile  Qmax Qmedian Qmean\n     &lt;int&gt; &lt;int&gt;   &lt;dbl&gt; &lt;dbl&gt;\n1        1    19      10  10.1\n2        2    30      25  25.2\n3        3    37      34  33.8\n4        4   475      40  44.4\n\nggplot(PISA_2022 %&gt;% \n  group_by(CNTSCHID) %&gt;%\n  summarise(size = n()), aes(x=size)) +\n  geom_density()",
    "crumbs": [
      "Appendicies",
      "PISA"
    ]
  },
  {
    "objectID": "chapters/A1-PISA_analysis.html#what-are-the-pisa-test-questions-like",
    "href": "chapters/A1-PISA_analysis.html#what-are-the-pisa-test-questions-like",
    "title": "PISA",
    "section": "\n4.11 What are the PISA test questions like?",
    "text": "4.11 What are the PISA test questions like?\nYou can view sample PISA science, reading and mathematics questions here.",
    "crumbs": [
      "Appendicies",
      "PISA"
    ]
  },
  {
    "objectID": "chapters/A1-PISA_analysis.html#how-can-i-find-the-ethnicity-or-race-of-a-student-taking-the-pisa-test",
    "href": "chapters/A1-PISA_analysis.html#how-can-i-find-the-ethnicity-or-race-of-a-student-taking-the-pisa-test",
    "title": "PISA",
    "section": "\n4.12 How can I find the ethnicity or race of a student taking the PISA test?",
    "text": "4.12 How can I find the ethnicity or race of a student taking the PISA test?\nThis data isn’t collected by PISA. Instead they collect information on the language spoken at home (LANGN) and the language of the test (LANGTEST_QQQ), as well as the immigration status and country of birth (COBN_S student, COBN_M mother, COBN_F father). Details on ethnicity and outcomes in the England are published through the country specific research report for 2018. Note that Chinese students are categorised under “Other” rather than “Asian”.",
    "crumbs": [
      "Appendicies",
      "PISA"
    ]
  },
  {
    "objectID": "chapters/A1-PISA_analysis.html#what-are-the-pisa-domains",
    "href": "chapters/A1-PISA_analysis.html#what-are-the-pisa-domains",
    "title": "PISA",
    "section": "\n4.13 What are the PISA domains?",
    "text": "4.13 What are the PISA domains?\nEvery PISA test has included test items measuring literacy, numeracy and science. In each cycle, one of three areas is the focus of study (the major domain). In addition, extra domains have been added to cycles (for example, creative thinking and collaborative problem solving). The additional domains are shown in the table below.\n\n\n\n\n\n\n\nYear\nMajor Domain\nMinor Domains\n\n\n\n2000\nReading literacy\nMathematics, Science\n\n\n2003\nMathematics\nReading literacy, Science, Cross-curricular problem solving\n\n\n2006\nScience\nReading literacy, Mathematics\n\n\n2009\nReading literacy\nMathematics, Science\n\n\n2012\nMathematics\nReading literacy, Science, Creative problem solving\n\n\n2015\nScience\nMathematics, Reading literacy, Collaborative problem solving\n\n\n2018\nReading literacy\nMathematics, Science, Global Competence\n\n\n2022\nMathematics\nReading literacy, Science, Creative thinking\n\n\n2025\nScience\nMathematics, Reading literacy, Learning in the Digital World",
    "crumbs": [
      "Appendicies",
      "PISA"
    ]
  },
  {
    "objectID": "chapters/A1-PISA_analysis.html#why-is-china-given-the-cnt-value-b-s-j-z-china-2018-or-b-s-j-g-china-2015",
    "href": "chapters/A1-PISA_analysis.html#why-is-china-given-the-cnt-value-b-s-j-z-china-2018-or-b-s-j-g-china-2015",
    "title": "PISA",
    "section": "\n4.14 Why is China given the CNT value B-S-J-Z (China) (2018) or B-S-J-G (China) (2015)?",
    "text": "4.14 Why is China given the CNT value B-S-J-Z (China) (2018) or B-S-J-G (China) (2015)?\nB-S-J-G/Z (China) is an acronym for Beijing, Shanghai, Jiangsu and Guangdong/Zhejiang, the four provinces/municipalities of the People’s Republic of China that take part in PISA data collection. Zhejiang took the place of Guangdong in the 2018 dataset. Several authors (including (Du and Wong 2019)) comment that sampling only from some of the most developed regions of China means the country’s data is unlikely to be nationally representative.",
    "crumbs": [
      "Appendicies",
      "PISA"
    ]
  },
  {
    "objectID": "chapters/A1-PISA_analysis.html#where-is-mainland-china-in-pisa-2022",
    "href": "chapters/A1-PISA_analysis.html#where-is-mainland-china-in-pisa-2022",
    "title": "PISA",
    "section": "\n4.15 Where is mainland China in PISA 2022?",
    "text": "4.15 Where is mainland China in PISA 2022?\n\nChinese provinces/municipalities (Beijing, Shanghai, Jiangsu and Zhejiang) and Lebanon are participants in PISA 2022 but were unable to collect data because schools were closed during the intended data collection period. - PISA 2022 participants",
    "crumbs": [
      "Appendicies",
      "PISA"
    ]
  },
  {
    "objectID": "chapters/A1-PISA_analysis.html#how-do-i-calculate-weighted-means-of-the-pv-scores",
    "href": "chapters/A1-PISA_analysis.html#how-do-i-calculate-weighted-means-of-the-pv-scores",
    "title": "PISA",
    "section": "\n4.16 How do I calculate weighted means of the PV scores?",
    "text": "4.16 How do I calculate weighted means of the PV scores?\nYou can use a function written by Miguel Diaz Kusztrick, here is his slightly tidied function for calculating weighted means and standard deviations (original link):\n\n# Copyright Miguel Diaz Kusztrick\nwght_meansd_pv &lt;- function(sdata, pv, weight, brr) {\n    mmeans  &lt;- c(0, 0, 0, 0)\n    names(mmeans) &lt;- c(\"MEAN\",\"SE-MEAN\",\"STDEV\",\"SE-STDEV\")\n    \n    mmeanspv &lt;- rep(0,length(pv))\n    stdspv   &lt;- rep(0,length(pv))\n    mmeansbr &lt;- rep(0,length(pv))\n    stdsbr   &lt;- rep(0,length(pv))\n    sum_weight &lt;- sum(sdata[,weight])\n    \n    for (i in 1:length(pv)) {\n        mmeanspv[i] &lt;- sum(sdata[,weight]*sdata[,pv[i]])/sum_weight\n        stdspv[i]   &lt;- sqrt((sum(sdata[,weight]*(sdata[,pv[i]]^2))/swght)-mmeanspv[i]^2)\n        for (j in 1:length(brr)) {\n            sbrr&lt;-sum(sdata[,brr[j]])\n            mbrrj&lt;-sum(sdata[,brr[j]]*sdata[,pv[i]])/sbrr\n            mmeansbr[i]&lt;-mmeansbr[i] + (mbrrj - mmeanspv[i])^2\n            stdsbr[i]&lt;-stdsbr[i] + (sqrt((sum(sdata[,brr[j]]*(sdata[,pv[i]]^2))/sbrr)-mbrrj^2) - stdspv[i])^2\n        }       \n    }\n    mmeans[1] &lt;- sum(mmeanspv) / length(pv)\n    mmeans[2] &lt;- sum((mmeansbr * 4) / length(brr)) / length(pv)\n    mmeans[3] &lt;- sum(stdspv) / length(pv)\n    mmeans[4] &lt;- sum((stdsbr * 4) / length(brr)) / length(pv)\n    ivar &lt;- c(0,0)\n    \n    for (i in 1:length(pv)) {\n        ivar[1] &lt;- ivar[1] + (mmeanspv[i] - mmeans[1])^2;\n        ivar[2] &lt;- ivar[2] + (stdspv[i] - mmeans[3])^2;\n    }\n    ivar = (1 + (1 / length(pv))) * (ivar / (length(pv) - 1));\n    mmeans[2] &lt;- sqrt(mmeans[2] + ivar[1]);\n    mmeans[4] &lt;- sqrt(mmeans[4] + ivar[2]);\n    return(mmeans);\n}",
    "crumbs": [
      "Appendicies",
      "PISA"
    ]
  },
  {
    "objectID": "chapters/A1-PISA_analysis.html#empty-fields",
    "href": "chapters/A1-PISA_analysis.html#empty-fields",
    "title": "PISA",
    "section": "\n5.1 Empty fields",
    "text": "5.1 Empty fields\nAll 2022 school responses to questions about the clubs and extra curricular activities run in a school SC053Q____ are coded as NA, as are SC207____. It’s not clear why this data is included in the dataset or whether this data should have values but doesn’t. These (albeit empty) fields are included in the full PISA_school_2022.parquet file linked above.\n\nCodeclub_flds &lt;- c(\"SC053Q01TA\",\"SC053Q02TA\",\"SC053Q03TA\",\"SC053Q04TA\",\"SC053Q05NA\",\n               \"SC053Q06NA\",\"SC053Q07TA\",\"SC053Q08TA\",\"SC053Q09TA\",\"SC053Q10TA\")\n\nPISA_2022_school %&gt;% \n  select(c(\"CNT\", starts_with(\"SC053Q\"), starts_with(\"SC207\"))) %&gt;% \n  group_by(CNT) %&gt;%\n  pivot_longer(-CNT, \n               names_to = \"club\",\n               values_to = \"present\") %&gt;%\n  filter(!is.na(present)) %&gt;%\n  pull(club) %&gt;% \n  unique()\n\n# Note: SC053D11TA is present:\n# &lt;This academic year&gt;,follow. activities/school offers&lt;national modal grade for 15-year-olds&gt;? &lt;country specific item&gt;\n\n\nAdditionally, creativity fields stored in ST334_____, ST340_____, ST341_____, PA185_____ and CREA____ on the student questionnaire are missing answers for all countries:\n\nCodePISA_2022 %&gt;% \n  select(c(\"CNT\", \"IMAGINE\", \n           starts_with(\"ST334\"),\n           starts_with(\"ST340\"), \n           starts_with(\"ST341\"),\n           starts_with(\"PA185\"),\n           starts_with(\"CREA\"))) %&gt;% \n  mutate(across(everything(), as.numeric)) %&gt;%\n  group_by(CNT) %&gt;%\n  pivot_longer(-CNT, \n               names_to = \"creativity\",\n               values_to = \"present\") %&gt;%\n  filter(!is.na(present)) %&gt;%\n  pull(creativity) %&gt;% \n  unique()",
    "crumbs": [
      "Appendicies",
      "PISA"
    ]
  },
  {
    "objectID": "chapters/A1-PISA_analysis.html#cyprus-present-but-missing",
    "href": "chapters/A1-PISA_analysis.html#cyprus-present-but-missing",
    "title": "PISA",
    "section": "\n5.2 Cyprus present but missing",
    "text": "5.2 Cyprus present but missing\nCyprus is still present in the levels of CNT even though PISA hasn’t recorded data on Cyprus since 2012. Other countries that didn’t participate in the 2022 round have been removed from the levels, e.g. China.\n\nCodecountries &lt;- PISA_2022 %&gt;% pull(CNT) %&gt;% unique()\ncountry_lvls &lt;- PISA_2022 %&gt;% pull(CNT) %&gt;% levels()\nsetdiff(country_lvls, countries)",
    "crumbs": [
      "Appendicies",
      "PISA"
    ]
  },
  {
    "objectID": "chapters/A1-PISA_analysis.html#great-britain-vs-the-united-kingdom",
    "href": "chapters/A1-PISA_analysis.html#great-britain-vs-the-united-kingdom",
    "title": "PISA",
    "section": "\n5.3 Great Britain vs the United Kingdom",
    "text": "5.3 Great Britain vs the United Kingdom\nThe United Kingdom is the country referred to when correctly combining the results of England, Scotland, Wales and Northern Ireland. However, the regions of the United Kingdom listed by the OECD are “Great Britain:” followed by England, Scotland, Wales and Northern Ireland. Northern Ireland isn’t part of Great Britain.\n\nCodePISA_2022 %&gt;% select(CNT, REGION) %&gt;% \n  filter(grepl(\"Great Britain\", REGION)) %&gt;% distinct()\n\n# A tibble: 4 × 2\n  CNT            REGION                         \n  &lt;fct&gt;          &lt;fct&gt;                          \n1 United Kingdom Great Britain: Wales           \n2 United Kingdom Great Britain: Northern Ireland\n3 United Kingdom Great Britain: England         \n4 United Kingdom Great Britain: Scotland",
    "crumbs": [
      "Appendicies",
      "PISA"
    ]
  },
  {
    "objectID": "chapters/A8-SEM.html",
    "href": "chapters/A8-SEM.html",
    "title": "SEM",
    "section": "",
    "text": "Structural Equation Modelling (SEM) is an approach to represent the correlations between a number of variables linked to some phenomenon. A dependent variable (for example, scores on some test) might be linked to a number of independent variables (for example, hours of study, teacher’s level of experience, etc.). A powerful aspect of SEM is that it can be used to construct latent variables - variables which have explanatory usefulness but can’t be measured directly.\nFor example, a researcher might wish to investigate how home environment impacts students’ mathematics achievement. There is no single variable, no single score, that can be measured to say a young person’s home environment is a 7/10 or a 3/10. We might then consider their home environment a latent variable. We imagine that the nature of the circumstances in their home impacts their learning, but we cannot directly report the level of the home environment as a variable.\nSEM allows us to propose a latent variable, like home environment, and calculate the contribution of a number of variables we can measure (e.g. the number of books in the home, parents’ occupation and level of education, family wealth, etc.) to the latent variable.\n\nResearchers use SEM to determine the correlations between a number of variable in a data set. It allows the relationship between multiple variables to be taken into account.\nIn the PISA data set, in the context of data related to UK students achievement in mathematics, a researcher might be interested in building a model of mathematics (PV1MATH) score by a number of variables in the data set, for example, reading score PV1READ), science score (PV1SCIE), family cultural capital (the index of economic, social and cultural status ESCS), wealth (WEALTH) and gender (ST004D01T). SEM can be used to represent the relationship between these variables and students’ mathematics achievement.\nTo create the SEM we will use the lavaan package - lavaan is a contraction of Latent Variable Analysis and allows us to fit a number of different SEMs to data. We will also need to install the semPlot package. The relationships between variables in SEMs are often represented as path diagrams - representations in which variables are represented as squares or circles and arrows labelled with correlation coefficients join the variables to represent the relationships.semPlot allows use to draw path diagrams\n\nTo create the SEM of UK mathematics achievement we first create a subset data.frame of UK data, UKdata. As lavaan uses numeric variables we need to convert gender (ST004D01T) to a numeric variable.\n\n# Load lavaan to create the SEM and semPlot to draw path diagrams\nlibrary(lavaan)\nlibrary(semPlot)\n# Create a subset of PISA data related to the UK containing the dependent variable of interest (PV1MATH) and the independent variables we are interested in\nUKdata&lt;-PISA_2022 %&gt;%\n  select(CNT, PV1SCIE, PV1MATH, PV1READ, ESCS, HOMEPOS, ST004D01T)%&gt;%\n  filter(CNT==\"United Kingdom\")\n# lavaan requires numeric variables as input, gender is a character varibale in the data.frame so convert it.\nUKdata$ST004D01T&lt;-as.numeric(UKdata$ST004D01T)\n\nThe first step is to create the model. Models in lavaan are represented as a dependent variable y, linked to a number of independent variables x1, x2, x3, etc. The ~ symbol is the regression operator. A simple regression forumla might then take the form of:\ny ~ x1 + x2 + x3\nTo indicate a variable is a latent variable we use the =~ operator. So to define a model in which the latent variable f1 varies with three indepdent variables we would write:\nf1 =~ x1 + x2 + x3\nIn some cases, the independent variables may correlate. For example, if we are investigating mathematics achievement (the dependent variable, y), by looking at the independent variables of reading (x1) and science score (x2), it may be the case that reading and science cores covary (that is changes to one impacts the other). In this case, we can specify covariance in our model by stating:\ny ~ x1 + x2 The regression model x1 ~ x2 Indicating the covariance\nIn our case, considering UK mathematics achievement, we can set up a model that mathematics score PV1MATH varies with science score PV1SCIE, reading score PV1READ, cultural resources in the home ESCS, a wealth proxy measure, HOMEPOS and gender ST004D01T: model&lt;-\"PV1MATH ~ PV1SCIE + PV1READ + ESCS + HOMEPOS\"\nWe then pass the model, and the data.frame to the sem function: fit&lt;-sem(model, data=UKdata). This produces a model as the ouput fit. To see the results we call summary(fit)\n\nmodel&lt;-\"PV1MATH ~ PV1SCIE + PV1READ + ESCS + HOMEPOS\"\nfit&lt;-sem(model, data=UKdata)\nsummary(fit)\n\nlavaan 0.6-19 ended normally after 1 iteration\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                         5\n\n                                                  Used       Total\n  Number of observations                         11083       12972\n\nModel Test User Model:\n                                                      \n  Test statistic                                 0.000\n  Degrees of freedom                                 0\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nRegressions:\n                   Estimate   Std.Err  z-value  P(&gt;|z|)\n  PV1MATH ~                                            \n    PV1SCIE            0.565    0.007   85.604    0.000\n    PV1READ            0.267    0.006   41.953    0.000\n    ESCS               5.432    0.734    7.404    0.000\n    HOMEPOS            1.027    0.716    1.434    0.151\n\nVariances:\n                   Estimate   Std.Err  z-value  P(&gt;|z|)\n   .PV1MATH         2006.033   26.948   74.441    0.000\n\n\nIn the regressions table, the function returns the value of the regression coefficients for each independent variable, and the P value (P(&gt;|z|)). Note in the model above all the independent variables are significant, but the largest loading comes from the WEALTH variable, with the science (PV1SCIE) and reading (PV1READ) scores contributing comparatively little.\nFinally, to produce a visual representation of the model, we pass our model, fit to the semPaths function (from the semPlot package we loaded above). We can specify was we want displayed on the lines, in this case the estimate of the regression coefficients between the variables.\n\n\n\n\n\n\n\n\nIn path diagrams, directly measured variables, manifest variables, are shown as squares. Latent variables are represented as circles. Single headed arrows represent the regression effects between variables. The curved arrows starting and ending on a square or circle indicate the variances of those variables. When curved arrows start and end on different variables, they represent covariance.\nOne issue to note here is the difference in the variance for the science and mathematics scores. PV1SCIE, PV1READ and PV1MATH are test scores and so have a large variance (the maximum and minimum science scores, for example, are 0.0 and 895.4). The variance of the two test variables is much greater that for HOMEPOS (Min=-10.0741 mean=-0.4447, Max=15.240) and ESCS (Min=-6.841 mean=-0.310, Max=7.380).\nTo resolve this difference, we can use the scale function to create a similar scale for PV1SCIE, PV1MATH and PV1READ. The scale function sets the mean of the variable to 0 and the variance to 1.\n\nUKdata$PV1READ&lt;-scale(UKdata$PV1READ)\nUKdata$PV1MATH&lt;-scale(UKdata$PV1MATH)\nUKdata$PV1SCIE&lt;-scale(UKdata$PV1SCIE)\n\nfit&lt;-sem(model, data=UKdata)\nsummary(fit)\n\nlavaan 0.6-19 ended normally after 1 iteration\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                         5\n\n                                                  Used       Total\n  Number of observations                         11083       12972\n\nModel Test User Model:\n                                                      \n  Test statistic                                 0.000\n  Degrees of freedom                                 0\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nRegressions:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  PV1MATH ~                                           \n    PV1SCIE           0.607    0.007   85.604    0.000\n    PV1READ           0.295    0.007   41.953    0.000\n    ESCS              0.057    0.008    7.404    0.000\n    HOMEPOS           0.011    0.008    1.434    0.151\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .PV1MATH           0.222    0.003   74.441    0.000\n\nsemPaths(fit, whatLabels = \"Estimate\")\n\n\n\n\n\n\n\nScaling the test scores gives a more balanced model.\nWe can make the model more complex, by adding that two or our independent variables, reading (PV1READ) and science (PV1SCIE) scores may co-vary, and vary with other independent variables.\n\nmodel&lt;-\"PV1MATH ~ PV1SCIE + PV1READ + ESCS + HOMEPOS\n        PV1READ ~~ PV1SCIE\n        PV1READ ~ PV1SCIE + PV1MATH + ESCS + HOMEPOS\n        PV1SCIE ~ PV1READ + PV1MATH + ESCS + HOMEPOS\"\nfit&lt;-sem(model, data=UKdata)\nsummary(fit)\n\nlavaan 0.6-19 ended normally after 23 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        16\n\n                                                  Used       Total\n  Number of observations                         11083       12972\n\nModel Test User Model:\n                                                      \n  Test statistic                                    NA\n  Degrees of freedom                                -4\n  P-value (Unknown)                                 NA\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nRegressions:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  PV1MATH ~                                           \n    PV1SCIE           0.454       NA                  \n    PV1READ           0.171       NA                  \n    ESCS              0.113       NA                  \n    HOMEPOS           0.071       NA                  \n  PV1READ ~                                           \n    PV1SCIE           0.242       NA                  \n    PV1MATH           0.386       NA                  \n [ reached getOption(\"max.print\") -- omitted 7 rows ]\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n .PV1READ ~~                                          \n   .PV1SCIE           0.065       NA                  \n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .PV1MATH           0.282       NA                  \n   .PV1READ           0.383       NA                  \n   .PV1SCIE           0.340       NA                  \n\nsemPaths(fit)\n\n\n\n\n\n\nsemPaths(fit, whatLabels = \"Estimate\")\n\n\n\n\n\n\n\n\nAs introduced above, we can use SEM to model a latent variable. For example, we might assume that students have some underlying variable linked to their general intelligence. However, we have no way to directly measure their general intelligence. We do have data on their achievement in science (PV1SCIE), mathematics (PV1MATH) and reading (PV1READ) we might assume that as the latent variable of general achievement increases so does achievement in science, mathematics and reading.\nTo perform the analysis, we use the =~ operator in our model, which indicates a latent variable. This time, our model then sets out that we are interested in a lv (latent variable) which varies with science (PV1SCIE), mathematics (PV1MATH) and reading (PV1READ) scores:\nmodel&lt;-“lv =~ PV1SCIE + PV1READ + PV1MATH”\nThen we run the model using sem in the same way as above, and plot the model using semPaths.\n\n# For a latent variable\n# =~ means a latent variable\nmodel&lt;-\"lv =~ PV1SCIE + PV1READ + PV1MATH\"\n\nfit&lt;-sem(model, data=UKdata)\nsummary(fit)\n\nlavaan 0.6-19 ended normally after 18 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                         6\n\n  Number of observations                         12972\n\nModel Test User Model:\n                                                      \n  Test statistic                                 0.000\n  Degrees of freedom                                 0\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  lv =~                                               \n    PV1SCIE           1.000                           \n    PV1READ           0.919    0.006  143.596    0.000\n    PV1MATH           1.015    0.006  175.355    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .PV1SCIE           0.145    0.003   43.323    0.000\n   .PV1READ           0.278    0.004   66.360    0.000\n   .PV1MATH           0.119    0.003   36.723    0.000\n    lv                0.855    0.013   67.872    0.000\n\nsemPaths(fit, whatLabels = \"Estimate\")\n\n\n\n\n\n\n\nThe mode raises the question of how strong does correlation between independent variables and a proposed latent variable need to be. Cho and colleagues Cho et al. (2020) suggest that:\n\n“When N = 100, researchers may choose a GFI [Meaning Goodness-of-Fit Index] cutoff value of .89 …When N &gt; 100, researchers may choose a GFI cutoff value of .93” (Cho et al. 2020, 197)\n\nWe can develop a more complex latent variable model. Let us assume that UK students reading scores depend on two latent variables, home environment (e.g. number of books, parental level of education etc) and cognitive ability (e.g. as reported by science and mathematics scores). Here are some relevant variables:\n\n\n\n\n\n\nItem name\nDescription\n\n\n\nST005Q01JA\nWhat is the  completed by your mother?\n\n\n\nST007Q01JA\nWhat is the  completed by your father?\n\n\n\nST256Q02JA\nIn your home: Classic literature (e.g. )\n\n\n\nST255Q01JA\nHow many books are there in your home?\n\n\nHOMEPOS\nFamily Wealth\n\n\n\n\n# Create a UK dataframe with plausible values\nUKdata&lt;-PISA_2022%&gt;%\n  select(CNT, ESCS, HOMEPOS, ST007Q01JA, ST256Q02JA, ST255Q01JA,\n         PV1READ, PV1SCIE, PV1MATH)%&gt;%\n  filter(CNT==\"United Kingdom\")\n\n# Make varibale numeric for lavan\nUKdata$ST007Q01JA&lt;-as.numeric(UKdata$ST007Q01JA)\nUKdata$ST256Q02JA&lt;-as.numeric(UKdata$ST256Q02JA)\nUKdata$ST255Q01JA&lt;-as.numeric(UKdata$ST255Q01JA)\n\n\n# Scale the test scores\nUKdata$PV1READ&lt;-scale(UKdata$PV1READ)\nUKdata$PV1MATH&lt;-scale(UKdata$PV1MATH)\nUKdata$PV1SCIE&lt;-scale(UKdata$PV1SCIE)\n# Propose a model with two latent variables - one related to home (lvh), the other cognitive ability (lva)\nmodel&lt;-\"lvi =~ ESCS + HOMEPOS + ST007Q01JA + ST256Q02JA + ST255Q01JA\n        lvc =~ PV1MATH + PV1READ\n        PV1SCIE ~ lvi + lvc\"\n# Fit the model\nfit&lt;-sem(model, data=UKdata)\nsummary(fit)\n\nlavaan 0.6-19 ended normally after 32 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        18\n\n                                                  Used       Total\n  Number of observations                          9156       12972\n\nModel Test User Model:\n                                                      \n  Test statistic                              1743.454\n  Degrees of freedom                                18\n  P-value (Chi-square)                           0.000\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  lvi =~                                              \n    ESCS              1.000                           \n    HOMEPOS           1.133    0.012   91.099    0.000\n    ST007Q01JA       -0.435    0.012  -37.662    0.000\n    ST256Q02JA        0.947    0.020   46.529    0.000\n    ST255Q01JA        1.381    0.019   72.078    0.000\n  lvc =~                                              \n    PV1MATH           1.000                           \n [ reached getOption(\"max.print\") -- omitted 1 row ]\n\nRegressions:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  PV1SCIE ~                                           \n    lvi               0.012    0.009    1.326    0.185\n    lvc               0.991    0.008  121.309    0.000\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  lvi ~~                                              \n    lvc               0.282    0.008   33.407    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .ESCS              0.239    0.005   46.204    0.000\n   .HOMEPOS           0.148    0.005   28.609    0.000\n   .ST007Q01JA        0.495    0.007   66.043    0.000\n   .ST256Q02JA        1.448    0.022   65.016    0.000\n   .ST255Q01JA        0.963    0.016   58.664    0.000\n   .PV1MATH           0.122    0.004   30.114    0.000\n   .PV1READ           0.293    0.005   56.485    0.000\n   .PV1SCIE           0.155    0.004   36.360    0.000\n [ reached getOption(\"max.print\") -- omitted 2 rows ]\n\nsemPaths(fit, whatLabels = \"Estimate\")\n\n\n\n\n\n\n\nInteresting features to note are a) the much higher loading of the cognitive latent variable (lvc has a loading of 0.71) than the home environment (liv, loading 0.02); b) the roughly equal contribution of mathematics and reading scores to lvb (the cognitive ability latent variable); c) and interesting to note the negative loadings of parental education (ST005, and ST007) on the home enviroment latent variable.\nNote the dotted line from the ESCS variable (truncated here to ESC) indicates that ESCS is acting as a marker variable, that is, it is fixed at 1.0, and the other variables determined relative to it. The same is true for PV1MATH for the ability latent variable.\n\nThere are a number of formatting options in the semPaths function.\nStarting from this plot:\n\nsemPaths(fit, whatLabels = \"Estimate\") \n\n\n\n\n\n\n\n\nTo rotate the plot (rotation=2):\n\n\nsemPaths(fit, whatLabels = \"Estimate\", rotation=2) \n\n\n\n\n\n\n\n\nTo change the colour of the lines (edge.color=\"blue\") and the size of the nodes (sizeMan=8):\n\n\nsemPaths(fit, whatLabels = \"Estimate\", rotation=2, edge.color=\"blue\", sizeMan =8) \n\n\n\n\n\n\n\n\nTo link the thickness of lines to their value (\"std\"):\n\n\nsemPaths(fit, whatLabels = \"Estimate\", rotation=2, edge.color=\"blue\", \n         sizeMan =5, \"std\") \n\n\n\n\n\n\n\n\nTo make the labels larger (edge.label.cex = 0.8):\n\n\nsemPaths(fit, whatLabels = \"Estimate\", rotation=2, edge.color=\"blue\", \n         sizeMan =5, \"std\", edge.label.cex = 0.8) \n\n\n\n\n\n\n\n\nTo add a title (title(\"PISA path diagram\")):\n\n\nsemPaths(fit, whatLabels = \"Estimate\", rotation=2, edge.color=\"blue\", \n         sizeMan =5, \"std\", edge.label.cex = 0.8) \ntitle(\"PISA path diagram\")\n\n\n\n\n\n\n\n\nTo give longer node names (nodeNames=nodenames):\n\n\nnodenames&lt;-c(\"Economic, social and cultural status\",\n             \"Wealth\",\"Maternal Schooling\",\"Paternal Schooling\",\n             \"In home: classical literature\",\"Books in home\",\n             \"Math score\", \"Reading score\", \"Science Score\")\nsemPaths(fit, whatLabels = \"Estimate\", rotation=2, edge.color=\"blue\", \n         sizeMan =5, \"std\",, edge.label.cex = 0.8, nodeNames=nodenames)\ntitle(\"PISA path diagram\")\n\n\n\n\n\n\n\n\n\n\nMake a SEM of reading scores in the PISA data for students in the United States. Consider co-variation between independent variables. First consider what independent variables in the data set might influence reading scores. Some potential items of interest include:\n\n\n\n\n\n\nItem name\nDescription\n\n\n\nST005Q01JA\nWhat is the  completed by your mother?\n\n\n\nST007Q01JA\nWhat is the  completed by your father?\n\n\n\nST256Q02JA\nIn your home: Classic literature (e.g. )\n\n\n\nST255Q01JA\nHow many books are there in your home?\n\n\nHOMEPOS\nFamily Wealth\n\n\nESCS\nIndex of economic, social and cultural status\n\n\nST254Q02JA\nHow many of the following [digital devices] are in your\n\n\n\n[home]: Desktop computers\n\n\n\n\n::: call-out warning\nDon’t forget to convert any non-numeric variables to numeric\n:::\n\n# Using ST255Q01JA  How many books are there in your home?\n# ST254Q02JA    How many in your home: Computers (desktop computer, portable laptop, or notebook)\nUSdata&lt;-PISA_2022%&gt;%\n  select(CNT, ESCS, HOMEPOS, PV1READ, ST255Q01JA, ST254Q02JA)%&gt;%\n  filter(CNT==\"United States\")\n# Making ST255Q01JA and ST012Q06NA numeric\nUSdata$ST255Q01JA&lt;-as.numeric(USdata$ST255Q01JA)\nUSdata$ST254Q02JA&lt;-as.numeric(USdata$ST254Q02JA)\n\n\nmodel&lt;-\"PV1READ ~ ESCS + HOMEPOS + ST255Q01JA+ ST254Q02JA\"\n\nfit&lt;-sem(model, data=USdata)\nsummary(fit)\n\nlavaan 0.6-19 ended normally after 1 iteration\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                         5\n\n                                                  Used       Total\n  Number of observations                          4163        4552\n\nModel Test User Model:\n                                                      \n  Test statistic                                 0.000\n  Degrees of freedom                                 0\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nRegressions:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  PV1READ ~                                           \n    ESCS             14.866    2.326    6.390    0.000\n    HOMEPOS          15.340    2.984    5.141    0.000\n    ST255Q01JA       21.151    1.413   14.965    0.000\n    ST254Q02JA      -20.733    2.150   -9.642    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .PV1READ        9987.581  218.913   45.623    0.000\n\nsemPaths(fit, whatLabels = \"Estimate\")\n\n\n\n\n\n\n\n\n\nThere are a number of variables in the PISA data set that could be used to model the home environment (e.g. Number of books in the home, number of computers, etc.). Using the home environment for UK students as a latent variable, create a model of the home environment.\n\n::: call-out warning\nDon’t forget to convert any non-numeric variables to numeric\n:::\n\n# Using ST251Q06JA  How many of these items are there at your [home]: Musical instruments (e.g. guitar, piano, [country-specific example])\n# and ST251Q07JA    How many of these items are there at your [home]: Works of art (e.g. paintings, sculptures, [country-specific example])\nUKdata&lt;-PISA_2022%&gt;%\n  select(CNT, ESCS, HOMEPOS, ST251Q06JA, ST251Q07JA)%&gt;%\n  filter(CNT==\"United Kingdom\")\n# Making variables numeric\nUKdata$ST251Q06JA&lt;-as.numeric(UKdata$ST251Q06JA)\nUKdata$ST251Q07JA&lt;-as.numeric(UKdata$ST251Q07JA)\nmodel&lt;-\"lv =~ ESCS + HOMEPOS + ST251Q06JA + ST251Q07JA \"\n\nfit&lt;-sem(model, data=UKdata)\nsummary(fit)\n\nlavaan 0.6-19 ended normally after 23 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                         8\n\n                                                  Used       Total\n  Number of observations                         10916       12972\n\nModel Test User Model:\n                                                      \n  Test statistic                                86.359\n  Degrees of freedom                                 2\n  P-value (Chi-square)                           0.000\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  lv =~                                               \n    ESCS              1.000                           \n    HOMEPOS           1.278    0.016   82.129    0.000\n    ST251Q06JA        0.930    0.016   58.374    0.000\n    ST251Q07JA        0.936    0.018   52.611    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .ESCS              0.312    0.006   51.116    0.000\n   .HOMEPOS           0.054    0.007    7.564    0.000\n   .ST251Q06JA        0.960    0.014   70.282    0.000\n   .ST251Q07JA        1.263    0.018   71.398    0.000\n    lv                0.474    0.011   44.235    0.000\n\nsemPaths(fit, whatLabels = \"Estimate\")\n\n\n\n\n\n\n\n\n\nYou believe that there are two latent variables underlying UK students’ performance in science - a science self-identity variable (related to the home environment, for example, gender, parents’ level of education) and a cognitive ability variable (indicated by performance in other subjects). Propose a model of science performance based on these two latent variables - linking each latent variable to multiple independent variables. Determine how much variance your model explains\n\n::: call-out warning\nDon’t forget to convert any non-numeric variables to numeric and consider scaling the test scores\n:::\n\n# Create a UK data frame with plausible values\nUKdata&lt;-PISA_2022%&gt;%\n  select(CNT, ESCS, HOMEPOS, ST005Q01JA, ST007Q01JA, PV1READ, PV1SCIE, \n         PV1MATH, ST004D01T)%&gt;%\n  filter(CNT==\"United Kingdom\")\n# Convert to numeric where not numeric\nUKdata$ST005Q01JA&lt;-as.numeric(UKdata$ST005Q01JA)\nUKdata$ST007Q01JA&lt;-as.numeric(UKdata$ST007Q01JA)\nUKdata$ST004D01T&lt;-as.numeric(UKdata$ST004D01T)\n\n# Scale the test scores\nUKdata$PV1READ&lt;-scale(UKdata$PV1READ)\nUKdata$PV1MATH&lt;-scale(UKdata$PV1MATH)\nUKdata$PV1SCIE&lt;-scale(UKdata$PV1SCIE)\n# Propose a model with two latent variables - one related to identity (lvi), the other ability (lva)\nmodel&lt;-\"lvi =~ ESCS + HOMEPOS + ST005Q01JA + ST007Q01JA + ST004D01T\n        lva =~ PV1MATH + PV1READ\n        PV1SCIE ~ lvi + lva\"\n# Fit the model\nfit&lt;-sem(model, data=UKdata)\nsummary(fit)\n\nlavaan 0.6-19 ended normally after 34 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        18\n\n                                                  Used       Total\n  Number of observations                          9683       12972\n\nModel Test User Model:\n                                                      \n  Test statistic                              1738.699\n  Degrees of freedom                                18\n  P-value (Chi-square)                           0.000\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  lvi =~                                              \n    ESCS              1.000                           \n    HOMEPOS           0.833    0.010   79.702    0.000\n    ST005Q01JA       -0.430    0.008  -51.306    0.000\n    ST007Q01JA       -0.437    0.009  -47.015    0.000\n    ST004D01T         0.001    0.006    0.175    0.861\n  lva =~                                              \n    PV1MATH           1.000                           \n [ reached getOption(\"max.print\") -- omitted 1 row ]\n\nRegressions:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  PV1SCIE ~                                           \n    lvi               0.004    0.007    0.518    0.605\n    lva               0.991    0.008  131.633    0.000\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  lvi ~~                                              \n    lva               0.312    0.009   33.677    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .ESCS              0.046    0.007    7.049    0.000\n   .HOMEPOS           0.327    0.007   49.672    0.000\n   .ST005Q01JA        0.366    0.005   67.130    0.000\n   .ST007Q01JA        0.470    0.007   67.762    0.000\n   .ST004D01T         0.250    0.004   69.581    0.000\n   .PV1MATH           0.122    0.004   30.788    0.000\n   .PV1READ           0.296    0.005   57.937    0.000\n   .PV1SCIE           0.157    0.004   37.728    0.000\n [ reached getOption(\"max.print\") -- omitted 2 rows ]\n\nsemPaths(fit, whatLabels = \"Estimate\")",
    "crumbs": [
      "Additional tests",
      "SEM"
    ]
  },
  {
    "objectID": "chapters/A8-SEM.html#model-syntax",
    "href": "chapters/A8-SEM.html#model-syntax",
    "title": "SEM",
    "section": "",
    "text": "To create the SEM of UK mathematics achievement we first create a subset data.frame of UK data, UKdata. As lavaan uses numeric variables we need to convert gender (ST004D01T) to a numeric variable.\n\n# Load lavaan to create the SEM and semPlot to draw path diagrams\nlibrary(lavaan)\nlibrary(semPlot)\n# Create a subset of PISA data related to the UK containing the dependent variable of interest (PV1MATH) and the independent variables we are interested in\nUKdata&lt;-PISA_2022 %&gt;%\n  select(CNT, PV1SCIE, PV1MATH, PV1READ, ESCS, HOMEPOS, ST004D01T)%&gt;%\n  filter(CNT==\"United Kingdom\")\n# lavaan requires numeric variables as input, gender is a character varibale in the data.frame so convert it.\nUKdata$ST004D01T&lt;-as.numeric(UKdata$ST004D01T)\n\nThe first step is to create the model. Models in lavaan are represented as a dependent variable y, linked to a number of independent variables x1, x2, x3, etc. The ~ symbol is the regression operator. A simple regression forumla might then take the form of:\ny ~ x1 + x2 + x3\nTo indicate a variable is a latent variable we use the =~ operator. So to define a model in which the latent variable f1 varies with three indepdent variables we would write:\nf1 =~ x1 + x2 + x3\nIn some cases, the independent variables may correlate. For example, if we are investigating mathematics achievement (the dependent variable, y), by looking at the independent variables of reading (x1) and science score (x2), it may be the case that reading and science cores covary (that is changes to one impacts the other). In this case, we can specify covariance in our model by stating:\ny ~ x1 + x2 The regression model x1 ~ x2 Indicating the covariance\nIn our case, considering UK mathematics achievement, we can set up a model that mathematics score PV1MATH varies with science score PV1SCIE, reading score PV1READ, cultural resources in the home ESCS, a wealth proxy measure, HOMEPOS and gender ST004D01T: model&lt;-\"PV1MATH ~ PV1SCIE + PV1READ + ESCS + HOMEPOS\"\nWe then pass the model, and the data.frame to the sem function: fit&lt;-sem(model, data=UKdata). This produces a model as the ouput fit. To see the results we call summary(fit)\n\nmodel&lt;-\"PV1MATH ~ PV1SCIE + PV1READ + ESCS + HOMEPOS\"\nfit&lt;-sem(model, data=UKdata)\nsummary(fit)\n\nlavaan 0.6-19 ended normally after 1 iteration\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                         5\n\n                                                  Used       Total\n  Number of observations                         11083       12972\n\nModel Test User Model:\n                                                      \n  Test statistic                                 0.000\n  Degrees of freedom                                 0\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nRegressions:\n                   Estimate   Std.Err  z-value  P(&gt;|z|)\n  PV1MATH ~                                            \n    PV1SCIE            0.565    0.007   85.604    0.000\n    PV1READ            0.267    0.006   41.953    0.000\n    ESCS               5.432    0.734    7.404    0.000\n    HOMEPOS            1.027    0.716    1.434    0.151\n\nVariances:\n                   Estimate   Std.Err  z-value  P(&gt;|z|)\n   .PV1MATH         2006.033   26.948   74.441    0.000\n\n\nIn the regressions table, the function returns the value of the regression coefficients for each independent variable, and the P value (P(&gt;|z|)). Note in the model above all the independent variables are significant, but the largest loading comes from the WEALTH variable, with the science (PV1SCIE) and reading (PV1READ) scores contributing comparatively little.\nFinally, to produce a visual representation of the model, we pass our model, fit to the semPaths function (from the semPlot package we loaded above). We can specify was we want displayed on the lines, in this case the estimate of the regression coefficients between the variables.\n\n\n\n\n\n\n\n\nIn path diagrams, directly measured variables, manifest variables, are shown as squares. Latent variables are represented as circles. Single headed arrows represent the regression effects between variables. The curved arrows starting and ending on a square or circle indicate the variances of those variables. When curved arrows start and end on different variables, they represent covariance.\nOne issue to note here is the difference in the variance for the science and mathematics scores. PV1SCIE, PV1READ and PV1MATH are test scores and so have a large variance (the maximum and minimum science scores, for example, are 0.0 and 895.4). The variance of the two test variables is much greater that for HOMEPOS (Min=-10.0741 mean=-0.4447, Max=15.240) and ESCS (Min=-6.841 mean=-0.310, Max=7.380).\nTo resolve this difference, we can use the scale function to create a similar scale for PV1SCIE, PV1MATH and PV1READ. The scale function sets the mean of the variable to 0 and the variance to 1.\n\nUKdata$PV1READ&lt;-scale(UKdata$PV1READ)\nUKdata$PV1MATH&lt;-scale(UKdata$PV1MATH)\nUKdata$PV1SCIE&lt;-scale(UKdata$PV1SCIE)\n\nfit&lt;-sem(model, data=UKdata)\nsummary(fit)\n\nlavaan 0.6-19 ended normally after 1 iteration\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                         5\n\n                                                  Used       Total\n  Number of observations                         11083       12972\n\nModel Test User Model:\n                                                      \n  Test statistic                                 0.000\n  Degrees of freedom                                 0\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nRegressions:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  PV1MATH ~                                           \n    PV1SCIE           0.607    0.007   85.604    0.000\n    PV1READ           0.295    0.007   41.953    0.000\n    ESCS              0.057    0.008    7.404    0.000\n    HOMEPOS           0.011    0.008    1.434    0.151\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .PV1MATH           0.222    0.003   74.441    0.000\n\nsemPaths(fit, whatLabels = \"Estimate\")\n\n\n\n\n\n\n\nScaling the test scores gives a more balanced model.\nWe can make the model more complex, by adding that two or our independent variables, reading (PV1READ) and science (PV1SCIE) scores may co-vary, and vary with other independent variables.\n\nmodel&lt;-\"PV1MATH ~ PV1SCIE + PV1READ + ESCS + HOMEPOS\n        PV1READ ~~ PV1SCIE\n        PV1READ ~ PV1SCIE + PV1MATH + ESCS + HOMEPOS\n        PV1SCIE ~ PV1READ + PV1MATH + ESCS + HOMEPOS\"\nfit&lt;-sem(model, data=UKdata)\nsummary(fit)\n\nlavaan 0.6-19 ended normally after 23 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        16\n\n                                                  Used       Total\n  Number of observations                         11083       12972\n\nModel Test User Model:\n                                                      \n  Test statistic                                    NA\n  Degrees of freedom                                -4\n  P-value (Unknown)                                 NA\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nRegressions:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  PV1MATH ~                                           \n    PV1SCIE           0.454       NA                  \n    PV1READ           0.171       NA                  \n    ESCS              0.113       NA                  \n    HOMEPOS           0.071       NA                  \n  PV1READ ~                                           \n    PV1SCIE           0.242       NA                  \n    PV1MATH           0.386       NA                  \n [ reached getOption(\"max.print\") -- omitted 7 rows ]\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n .PV1READ ~~                                          \n   .PV1SCIE           0.065       NA                  \n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .PV1MATH           0.282       NA                  \n   .PV1READ           0.383       NA                  \n   .PV1SCIE           0.340       NA                  \n\nsemPaths(fit)\n\n\n\n\n\n\nsemPaths(fit, whatLabels = \"Estimate\")\n\n\n\n\n\n\n\n\nAs introduced above, we can use SEM to model a latent variable. For example, we might assume that students have some underlying variable linked to their general intelligence. However, we have no way to directly measure their general intelligence. We do have data on their achievement in science (PV1SCIE), mathematics (PV1MATH) and reading (PV1READ) we might assume that as the latent variable of general achievement increases so does achievement in science, mathematics and reading.\nTo perform the analysis, we use the =~ operator in our model, which indicates a latent variable. This time, our model then sets out that we are interested in a lv (latent variable) which varies with science (PV1SCIE), mathematics (PV1MATH) and reading (PV1READ) scores:\nmodel&lt;-“lv =~ PV1SCIE + PV1READ + PV1MATH”\nThen we run the model using sem in the same way as above, and plot the model using semPaths.\n\n# For a latent variable\n# =~ means a latent variable\nmodel&lt;-\"lv =~ PV1SCIE + PV1READ + PV1MATH\"\n\nfit&lt;-sem(model, data=UKdata)\nsummary(fit)\n\nlavaan 0.6-19 ended normally after 18 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                         6\n\n  Number of observations                         12972\n\nModel Test User Model:\n                                                      \n  Test statistic                                 0.000\n  Degrees of freedom                                 0\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  lv =~                                               \n    PV1SCIE           1.000                           \n    PV1READ           0.919    0.006  143.596    0.000\n    PV1MATH           1.015    0.006  175.355    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .PV1SCIE           0.145    0.003   43.323    0.000\n   .PV1READ           0.278    0.004   66.360    0.000\n   .PV1MATH           0.119    0.003   36.723    0.000\n    lv                0.855    0.013   67.872    0.000\n\nsemPaths(fit, whatLabels = \"Estimate\")\n\n\n\n\n\n\n\nThe mode raises the question of how strong does correlation between independent variables and a proposed latent variable need to be. Cho and colleagues Cho et al. (2020) suggest that:\n\n“When N = 100, researchers may choose a GFI [Meaning Goodness-of-Fit Index] cutoff value of .89 …When N &gt; 100, researchers may choose a GFI cutoff value of .93” (Cho et al. 2020, 197)\n\nWe can develop a more complex latent variable model. Let us assume that UK students reading scores depend on two latent variables, home environment (e.g. number of books, parental level of education etc) and cognitive ability (e.g. as reported by science and mathematics scores). Here are some relevant variables:\n\n\n\n\n\n\nItem name\nDescription\n\n\n\nST005Q01JA\nWhat is the  completed by your mother?\n\n\n\nST007Q01JA\nWhat is the  completed by your father?\n\n\n\nST256Q02JA\nIn your home: Classic literature (e.g. )\n\n\n\nST255Q01JA\nHow many books are there in your home?\n\n\nHOMEPOS\nFamily Wealth\n\n\n\n\n# Create a UK dataframe with plausible values\nUKdata&lt;-PISA_2022%&gt;%\n  select(CNT, ESCS, HOMEPOS, ST007Q01JA, ST256Q02JA, ST255Q01JA,\n         PV1READ, PV1SCIE, PV1MATH)%&gt;%\n  filter(CNT==\"United Kingdom\")\n\n# Make varibale numeric for lavan\nUKdata$ST007Q01JA&lt;-as.numeric(UKdata$ST007Q01JA)\nUKdata$ST256Q02JA&lt;-as.numeric(UKdata$ST256Q02JA)\nUKdata$ST255Q01JA&lt;-as.numeric(UKdata$ST255Q01JA)\n\n\n# Scale the test scores\nUKdata$PV1READ&lt;-scale(UKdata$PV1READ)\nUKdata$PV1MATH&lt;-scale(UKdata$PV1MATH)\nUKdata$PV1SCIE&lt;-scale(UKdata$PV1SCIE)\n# Propose a model with two latent variables - one related to home (lvh), the other cognitive ability (lva)\nmodel&lt;-\"lvi =~ ESCS + HOMEPOS + ST007Q01JA + ST256Q02JA + ST255Q01JA\n        lvc =~ PV1MATH + PV1READ\n        PV1SCIE ~ lvi + lvc\"\n# Fit the model\nfit&lt;-sem(model, data=UKdata)\nsummary(fit)\n\nlavaan 0.6-19 ended normally after 32 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        18\n\n                                                  Used       Total\n  Number of observations                          9156       12972\n\nModel Test User Model:\n                                                      \n  Test statistic                              1743.454\n  Degrees of freedom                                18\n  P-value (Chi-square)                           0.000\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  lvi =~                                              \n    ESCS              1.000                           \n    HOMEPOS           1.133    0.012   91.099    0.000\n    ST007Q01JA       -0.435    0.012  -37.662    0.000\n    ST256Q02JA        0.947    0.020   46.529    0.000\n    ST255Q01JA        1.381    0.019   72.078    0.000\n  lvc =~                                              \n    PV1MATH           1.000                           \n [ reached getOption(\"max.print\") -- omitted 1 row ]\n\nRegressions:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  PV1SCIE ~                                           \n    lvi               0.012    0.009    1.326    0.185\n    lvc               0.991    0.008  121.309    0.000\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  lvi ~~                                              \n    lvc               0.282    0.008   33.407    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .ESCS              0.239    0.005   46.204    0.000\n   .HOMEPOS           0.148    0.005   28.609    0.000\n   .ST007Q01JA        0.495    0.007   66.043    0.000\n   .ST256Q02JA        1.448    0.022   65.016    0.000\n   .ST255Q01JA        0.963    0.016   58.664    0.000\n   .PV1MATH           0.122    0.004   30.114    0.000\n   .PV1READ           0.293    0.005   56.485    0.000\n   .PV1SCIE           0.155    0.004   36.360    0.000\n [ reached getOption(\"max.print\") -- omitted 2 rows ]\n\nsemPaths(fit, whatLabels = \"Estimate\")\n\n\n\n\n\n\n\nInteresting features to note are a) the much higher loading of the cognitive latent variable (lvc has a loading of 0.71) than the home environment (liv, loading 0.02); b) the roughly equal contribution of mathematics and reading scores to lvb (the cognitive ability latent variable); c) and interesting to note the negative loadings of parental education (ST005, and ST007) on the home enviroment latent variable.\nNote the dotted line from the ESCS variable (truncated here to ESC) indicates that ESCS is acting as a marker variable, that is, it is fixed at 1.0, and the other variables determined relative to it. The same is true for PV1MATH for the ability latent variable.\n\nThere are a number of formatting options in the semPaths function.\nStarting from this plot:\n\nsemPaths(fit, whatLabels = \"Estimate\") \n\n\n\n\n\n\n\n\nTo rotate the plot (rotation=2):\n\n\nsemPaths(fit, whatLabels = \"Estimate\", rotation=2) \n\n\n\n\n\n\n\n\nTo change the colour of the lines (edge.color=\"blue\") and the size of the nodes (sizeMan=8):\n\n\nsemPaths(fit, whatLabels = \"Estimate\", rotation=2, edge.color=\"blue\", sizeMan =8) \n\n\n\n\n\n\n\n\nTo link the thickness of lines to their value (\"std\"):\n\n\nsemPaths(fit, whatLabels = \"Estimate\", rotation=2, edge.color=\"blue\", \n         sizeMan =5, \"std\") \n\n\n\n\n\n\n\n\nTo make the labels larger (edge.label.cex = 0.8):\n\n\nsemPaths(fit, whatLabels = \"Estimate\", rotation=2, edge.color=\"blue\", \n         sizeMan =5, \"std\", edge.label.cex = 0.8) \n\n\n\n\n\n\n\n\nTo add a title (title(\"PISA path diagram\")):\n\n\nsemPaths(fit, whatLabels = \"Estimate\", rotation=2, edge.color=\"blue\", \n         sizeMan =5, \"std\", edge.label.cex = 0.8) \ntitle(\"PISA path diagram\")\n\n\n\n\n\n\n\n\nTo give longer node names (nodeNames=nodenames):\n\n\nnodenames&lt;-c(\"Economic, social and cultural status\",\n             \"Wealth\",\"Maternal Schooling\",\"Paternal Schooling\",\n             \"In home: classical literature\",\"Books in home\",\n             \"Math score\", \"Reading score\", \"Science Score\")\nsemPaths(fit, whatLabels = \"Estimate\", rotation=2, edge.color=\"blue\", \n         sizeMan =5, \"std\",, edge.label.cex = 0.8, nodeNames=nodenames)\ntitle(\"PISA path diagram\")",
    "crumbs": [
      "Additional tests",
      "SEM"
    ]
  },
  {
    "objectID": "chapters/A8-SEM.html#tasks",
    "href": "chapters/A8-SEM.html#tasks",
    "title": "SEM",
    "section": "",
    "text": "Make a SEM of reading scores in the PISA data for students in the United States. Consider co-variation between independent variables. First consider what independent variables in the data set might influence reading scores. Some potential items of interest include:\n\n\n\n\n\n\nItem name\nDescription\n\n\n\nST005Q01JA\nWhat is the  completed by your mother?\n\n\n\nST007Q01JA\nWhat is the  completed by your father?\n\n\n\nST256Q02JA\nIn your home: Classic literature (e.g. )\n\n\n\nST255Q01JA\nHow many books are there in your home?\n\n\nHOMEPOS\nFamily Wealth\n\n\nESCS\nIndex of economic, social and cultural status\n\n\nST254Q02JA\nHow many of the following [digital devices] are in your\n\n\n\n[home]: Desktop computers\n\n\n\n\n::: call-out warning\nDon’t forget to convert any non-numeric variables to numeric\n:::\n\n# Using ST255Q01JA  How many books are there in your home?\n# ST254Q02JA    How many in your home: Computers (desktop computer, portable laptop, or notebook)\nUSdata&lt;-PISA_2022%&gt;%\n  select(CNT, ESCS, HOMEPOS, PV1READ, ST255Q01JA, ST254Q02JA)%&gt;%\n  filter(CNT==\"United States\")\n# Making ST255Q01JA and ST012Q06NA numeric\nUSdata$ST255Q01JA&lt;-as.numeric(USdata$ST255Q01JA)\nUSdata$ST254Q02JA&lt;-as.numeric(USdata$ST254Q02JA)\n\n\nmodel&lt;-\"PV1READ ~ ESCS + HOMEPOS + ST255Q01JA+ ST254Q02JA\"\n\nfit&lt;-sem(model, data=USdata)\nsummary(fit)\n\nlavaan 0.6-19 ended normally after 1 iteration\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                         5\n\n                                                  Used       Total\n  Number of observations                          4163        4552\n\nModel Test User Model:\n                                                      \n  Test statistic                                 0.000\n  Degrees of freedom                                 0\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nRegressions:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  PV1READ ~                                           \n    ESCS             14.866    2.326    6.390    0.000\n    HOMEPOS          15.340    2.984    5.141    0.000\n    ST255Q01JA       21.151    1.413   14.965    0.000\n    ST254Q02JA      -20.733    2.150   -9.642    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .PV1READ        9987.581  218.913   45.623    0.000\n\nsemPaths(fit, whatLabels = \"Estimate\")\n\n\n\n\n\n\n\n\n\nThere are a number of variables in the PISA data set that could be used to model the home environment (e.g. Number of books in the home, number of computers, etc.). Using the home environment for UK students as a latent variable, create a model of the home environment.\n\n::: call-out warning\nDon’t forget to convert any non-numeric variables to numeric\n:::\n\n# Using ST251Q06JA  How many of these items are there at your [home]: Musical instruments (e.g. guitar, piano, [country-specific example])\n# and ST251Q07JA    How many of these items are there at your [home]: Works of art (e.g. paintings, sculptures, [country-specific example])\nUKdata&lt;-PISA_2022%&gt;%\n  select(CNT, ESCS, HOMEPOS, ST251Q06JA, ST251Q07JA)%&gt;%\n  filter(CNT==\"United Kingdom\")\n# Making variables numeric\nUKdata$ST251Q06JA&lt;-as.numeric(UKdata$ST251Q06JA)\nUKdata$ST251Q07JA&lt;-as.numeric(UKdata$ST251Q07JA)\nmodel&lt;-\"lv =~ ESCS + HOMEPOS + ST251Q06JA + ST251Q07JA \"\n\nfit&lt;-sem(model, data=UKdata)\nsummary(fit)\n\nlavaan 0.6-19 ended normally after 23 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                         8\n\n                                                  Used       Total\n  Number of observations                         10916       12972\n\nModel Test User Model:\n                                                      \n  Test statistic                                86.359\n  Degrees of freedom                                 2\n  P-value (Chi-square)                           0.000\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  lv =~                                               \n    ESCS              1.000                           \n    HOMEPOS           1.278    0.016   82.129    0.000\n    ST251Q06JA        0.930    0.016   58.374    0.000\n    ST251Q07JA        0.936    0.018   52.611    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .ESCS              0.312    0.006   51.116    0.000\n   .HOMEPOS           0.054    0.007    7.564    0.000\n   .ST251Q06JA        0.960    0.014   70.282    0.000\n   .ST251Q07JA        1.263    0.018   71.398    0.000\n    lv                0.474    0.011   44.235    0.000\n\nsemPaths(fit, whatLabels = \"Estimate\")\n\n\n\n\n\n\n\n\n\nYou believe that there are two latent variables underlying UK students’ performance in science - a science self-identity variable (related to the home environment, for example, gender, parents’ level of education) and a cognitive ability variable (indicated by performance in other subjects). Propose a model of science performance based on these two latent variables - linking each latent variable to multiple independent variables. Determine how much variance your model explains\n\n::: call-out warning\nDon’t forget to convert any non-numeric variables to numeric and consider scaling the test scores\n:::\n\n# Create a UK data frame with plausible values\nUKdata&lt;-PISA_2022%&gt;%\n  select(CNT, ESCS, HOMEPOS, ST005Q01JA, ST007Q01JA, PV1READ, PV1SCIE, \n         PV1MATH, ST004D01T)%&gt;%\n  filter(CNT==\"United Kingdom\")\n# Convert to numeric where not numeric\nUKdata$ST005Q01JA&lt;-as.numeric(UKdata$ST005Q01JA)\nUKdata$ST007Q01JA&lt;-as.numeric(UKdata$ST007Q01JA)\nUKdata$ST004D01T&lt;-as.numeric(UKdata$ST004D01T)\n\n# Scale the test scores\nUKdata$PV1READ&lt;-scale(UKdata$PV1READ)\nUKdata$PV1MATH&lt;-scale(UKdata$PV1MATH)\nUKdata$PV1SCIE&lt;-scale(UKdata$PV1SCIE)\n# Propose a model with two latent variables - one related to identity (lvi), the other ability (lva)\nmodel&lt;-\"lvi =~ ESCS + HOMEPOS + ST005Q01JA + ST007Q01JA + ST004D01T\n        lva =~ PV1MATH + PV1READ\n        PV1SCIE ~ lvi + lva\"\n# Fit the model\nfit&lt;-sem(model, data=UKdata)\nsummary(fit)\n\nlavaan 0.6-19 ended normally after 34 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        18\n\n                                                  Used       Total\n  Number of observations                          9683       12972\n\nModel Test User Model:\n                                                      \n  Test statistic                              1738.699\n  Degrees of freedom                                18\n  P-value (Chi-square)                           0.000\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  lvi =~                                              \n    ESCS              1.000                           \n    HOMEPOS           0.833    0.010   79.702    0.000\n    ST005Q01JA       -0.430    0.008  -51.306    0.000\n    ST007Q01JA       -0.437    0.009  -47.015    0.000\n    ST004D01T         0.001    0.006    0.175    0.861\n  lva =~                                              \n    PV1MATH           1.000                           \n [ reached getOption(\"max.print\") -- omitted 1 row ]\n\nRegressions:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  PV1SCIE ~                                           \n    lvi               0.004    0.007    0.518    0.605\n    lva               0.991    0.008  131.633    0.000\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  lvi ~~                                              \n    lva               0.312    0.009   33.677    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .ESCS              0.046    0.007    7.049    0.000\n   .HOMEPOS           0.327    0.007   49.672    0.000\n   .ST005Q01JA        0.366    0.005   67.130    0.000\n   .ST007Q01JA        0.470    0.007   67.762    0.000\n   .ST004D01T         0.250    0.004   69.581    0.000\n   .PV1MATH           0.122    0.004   30.788    0.000\n   .PV1READ           0.296    0.005   57.937    0.000\n   .PV1SCIE           0.157    0.004   37.728    0.000\n [ reached getOption(\"max.print\") -- omitted 2 rows ]\n\nsemPaths(fit, whatLabels = \"Estimate\")",
    "crumbs": [
      "Additional tests",
      "SEM"
    ]
  },
  {
    "objectID": "chapters/A4-Other_datasets.html",
    "href": "chapters/A4-Other_datasets.html",
    "title": "Other datasets",
    "section": "",
    "text": "There exist thousands of datasets that you can freely analyse. This section covers a few of the major ones for education, or that might fruitfully be combined with educational datasets such as PISA.",
    "crumbs": [
      "Appendicies",
      "Other datasets"
    ]
  },
  {
    "objectID": "chapters/A4-Other_datasets.html#global-gender-gap-index-gggi",
    "href": "chapters/A4-Other_datasets.html#global-gender-gap-index-gggi",
    "title": "Other datasets",
    "section": "\n2.1 Global Gender Gap Index (GGGI)",
    "text": "2.1 Global Gender Gap Index (GGGI)\nThe world economic forum produces the Global Gender Gap Index (GGGI), this index combines female and male outcomes on Economic participation and opportunity, educational attainment, health and survival, and political empowerment.\nReports for: 2022, 2021, 2020,2018,2017,2016, 2015\nIt has proven difficult to find the 2015 dataset used by Stoet & Geary, the 2013 dataset is here",
    "crumbs": [
      "Appendicies",
      "Other datasets"
    ]
  },
  {
    "objectID": "chapters/A4-Other_datasets.html#united-nations",
    "href": "chapters/A4-Other_datasets.html#united-nations",
    "title": "Other datasets",
    "section": "\n2.2 United Nations",
    "text": "2.2 United Nations\nThe UN reports on two gender specific indexes:\nGender Inequality Index (GII)\nThe Gender Inequality Index is a index incorporating data on reproductive health, empowerment and the labour market. Values range from 0 - full equality for men and women, to 0, full inequality.\nGender Development Index (GDI)\nThe Gender Development Index measures inequalities in human development, combining data on female and male life expectancy, years of schooling and earned income. Values of 1 indicate equality, with values of less than 1 showing males performing better, and values over 1 showing females doing better.\nDownloads for the GII and GDI are here",
    "crumbs": [
      "Appendicies",
      "Other datasets"
    ]
  },
  {
    "objectID": "chapters/A2-DfE_analysis.html",
    "href": "chapters/A2-DfE_analysis.html",
    "title": "DfE England",
    "section": "",
    "text": "There are four main data sources that you can use to gain information about education in England:",
    "crumbs": [
      "Appendicies",
      "DfE England"
    ]
  },
  {
    "objectID": "chapters/A2-DfE_analysis.html#school-funding",
    "href": "chapters/A2-DfE_analysis.html#school-funding",
    "title": "DfE England",
    "section": "\n2.1 School funding",
    "text": "2.1 School funding\nSchool funding information is available on the gov uk skillsfunding website. You can download year on year datasets here, with data going back to 2014/15",
    "crumbs": [
      "Appendicies",
      "DfE England"
    ]
  },
  {
    "objectID": "chapters/01-Intro_to_quant_methods.html",
    "href": "chapters/01-Intro_to_quant_methods.html",
    "title": "01 Introduction",
    "section": "",
    "text": "This session will introduce you to the assumptions that underpin quantitative research. We will consider the potential value of quantitative research, and consider the process of quantising latent variables. Latent variables are variables that can only be inferred indirectly from data. For example, consider intelligence - there is no way to measure intelligence directly, we have to base our assumptions of intelligence on performance on some tasks, such as those in intelligence tests. Many variables of interest to educational researchers are latent variables (consider, attitudes to subjects, academic achievement, interest, belonging etc.)\nIn this session we will consider the affordances and challenges of constructing quantitaitve variables in the context of educational research.",
    "crumbs": [
      "01 Introduction"
    ]
  },
  {
    "objectID": "chapters/01-Intro_to_quant_methods.html#activity-1-the-mismeasure-of-man",
    "href": "chapters/01-Intro_to_quant_methods.html#activity-1-the-mismeasure-of-man",
    "title": "01 Introduction",
    "section": "\n1.1 Activity 1: The mismeasure of man?",
    "text": "1.1 Activity 1: The mismeasure of man?\n\n“The Mismeasure of Man treats one particular form of quantified claim about the ranking of human groups: the argument that intelligence can be meaningfully abstracted as a single number capable of ranking all people on a linear scale of intrinsic and unalterable mental worth.\n… this limited subject embodies the deepest (and most common) philosophical error, with the most fundamental and far-ranging social impact, for the entire troubling subject of nature and nurture, or the genetic contribution to human social organization.” (Gould 1996, ii)\n\nDiscuss:\n\nTo what extent do the variables commonly studied in educational research (for example, intelligence, exam scores, attitudes etc.) validly represent some underlying latent variable?\nWhat advantages does quantification of such variables bring, and what issues does it raise?\nCan you think of an example in your own practice where a variable has been created that doesn’t fully reflect the latent concept? -What is the researcher’s role in making sure variables are validly represented?",
    "crumbs": [
      "01 Introduction"
    ]
  },
  {
    "objectID": "chapters/01-Intro_to_quant_methods.html#activity-2-an-example-of-quantification",
    "href": "chapters/01-Intro_to_quant_methods.html#activity-2-an-example-of-quantification",
    "title": "01 Introduction",
    "section": "\n1.2 Activity 2: An example of quantification",
    "text": "1.2 Activity 2: An example of quantification\nIn the seminar we will consider this paper:\nPasha-Zaidi, N., & Afari, E. (2016). Gender in STEM education: An exploratory study of student perceptions of math and science instructors in the United Arab Emirates. International Journal of Science and Mathematics Education, 14(7), 1215-1231.\nPasha-Zaidi and Afari (2016)\nReflect on\n\nWhat potential issues arise from the authors’ construction of quantitative variables of ‘teacher professionalism’ and ‘teacher warmth’?\nTo what extent does the authors’ survey validly probe the variables of ‘teacher professionalism’ and ‘teacher warmth’?\nWhat other critiques of the study can you propose?",
    "crumbs": [
      "01 Introduction"
    ]
  },
  {
    "objectID": "chapters/01-Intro_to_quant_methods.html#activity-3-a-false-dualism",
    "href": "chapters/01-Intro_to_quant_methods.html#activity-3-a-false-dualism",
    "title": "01 Introduction",
    "section": "\n1.3 Activity 3: A false dualism?",
    "text": "1.3 Activity 3: A false dualism?\n\n“‘Quantitative’ and ‘qualitative’ are frequently seen in opposition…. The contrast is drawn between the objective world (out there independently of our thinking about it) and the subjective worlds (in our heads, as it were, and individually constructed); between the public discourse and private meanings; between reality unconstructed by anyone and the ‘multiple realities’ constructed by each individual. The tendency to dichotomise in this way is understandable but misleading.” - (Pring 2000, 248)\n\nDiscussion Questions\n\nWhat are the differing assumptions of qualitative and quantitative educational research?\nAre the two ‘paradigms’ completely distinct? Is the distinction helpful?\nHow should a researcher choose what approach to use?",
    "crumbs": [
      "01 Introduction"
    ]
  },
  {
    "objectID": "chapters/01-Intro_to_quant_methods.html#task-4-another-critique-of-quantification",
    "href": "chapters/01-Intro_to_quant_methods.html#task-4-another-critique-of-quantification",
    "title": "01 Introduction",
    "section": "\n1.4 Task 4: Another critique of quantification",
    "text": "1.4 Task 4: Another critique of quantification\nThe second task considers this paper: Gibson and Dembo (1984)\nFor the purpose of discussion, teacher efficacy has been defined as “the extent to which the teacher believes he or she has the capacity to affect student performance” (Berman et al. 1977, 137)\nTool\n\n\n\n\n(Gibson and Dembo 1984, 573)\nFindings\n\n(Gibson and Dembo 1984, 577)\nTo discuss\n\nDoes teacher efficacy measure a discrete aspect of teachers’ beliefs? Does that matter?\nDoes the construct have validity? I.e., does the questionnaire measure what it claims to?\nWhat issues arises from quantifying teacher efficacy?\nWhat alternatives are there to quantitative measures of teacher efficacy? What are their advantages and limitations?",
    "crumbs": [
      "01 Introduction"
    ]
  },
  {
    "objectID": "chapters/12-value_of_quant.html",
    "href": "chapters/12-value_of_quant.html",
    "title": "12 The value of quantitative methods",
    "section": "",
    "text": "In this seminar we will reflect on advantages and disadvantages of using quantitative methods education research.",
    "crumbs": [
      "12 The value of quantitative methods"
    ]
  },
  {
    "objectID": "chapters/12-value_of_quant.html#task-1---the-education-endowment-fund",
    "href": "chapters/12-value_of_quant.html#task-1---the-education-endowment-fund",
    "title": "12 The value of quantitative methods",
    "section": "2.1 Task 1 - The Education Endowment Fund",
    "text": "2.1 Task 1 - The Education Endowment Fund\nBased on your reading of the summary of the EEF report, page 4: - To what extent is the EEF project useful research for teachers? - Should interventions that receive low ratings, for example the work experience programme of the form evaluated, be rejected? - Should all practices in schools undergo testing of this form? - Given the low effect size of many educational interventions are randomised control trials a helpful approach for providing policy recommendations?",
    "crumbs": [
      "12 The value of quantitative methods"
    ]
  },
  {
    "objectID": "chapters/12-value_of_quant.html#task-2---useful-quantification-visible-learning",
    "href": "chapters/12-value_of_quant.html#task-2---useful-quantification-visible-learning",
    "title": "12 The value of quantitative methods",
    "section": "2.2 Task 2 - Useful quantification? Visible Learning",
    "text": "2.2 Task 2 - Useful quantification? Visible Learning\nLook at the representations of effect sizes developed by Hattie:\n\n\n\nConsider this discussion of how Hattie developed these tables: Effect Size\nIs effect size a useful value for teachers to consider when deciding what approaches to adopt?\nAre meta-analyses of different classroom interventions practically useful? Can they guide practice in a meaningful manner? What questions might be asked about a meta-analysis before adopting its findings?\nWhat artefacts (findings that don’t reflect the underlying situation) might arise from meta-analyses that combine the results of different studies?\nCan interventions be ranked in a way that is meaningful for schools and teachers?",
    "crumbs": [
      "12 The value of quantitative methods"
    ]
  },
  {
    "objectID": "chapters/12-value_of_quant.html#task-3-the-value-of-quantitative-educational-research",
    "href": "chapters/12-value_of_quant.html#task-3-the-value-of-quantitative-educational-research",
    "title": "12 The value of quantitative methods",
    "section": "2.3 Task 3 The value of quantitative educational research",
    "text": "2.3 Task 3 The value of quantitative educational research\n\nFrom the analyses that we have carried out on the course, report any findings that you think are of value for teaching in your discipline\nWhat barriers currently exist to the development of quantitative research that is useful to STEM teachers?\nGiven the issues with EEF, what might policy makers do to support the meaningful development and use of quantitative education research?\nIs a dichotomy (e.g. a separation in the value and the researchers who conduct the work) between qualitative and quantitative work useful?",
    "crumbs": [
      "12 The value of quantitative methods"
    ]
  },
  {
    "objectID": "chapters/05-Presentations.html",
    "href": "chapters/05-Presentations.html",
    "title": "05 Presentations",
    "section": "",
    "text": "This task is worth 10% of total marks\nPrepare a 5-minute presentation: On a single slide, produce a graph of PISA data. Discuss assumptions in the variables, and how you prepared the data. Describe patterns you can see and link to the literature (you may add a second slide for linking to literature).",
    "crumbs": [
      "05 Presentations"
    ]
  },
  {
    "objectID": "chapters/05-Presentations.html#suggestions",
    "href": "chapters/05-Presentations.html#suggestions",
    "title": "05 Presentations",
    "section": "0.1 Suggestions",
    "text": "0.1 Suggestions\nThink of the variables in PISA (science, maths and reading achievement, gender, social class, wealth, food poverty, well being…) and then think of an interesting question:\nIs the correlation between maths score and wealth the same in the UK, the US and Germany? Does food poverty impact reading scores across the whole data set? How large are gender differences in reading score and do they vary across countries? Do mean reading and mean science score correlate?\nThen, using what you have learned so far about ggplot, produce one graph and discuss the patterns in it. Put the graph on a single PowerPoint slide and play with the options in ggplot to produce the best presented graph you can. Then compare the pattern in the literature to one or two papers. For example, if addressing the first question above, what has previous research said about the relationship between maths and wealth? Does your graph agree with or differ from the previous research.\nYou can find an example presentation on KEATs.",
    "crumbs": [
      "05 Presentations"
    ]
  },
  {
    "objectID": "chapters/05-Presentations.html#marking-points",
    "href": "chapters/05-Presentations.html#marking-points",
    "title": "05 Presentations",
    "section": "0.2 Marking points",
    "text": "0.2 Marking points\n\nWere assumptions in the variables discussed?\nWas data cleaning and preparation (and its implications) discussed?\nWas a well-presented graph produced?\nWere the patterns in the graph discussed?\nWere the data linked to the literature?\nGeneral comments on insight into issues and presentation\n\n\n\n\n\n\n\nTip\n\n\n\nMake sure you practice your presentation to fit into the time\n\n\n\n\n\n\n\n\nTip\n\n\n\nDon’t try to pack too much data into your graph. There is a skill to making a graph that tells a good story. You might find some of these pages provide useful gudiance:\n\nThe ‘From Data to Viz’ blog has a helpful flowchart for choosing an appropriate type of graph for different forms of data. The’Visual Vocabulary’ site, produced by the Financial times is an alternative option for selecting an appropriate chart.\nYou can find a gallery of around 400 types of visualisation you can produce in R at the R chart gallery.\nThe Royal Statistical Society has produced a guide to making visual representations, Best Practice for Data Representations, that shows you how to make readable, accessible data visualisations.",
    "crumbs": [
      "05 Presentations"
    ]
  },
  {
    "objectID": "chapters/08-Writing_report.html",
    "href": "chapters/08-Writing_report.html",
    "title": "08 Writing a quantitative report",
    "section": "",
    "text": "In the lecture you looked at Du and Wong (2019) as an example of a quantitative report. This session will help you structure your writing for your own quantitative report in assignment 3.",
    "crumbs": [
      "08 Writing a quantitative report"
    ]
  },
  {
    "objectID": "chapters/08-Writing_report.html#activity-1-proposing-a-question",
    "href": "chapters/08-Writing_report.html#activity-1-proposing-a-question",
    "title": "08 Writing a quantitative report",
    "section": "1.1 Activity 1: Proposing a question",
    "text": "1.1 Activity 1: Proposing a question\n\nSpend 10 minutes researching a problem (this can’t be extensive but find something that is flagged as requiring more research). Alternatively, you make already have a problem, in which case move onto the next step\nState a rough research problem:\ne.g., There is an imbalance in the number of students studying a-level biology (i.e., too few boys)\nTurn the problem into a question:\ne.g., What school features correlate with higher and lower level of male uptake of a-level biology?\nIncrease the specificity of the question:\ne.g., In DfE school census data for the period 2017-2022 what school variables (including number of biology teachers, uptake of GCSE triple science, % of FSM students etc.) correlate with higher and lower level of male uptake of a-level biology?",
    "crumbs": [
      "08 Writing a quantitative report"
    ]
  },
  {
    "objectID": "chapters/08-Writing_report.html#activity-2-find-a-data-set-and-check-its-applicability",
    "href": "chapters/08-Writing_report.html#activity-2-find-a-data-set-and-check-its-applicability",
    "title": "08 Writing a quantitative report",
    "section": "1.2 Activity 2: Find a data set and check its applicability",
    "text": "1.2 Activity 2: Find a data set and check its applicability\n\nUse the list of open data sets to choose an appropriate data set\nDoes it include all the data to answer your question? Which items will you use in your analysis? What form is the data you will use in?\nWhat form of cleaning will the data require?\nWill you need to draw on multiple data sets?",
    "crumbs": [
      "08 Writing a quantitative report"
    ]
  },
  {
    "objectID": "chapters/08-Writing_report.html#activity-3-decide-on-approaches-to-analysis",
    "href": "chapters/08-Writing_report.html#activity-3-decide-on-approaches-to-analysis",
    "title": "08 Writing a quantitative report",
    "section": "1.3 Activity 3: Decide on approaches to analysis",
    "text": "1.3 Activity 3: Decide on approaches to analysis\n\nWhat types of data are relevant to your questions (continuous, discontinuous?)\nWhat types of test will you need to run?\nWhat kind of descriptive statistics will be useful?",
    "crumbs": [
      "08 Writing a quantitative report"
    ]
  },
  {
    "objectID": "chapters/08-Writing_report.html#activity-4-sketch-a-research-plan",
    "href": "chapters/08-Writing_report.html#activity-4-sketch-a-research-plan",
    "title": "08 Writing a quantitative report",
    "section": "1.4 Activity 4: Sketch a research plan",
    "text": "1.4 Activity 4: Sketch a research plan\n\nWhen will you finalize your question?\nWhen will you carry out your data analysis?\nWhen will you write up?\nWhat help will you need?\nHow can you collaborate with peers?\nWhat R/SPSS/Excel skills do you need to acquire?",
    "crumbs": [
      "08 Writing a quantitative report"
    ]
  },
  {
    "objectID": "chapters/A3-TIMSS_analysis.html",
    "href": "chapters/A3-TIMSS_analysis.html",
    "title": "TIMSS, PIRLS and ICILS",
    "section": "",
    "text": "1 What is TIMSS?\nTrends in International Mathematics and Science Study (TIMSS) is a set of assessments comparing international achievement in mathematics and science. TIMSS is run by the International Association for the Evaluation of Educational Achievement (IEA) an international group of national research institutions and governments working to research and improve education. TIMSS launched in 2015\nThe study surveys both 9-10-year-old and 13-14-year-old students, across 64 countries (in 2019). Contextual data about schools, teachers and parents is collected in the survey. TIMSS advanced (running since 1995) collects data on students in their final year of secondary schooling.\nYou can read more about TIMSS, and download data sets, from the TIMSS website: TIMSS\n\n\n2 What is PIRLS?\nPIRLS (Progress in International Reading Literacy Study) is the IEA’S parallel study to TIMSS which focuses on international literacy. The study samples 9-10-year old students and has taken place every five years since 2001.\nYou can read more about PIRLS, and download data sets, from the PIRLS website: TIMSS\n\n\n3 International Computer and Information Literacy Study (ICILS)\nICILS is the IEA international comparative assessment of students’ computing and IT literacy. First conducted in 2013, the study assesses computer and information literacy (CIL) and computational thinking (CT) of 13-14-year-old students. The assessment takes place every 5 years.\nLearn more about ICILS, and download data sets, from the ICILS website: ICILS",
    "crumbs": [
      "Appendicies",
      "TIMSS, PIRLS and ICILS"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Quantitative methods in the context of education research",
    "section": "",
    "text": "This book has been written to accompany the MA STEM quantitative methods course at King’s College London. It will take the reader through the process of learning the R statistical programming language through the analysis of the 2022 PISA survey data. The book does not assume any prior knowledge and should suit the needs of those looking to learn R, learn statistics, learn how to analyse PISA data, or any combination of these.\n\n1 Copyright and usage\nThis book is free to use under a CC BY-NC-ND 4.0 license.\nAll PISA products are published under the Creative Commons Attribution-NonCommercial-ShareAlike 3.0 IGO (CC BY-NC-SA 3.0 IGO) license. This includes the .feather and .parquet formatted datasets linked throughout the text. The PISA 2022 dataset is also available from the OECD website.\nWe have tested the software and datasets used in the making of this book, but cannot guarantee that they are free from errors. If you find any errors or have any questions, please contact peter.kemp@kcl.ac.uk and/or richard.brock@kcl.ac.uk. You are using this book at your own risk and we cannot be held responsible for any loss or damage arising from the use of this book (please don’t overwrite your hard disks!).\nTo reference this book, please use:\n\nKemp, Peter EJ, Richard Brock, Amy O’Brien, Carla Finesilver, Lulu Healy, and David Pepper. 2023. Quantitative Methods in the Context of Education Research: The PISA 2022 data set. London, United Kingdom: King’s College London. https://peterejkemp.github.io/v3/.\n\nAnd to reference the PISA 2022 dataset, please use:\n\nOECD. 2022. PISA 2022 Results (Volume i). OECD. https://www.oecd-ilibrary.org/docserver/53f23881-en.pdf.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "chapters/11-selecting_statistical_tools.html",
    "href": "chapters/11-selecting_statistical_tools.html",
    "title": "11 Selecting statistical tools",
    "section": "",
    "text": "Look over the test selection flow chart:\n\n\nShow the code\nlibrary(DiagrammeR)\ngrViz(\"\n      digraph Random{\n      graph [layout = dot,\n      overlap =T,\n      bgcolor='white',\n      splines=line]#controls l type setup\n      node [shape = box,style='filled',\n      fillcolor='skyblue',\n      fontSize=30,fontcolor='darkgrey',\n      fontname= 'Arial']\n     a [label = 'What do you want to do?']\n     b [label = 'Test a hypothesis - on what kind of data?']\n     c [label = 'Examine a relationship']\n     d [label = 'Continuous'];\n     e [label = 'Normally Distribured/Parametric'];\n     f [label = '1 Group'];\n     g [label = 'One sample t-test', fillcolor='lightyellow'];\n     h [label = 'Do a test of normality'];\n     i [label = 'qqplot', fillcolor='lightyellow'];\n     j [label = 'Tests on skewed distributions', fillcolor='lightyellow'];\n     k [label = 'Discrete / Categorical'];\n     l [label = '2 Groups'];\n     m [label = 'Unpaired groups'];\n     n [label = 'Expected counts more than 5\\nin more than 75 per cent of cells'];\n     o [label = 'Chi-squared', fillcolor='lightyellow'];\n     p [label = 'Expected counts more than 5\\n in less than 75 per cent of cells'];\n     q [label = 'Fisher exact test', fillcolor='lightyellow'];\n     r [label = 'Continuous variables'];\n     s [label = 'Linear Regression', fillcolor='lightyellow'];\n     t [label = '2 groups']\n     u [label = 'Paired groups']\n     v [label = 'Unpaired groups']\n     w [label = 'Paired t-test', fillcolor='lightyellow']\n     x [label = 'Unpaired t-test', fillcolor='lightyellow']\n     y [label = '3 groups or more']\n     z [label = 'anova', fillcolor='lightyellow']\n     aa [label = 'Not normally distributed'] \n     a -&gt; b\n     a -&gt; c\n     b -&gt; d\n     d -&gt; h\n     h -&gt; i\n     i -&gt; aa\n     aa -&gt; j\n     i -&gt; e\n     e -&gt; f\n     f -&gt; g\n     b -&gt; k\n     k -&gt; l\n     l -&gt; m\n     m -&gt; n\n     n -&gt; o\n     m -&gt; p\n     p -&gt; q\n     c -&gt; r\n     r -&gt; s\n     e -&gt; t\n     t -&gt; u\n     t -&gt; v\n     u -&gt; w\n     v -&gt; x\n     e -&gt; y\n     y -&gt; z\n      }\")\n\n\n\n\n\n\n\n\n\nWe will continue to use the PISA_2022 dataset, make sure it is loaded.\n\n# Load PISA data\n\nlibrary(arrow)\nlibrary(tidyverse)\n\nPISA_2022 &lt;- read_parquet(r\"[&lt;folder&gt;PISA_2022_student.parquet]\")",
    "crumbs": [
      "11 Selecting statistical tools"
    ]
  },
  {
    "objectID": "chapters/11-selecting_statistical_tools.html#pre-session-reading",
    "href": "chapters/11-selecting_statistical_tools.html#pre-session-reading",
    "title": "11 Selecting statistical tools",
    "section": "",
    "text": "Look over the test selection flow chart:\n\n\nShow the code\nlibrary(DiagrammeR)\ngrViz(\"\n      digraph Random{\n      graph [layout = dot,\n      overlap =T,\n      bgcolor='white',\n      splines=line]#controls l type setup\n      node [shape = box,style='filled',\n      fillcolor='skyblue',\n      fontSize=30,fontcolor='darkgrey',\n      fontname= 'Arial']\n     a [label = 'What do you want to do?']\n     b [label = 'Test a hypothesis - on what kind of data?']\n     c [label = 'Examine a relationship']\n     d [label = 'Continuous'];\n     e [label = 'Normally Distribured/Parametric'];\n     f [label = '1 Group'];\n     g [label = 'One sample t-test', fillcolor='lightyellow'];\n     h [label = 'Do a test of normality'];\n     i [label = 'qqplot', fillcolor='lightyellow'];\n     j [label = 'Tests on skewed distributions', fillcolor='lightyellow'];\n     k [label = 'Discrete / Categorical'];\n     l [label = '2 Groups'];\n     m [label = 'Unpaired groups'];\n     n [label = 'Expected counts more than 5\\nin more than 75 per cent of cells'];\n     o [label = 'Chi-squared', fillcolor='lightyellow'];\n     p [label = 'Expected counts more than 5\\n in less than 75 per cent of cells'];\n     q [label = 'Fisher exact test', fillcolor='lightyellow'];\n     r [label = 'Continuous variables'];\n     s [label = 'Linear Regression', fillcolor='lightyellow'];\n     t [label = '2 groups']\n     u [label = 'Paired groups']\n     v [label = 'Unpaired groups']\n     w [label = 'Paired t-test', fillcolor='lightyellow']\n     x [label = 'Unpaired t-test', fillcolor='lightyellow']\n     y [label = '3 groups or more']\n     z [label = 'anova', fillcolor='lightyellow']\n     aa [label = 'Not normally distributed'] \n     a -&gt; b\n     a -&gt; c\n     b -&gt; d\n     d -&gt; h\n     h -&gt; i\n     i -&gt; aa\n     aa -&gt; j\n     i -&gt; e\n     e -&gt; f\n     f -&gt; g\n     b -&gt; k\n     k -&gt; l\n     l -&gt; m\n     m -&gt; n\n     n -&gt; o\n     m -&gt; p\n     p -&gt; q\n     c -&gt; r\n     r -&gt; s\n     e -&gt; t\n     t -&gt; u\n     t -&gt; v\n     u -&gt; w\n     v -&gt; x\n     e -&gt; y\n     y -&gt; z\n      }\")",
    "crumbs": [
      "11 Selecting statistical tools"
    ]
  },
  {
    "objectID": "chapters/11-selecting_statistical_tools.html#pre-session-task---loading-the-data",
    "href": "chapters/11-selecting_statistical_tools.html#pre-session-task---loading-the-data",
    "title": "11 Selecting statistical tools",
    "section": "",
    "text": "We will continue to use the PISA_2022 dataset, make sure it is loaded.\n\n# Load PISA data\n\nlibrary(arrow)\nlibrary(tidyverse)\n\nPISA_2022 &lt;- read_parquet(r\"[&lt;folder&gt;PISA_2022_student.parquet]\")",
    "crumbs": [
      "11 Selecting statistical tools"
    ]
  },
  {
    "objectID": "chapters/11-selecting_statistical_tools.html#task-1-plot-a-graph-of-mean-science-scores-by-country",
    "href": "chapters/11-selecting_statistical_tools.html#task-1-plot-a-graph-of-mean-science-scores-by-country",
    "title": "11 Selecting statistical tools",
    "section": "2.1 Task 1 Plot a graph of mean science scores by country",
    "text": "2.1 Task 1 Plot a graph of mean science scores by country\nImagine we wish to compare the mean scores of students on the science element of PISA by plotting a bar graph. First you need to use the sumarise function to calculate means by countries. Then use ggplot with geom_col to create the graph. Extension task: add error bars for the standard deviations of science scores.\n\n\nShow the code\n# Task 1: Plot a graph of mean science scores by country\n# Create a variable avgscience - for every country (Group_by(CNT)) calculate the mean\n# science score (PV1SCIE) and ignore NA (na.rm=TRUE)\n\navgscience &lt;- PISA_2022 %&gt;%\n  group_by(CNT) %&gt;%\n  summarise(mean_sci = mean(PV1SCIE, na.rm = TRUE)) %&gt;%\n  arrange(desc(mean_sci))\n\n\n# Plot the data  x=CNT (reorder to ascending order), mean science score on the y\n# Change the fill colour to red, rotate the text, locate the text and reduce the font size\nggplot(data = avgscience,\n       aes(x = reorder(CNT, - mean_sci), y = mean_sci)) +\ngeom_col(fill = \"red\") +\ntheme(axis.text.x = element_text(angle = 90, hjust = 0.95,\n                                 vjust = 0.2, \n                                 size = 5))+\n  labs(x = \"Country\", y = \"Mean Science Score\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n# Extension version: added summarise to find standard deviation \n\navgscience &lt;- PISA_2022 %&gt;% \n  group_by(CNT) %&gt;%\n  summarise(mean_sci = mean(PV1SCIE, na.rm = TRUE),\n            sd_sci = sd(PV1SCIE, na.rm = TRUE)) %&gt;%\n  arrange(desc(mean_sci))\n\n# Extension version: geom_errorbar added with aes y=mean_sci (the centre of the bar) and then the maximum and minimum set to the mean plus or minus the standard deviation (ymin=mean_sci-sd_sci, ymax=mean_sci+sd_sci) \n\nggplot(data = avgscience, \n       aes(x = reorder(CNT, -mean_sci), y = mean_sci)) +\ngeom_col(fill = \"red\") +\ntheme(axis.text.x = element_text(angle = 90, hjust = 0.95, vjust = 0.2, \n                                 size = 5))+\n  labs(x=\"Country\", y = \"Mean Science Score\")+\n  geom_errorbar(aes(y = mean_sci, ymin = mean_sci - sd_sci,\n                    ymax = mean_sci + sd_sci),\n                width = 0.5, colour='black', size = 0.5)",
    "crumbs": [
      "11 Selecting statistical tools"
    ]
  },
  {
    "objectID": "chapters/11-selecting_statistical_tools.html#task-2-are-there-differences-in-science-scores-by-gender-for-the-total-data-set",
    "href": "chapters/11-selecting_statistical_tools.html#task-2-are-there-differences-in-science-scores-by-gender-for-the-total-data-set",
    "title": "11 Selecting statistical tools",
    "section": "2.2 Task 2 Are there differences in science scores by gender for the total data set?",
    "text": "2.2 Task 2 Are there differences in science scores by gender for the total data set?\nConsider the kinds of variables that represent the science score. What is an appropriate test to determine differences in the means between the two groups? Create two vectors, for boys and girls, that you can feed into the t.test function.\n\n\nShow the code\n# Task 2: Are there differences in Science scores by gender for the total data set? (Yes)\n# A comparison of means of two continuous variables, use a t-test.\n\n1MaleSci &lt;- PISA_2022 %&gt;%\n2  select(ST004D01T, PV1SCIE) %&gt;%\n3  filter(ST004D01T == \"Male\")\n\n# Choose the  gender (ST004D01T) and science score columns (PV1SCIE) from  2022 data, filter for females \n# Put that data into FemaleSci\n\n4FemaleSci &lt;- PISA_2022 %&gt;%\n  select(CNT, ST004D01T, PV1SCIE) %&gt;% \n  filter(ST004D01T == \"Female\")\n\n#Do a t-test comparing MaleSci and FemaleSci\nt.test(MaleSci$PV1SCIE, FemaleSci$PV1SCIE)\n# p-value is &lt; 2.2e-16 which is less than 0.05 so statistically significant differences exist\n\n\n\n1\n\nline 1 - Pipe the data into a new data frame MaleSci\n\n2\n\nline 2 - Choose the gender (ST004D01T) and science score columns (PV1SCIE) from 2022 data\n\n3\n\nline 3 - filter for males\n\n4\n\nline 4 - repeat for females, creating a data frame FemaleSci\n\n\n\n\n\n    Welch Two Sample t-test\n\ndata:  MaleSci$PV1SCIE and FemaleSci$PV1SCIE\nt = -9.3337, df = 610738, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -3.033446 -1.980566\nsample estimates:\nmean of x mean of y \n 449.2026  451.7096",
    "crumbs": [
      "11 Selecting statistical tools"
    ]
  },
  {
    "objectID": "chapters/11-selecting_statistical_tools.html#task-3-are-there-differences-in-science-scores-by-gender-for-uk-students",
    "href": "chapters/11-selecting_statistical_tools.html#task-3-are-there-differences-in-science-scores-by-gender-for-uk-students",
    "title": "11 Selecting statistical tools",
    "section": "2.3 Task 3 Are there differences in science scores by gender for UK students?",
    "text": "2.3 Task 3 Are there differences in science scores by gender for UK students?\nAs above, but include a filter by country.\n\n\nShow the code\n# Task 3: Are there differences in Science scores by gender for UK students? (No)\n# A comparison of means of two continuous variables, use a t-test.\n# Choose the country (CNT), gender (ST004D01T) and science score columns (PV1SCIE) from  2022 data, filter for males and the UK\n# Put that data into UKMaleSci\n\nUKMaleSci &lt;- PISA_2022 %&gt;% \n  select(CNT, ST004D01T, PV1SCIE) %&gt;% \n  filter(ST004D01T == \"Male\")  %&gt;% \n  filter(CNT == \"United Kingdom\")\n\n# Choose the country (CNT), gender (ST004D01T) and science score columns (PV1SCIE) from  data, filter for females and the UK\n# Put that data into UKFemaleSci\nUKFemaleSci &lt;- PISA_2022 %&gt;% \n  select(CNT, ST004D01T, PV1SCIE) %&gt;% \n  filter(ST004D01T == \"Female\") %&gt;% \n  filter(CNT == \"United Kingdom\")\n\n# Do a t-test comparing UKMaleSci and UKFemaleSci\nt.test(UKMaleSci$PV1SCIE, UKFemaleSci$PV1SCIE)\n\n\n\n    Welch Two Sample t-test\n\ndata:  UKMaleSci$PV1SCIE and UKFemaleSci$PV1SCIE\nt = 3.9298, df = 12964, p-value = 8.547e-05\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n  3.529142 10.553500\nsample estimates:\nmean of x mean of y \n 495.7375  488.6962 \n\n\nShow the code\n# the p-value is 0.1267 over, 0.05, so statistically significant differences between males and females",
    "crumbs": [
      "11 Selecting statistical tools"
    ]
  },
  {
    "objectID": "chapters/11-selecting_statistical_tools.html#task-4-for-the-whole-data-set-is-there-a-correlation-between-students-science-score-and-reading-scores",
    "href": "chapters/11-selecting_statistical_tools.html#task-4-for-the-whole-data-set-is-there-a-correlation-between-students-science-score-and-reading-scores",
    "title": "11 Selecting statistical tools",
    "section": "2.4 Task 4 For the whole data set, is there a correlation between students’ science score and reading scores?",
    "text": "2.4 Task 4 For the whole data set, is there a correlation between students’ science score and reading scores?\nReflect on the appropriate test to show correlation between two scores. This test can be carried out quite simply using a couple of lines of code. Extensions: a) perform the same analysis, but consider the impact of gender; b) Find the correlations between reading and science core by country, and rank from most highly correlated to least.\n\n\nShow the code\n# Task 4: For the whole data set, is there a correlation between students’ science score reading score? (Yes, significant 0.77)\n\n# Do the regression test between science score (PV1SCIE) and reading score (PV1READ) on the PISA_2022 data\n1lmSciRead &lt;- lm(PV1SCIE ~ PV1READ, data = PISA_2022)\nsummary(lmSciRead)\n\n# Extension 1: Add Gender:\n3lmSciRead &lt;- lm(PV1SCIE ~ PV1READ + ST004D01T, data = PISA_2022)\nsummary(lmSciRead)\n\n# Extension 2: Rank by correlation\nCNTPISA &lt;- PISA_2022 %&gt;%\n5  select(CNT, PV1SCIE, PV1READ) %&gt;%\n6  group_by(CNT)%&gt;%\n7  summarise(MeanSci = mean(PV1SCIE),\n            MeanRead = mean(PV1READ),\n            Cor=cor(PV1SCIE, PV1READ)) %&gt;%\n  arrange(desc(Cor))\n\n\n\n1\n\nline 1 - Run a linear model, predicting PV1SCIE with PV1READ, based on PISA_2022 data, then summarise\n\n3\n\nline 5 - create a new data frame CNTPISA, and PISA_2022 into it selecting country, science and reading score\n\n5\n\nline 7 - summarise to find mean science scores, in the column MeanSci, and mean reading scores in MeanRead\n\n6\n\nline 9 - For each country, find the correlation between science and reading scores, put in the column Cor\n\n7\n\nline 10 - sort the data frame in descending order of the column Cor the correlation scores\n\n\n\n\n\nCall:\nlm(formula = PV1SCIE ~ PV1READ, data = PISA_2022)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-348.75  -38.22   -1.08   37.50  384.95 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 97.890279   0.303098     323   &lt;2e-16 ***\nPV1READ      0.804547   0.000671    1199   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 57.57 on 613742 degrees of freedom\nMultiple R-squared:  0.7008,    Adjusted R-squared:  0.7008 \nF-statistic: 1.438e+06 on 1 and 613742 DF,  p-value: &lt; 2.2e-16\n\n\nCall:\nlm(formula = PV1SCIE ~ PV1READ + ST004D01T, data = PISA_2022)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-358.01  -37.74   -0.83   37.13  376.71 \n\nCoefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   8.486e+01  3.180e-01   266.9   &lt;2e-16 ***\nPV1READ       8.139e-01  6.674e-04  1219.4   &lt;2e-16 ***\nST004D01TMale 1.785e+01  1.462e-01   122.1   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 56.88 on 613662 degrees of freedom\n  (79 observations deleted due to missingness)\nMultiple R-squared:  0.7079,    Adjusted R-squared:  0.7079 \nF-statistic: 7.436e+05 on 2 and 613662 DF,  p-value: &lt; 2.2e-16",
    "crumbs": [
      "11 Selecting statistical tools"
    ]
  },
  {
    "objectID": "chapters/11-selecting_statistical_tools.html#task-5-plot-a-representation-of-uk-students-science-score-against-reading-score-with-a-linear-best-fit-line.",
    "href": "chapters/11-selecting_statistical_tools.html#task-5-plot-a-representation-of-uk-students-science-score-against-reading-score-with-a-linear-best-fit-line.",
    "title": "11 Selecting statistical tools",
    "section": "2.5 Task 5 Plot a representation of UK students’ science score against reading score, with a linear best fit line.",
    "text": "2.5 Task 5 Plot a representation of UK students’ science score against reading score, with a linear best fit line.\nIt will help here to create a data.frame that contains a filtered version of the whole dataset you can pass to ggplot.\n\n\nShow the code\n# Task 5: Plot a representation of UK students’ science score against reading score.\n \n# Choose the three variables of interest, science score (PV1SCIE), reading score (PV1READ) and country (CNT)\n# and filter for the UK. Put the values into regplotdata\n1regplotdata &lt;- PISA_2022 %&gt;%\n2  select(PV1SCIE, PV1READ, CNT) %&gt;%\n3  filter(CNT == \"United Kingdom\")\n\n# Plot the data in regplotdata, set the science score on the x-xis and reading on y-axis, set the size, colour and alpha (transparency)\n# of points and add a linear ('lm') black line\n\nggplot(data = regplotdata, \n5       aes(x = PV1SCIE, y = PV1READ)) +\n6    geom_point(size = 0.5, colour = \"red\", alpha = 0.3) +\n7    geom_smooth(method = \"lm\", colour=\"black\")+\n    labs(x = \"Science Score\", y = \"Reading score\")\n\n\n\n1\n\nline 1 - Create a new data frame for plotting regplotdata\n\n2\n\nline 2 - Select the variables we need: PV1SCIE, PV1READ and CNT.\n\n3\n\nline 3 - filter for UK results\n\n5\n\nline 6 - set the x-axis as science scores, and y axis as reading scores\n\n6\n\nline 7 - use geom_point to plot a scatter graph, set the point colour to red, and transparency (alpha) to 0.3\n\n7\n\nline 8 - add labels",
    "crumbs": [
      "11 Selecting statistical tools"
    ]
  },
  {
    "objectID": "chapters/11-selecting_statistical_tools.html#task-6-do-girls-and-boys-in-the-uk-have-different-preferences-for-maths",
    "href": "chapters/11-selecting_statistical_tools.html#task-6-do-girls-and-boys-in-the-uk-have-different-preferences-for-maths",
    "title": "11 Selecting statistical tools",
    "section": "2.6 Task 6 Do girls and boys in the UK have different preferences for maths?",
    "text": "2.6 Task 6 Do girls and boys in the UK have different preferences for maths?\nThe PISA 2022 data set includes the variable MATHPREF (Preference of Math over other core subjects). Determine if the data for girls and boys are homogenous (i.e. if the null hypothesis that girls and boys have similar preferences for maths). Note the possible responses are: 0 No preference for mathematics over other subjects and 1 Preference for mathematics over other subjects\n\n\nShow the code\n# Task 6: Is there a relationship between UK boys' and girls' mathematics preferences\n  \n1chi_data &lt;- PISA_2022 %&gt;%\n2  select(CNT, ST004D01T, MATHPREF) %&gt;%\n3  filter(CNT == \"United Kingdom\")  %&gt;%\n4  droplevels() %&gt;%\n5  na.omit()\n\n# We wish to compare two categorical variables, gender (Male/Female) and preference for maths (0 = No Preference for maths/ 1= Preference for maths)\n# Create a frequency table\n\n6Mathpreftable &lt;- xtabs(data = chi_data, ~ ST004D01T + MATHPREF)\n\n# Perform the chisq.test on the data\n\n7chisq.test(Mathpreftable)\n\n# p-value= 4.554e-08 - reject the null hypothesis - boys and girls have different preferences for mathematics\n\n\n\n1\n\nline 1 - Pipe PISA_2022 to a new data frame to test: chi_data\n\n2\n\nline 2 - Select the variables we need: gender (ST004D01T), country (CNT), and math preference (MATHPEF).\n\n3\n\nline 3 - filter for UK results\n\n4\n\nline 4 - drop unneeded levels for other countries\n\n5\n\nline 5 - drop NAs\n\n6\n\nline 6 - create a contingency table of gender (ST004D01T) by maths preference (MATHPREF)\n\n7\n\nline 7 - perform the chi-square test\n\n\n\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  Mathpreftable\nX-squared = 29.898, df = 1, p-value = 4.554e-08",
    "crumbs": [
      "11 Selecting statistical tools"
    ]
  },
  {
    "objectID": "chapters/11-selecting_statistical_tools.html#task-7-does-mathematics-preferences-explain-variation-in-mathematics-score-for-uk-students",
    "href": "chapters/11-selecting_statistical_tools.html#task-7-does-mathematics-preferences-explain-variation-in-mathematics-score-for-uk-students",
    "title": "11 Selecting statistical tools",
    "section": "2.7 Task 7 Does mathematics preferences explain variation in mathematics score for UK students?",
    "text": "2.7 Task 7 Does mathematics preferences explain variation in mathematics score for UK students?\nArguments have been made the students who know more science, might engage in more environmental activism. Determine what percentage of variation in UK mathematics scores is explained by a) the variable MATHPREF (Preference of Math over other core subjectsn); b) MATHEASE (Perception of Mathematics as easier than other subjects); and c) MATHMOT (Motivation to do well in mathematics ).\n\n\nShow the code\n# Task 7: How much variability in mathematics score is explained by attitude to maths variables for UK respondents\n\nUK_data &lt;- PISA_2022 %&gt;%\n1  select(CNT, PV1MATH, MATHPREF, MATHMOT, MATHEASE) %&gt;%\n2  filter(CNT == \"United Kingdom\")  %&gt;%\n3  na.omit()\n\n# Perform the anova test\n4resaov &lt;- aov(data = UK_data,\n5              PV1MATH ~ MATHPREF + MATHMOT + MATHEASE)\n6summary(resaov)\n#&gt; Significant differences exist for MATHPREF and MATHEASE, but not for MATHMOT (Motivation to do well in mathematics)\n\n# Determine the % of variation explained\n7library(lsr)\n8eta &lt;- etaSquared(resaov)\n9eta &lt;- 100*eta\n10eta\n# MATHPREF explains only 0.54% of the variance, and MATHEASE, 0.26% (MATHMOT is not significant)\n\n\n\n1\n\nline 1 - select the variables of interest, country, maths scores, maths prefernce, maths motivation, and perception of easiness of maths\n\n2\n\nline 2 - filter for country of interest - i.e. the UK\n\n3\n\nline 3 - drop any NAs in the data\n\n4\n\nline 4 - use aov to perform the anova calculation. We set the data we are passing (data = UK_data) - we put the output into a new variable resaov\n\n5\n\nline 5 -and set that we want to determine the variance in maths scores by math preference, motivation and ease (PV1MATH ~ MATHPREF + MATHMOT + MATHEASE)\n\n6\n\nline 6 - produce a summary of resaov\n\n7\n\nline 7 - load the lsr library for the etaSquared function\n\n8\n\nline 8 - use etaSquared(resaov) to find the eta squared value. We convert this to a data frame so we can perform the next steps\n\n9\n\nline 9 - to convert the eta squared value into a percentage of variance explained, we multiply by 100\n\n\n10\n\nline 10 - print the result\n\n\n\n\n               Df   Sum Sq Mean Sq F value   Pr(&gt;F)    \nMATHPREF        1   981096  981096 108.868  &lt; 2e-16 ***\nMATHMOT         1    39980   39980   4.436   0.0352 *  \nMATHEASE        1   247557  247557  27.470 1.63e-07 ***\nResiduals   10579 95335543    9012                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n             eta.sq eta.sq.part\nMATHPREF 0.53998100  0.54418893\nMATHMOT  0.06829671  0.06915768\nMATHEASE 0.25625926  0.25899678",
    "crumbs": [
      "11 Selecting statistical tools"
    ]
  },
  {
    "objectID": "chapters/A5-Self_Study_Tasks.html",
    "href": "chapters/A5-Self_Study_Tasks.html",
    "title": "Self Study Tasks",
    "section": "",
    "text": "The pages below set out a series of graded challenges that you can use to test your R and statistical skills. Sample code that solves each problem is included so you can compare your solution with ours. Don’t worry if you solve something in a different way, there will be multiple solutions to the same task. The tasks are all set on the PISA_2022 data set: PISA_2022\nTo load the data, use the code below:",
    "crumbs": [
      "Appendicies",
      "Self Study Tasks"
    ]
  },
  {
    "objectID": "chapters/A5-Self_Study_Tasks.html#task-1-practice-creating-a-summary-table-1",
    "href": "chapters/A5-Self_Study_Tasks.html#task-1-practice-creating-a-summary-table-1",
    "title": "Self Study Tasks",
    "section": "\n0.1 Task 1 Practice creating a summary table #1",
    "text": "0.1 Task 1 Practice creating a summary table #1\n\nCreate a table that summarises the mean PISA science scores by country. You will need to use the group_by, summarise and mean functions.\n\nShow the codePISAsummary&lt;-PISA_2022%&gt;%  # Pipe the overall frame to a summary data.frame\n  select(CNT, PV1SCIE)%&gt;%  # Select the two required columns\n  group_by(CNT) %&gt;%        # Group the entries by country\n  summarise(meansci = mean(PV1SCIE)) # calculate means for each country\n\nprint(PISAsummary)\n\n# A tibble: 80 × 2\n   CNT                  meansci\n   &lt;fct&gt;                  &lt;dbl&gt;\n 1 Albania                 376.\n 2 United Arab Emirates    436.\n 3 Argentina               415.\n 4 Australia               508.\n 5 Austria                 494.\n 6 Belgium                 495.\n 7 Bulgaria                422.\n 8 Brazil                  406.\n 9 Brunei Darussalam       445.\n10 Canada                  499.\n# ℹ 70 more rows\n\n\nExtension: use the signif function to give the responses to three significant figures",
    "crumbs": [
      "Appendicies",
      "Self Study Tasks"
    ]
  },
  {
    "objectID": "chapters/A5-Self_Study_Tasks.html#task-2-practice-creating-a-summary-table-including-percentages-2",
    "href": "chapters/A5-Self_Study_Tasks.html#task-2-practice-creating-a-summary-table-including-percentages-2",
    "title": "Self Study Tasks",
    "section": "\n0.2 Task 2 Practice creating a summary table (including percentages) #2",
    "text": "0.2 Task 2 Practice creating a summary table (including percentages) #2\n\nUse the table function to create a summary of numbers of speakers of different languages (LANGN) recorded in the data frame for the UK. Use the mutate function to turn these into percentages (you will need to calculate a total)\n\nShow the codeUKPISA&lt;-PISA_2022%&gt;%\n  select(CNT,LANGN)%&gt;%               # Select the country school type \n  filter(CNT == \"United Kingdom\")%&gt;%  # filter for the UK\n  select(LANGN) %&gt;%                  # Just select the language (removing country)\n  droplevels()                                   \n\nUKPISA&lt;-xtabs(data=UKPISA, ~ LANGN)  # Create a summary of counts\n                                    # To manipulate the table it is\nUKPISA&lt;-as.data.frame(UKPISA)       # easier to convert it to a \n                                    # a data.frame\n\nUKPISA&lt;-mutate(UKPISA, per = Freq / sum(Freq)*100)\nUKPISA  \n\n                            LANGN Freq         per\n1                           Scots  387  2.98334875\n2                         English 9710 74.85353068\n3                           Welsh  137  1.05612088\n4                 Scottish Gaelic    7  0.05396238\n5                           Irish   28  0.21584952\n6  Other European languages (QSC)  154  1.18717237\n7                    Ulster Scots   41  0.31606537\n8   A non-European Union language  128  0.98674067\n9          Another language (QUK)  809  6.23650940\n10                        Missing 1571 12.11069997\n\nShow the code# If you want to sort the data (arrange descending by the percentage vector)\nUKPISA&lt;-UKPISA%&gt;%\n  arrange(desc(per))\nUKPISA\n\n                            LANGN Freq         per\n1                         English 9710 74.85353068\n2                         Missing 1571 12.11069997\n3          Another language (QUK)  809  6.23650940\n4                           Scots  387  2.98334875\n5  Other European languages (QSC)  154  1.18717237\n6                           Welsh  137  1.05612088\n7   A non-European Union language  128  0.98674067\n8                    Ulster Scots   41  0.31606537\n9                           Irish   28  0.21584952\n10                Scottish Gaelic    7  0.05396238",
    "crumbs": [
      "Appendicies",
      "Self Study Tasks"
    ]
  },
  {
    "objectID": "chapters/A5-Self_Study_Tasks.html#task-3-practice-pivoting-a-table",
    "href": "chapters/A5-Self_Study_Tasks.html#task-3-practice-pivoting-a-table",
    "title": "Self Study Tasks",
    "section": "\n0.3 Task 3 Practice pivoting a table",
    "text": "0.3 Task 3 Practice pivoting a table\n\nConvert a table of UK Science, Maths and Reading scores, extracted from the main data set, into the long format R prefers. In the long format, each score becomes a single so each student will have three entries.\n\nShow the code# Create a data frame in wide format, with three columns for each student's scores (math, reading and science)\nUKScores&lt;-PISA_2022%&gt;%\n  select(CNT,PV1MATH, PV1READ, PV1SCIE)%&gt;%\n  filter(CNT == \"United Kingdom\")%&gt;%\n  select(PV1MATH, PV1READ, PV1SCIE)\n# Use pivot longer to turn the three columns into one. First, pass pivotlonger the dataframe to be converted, then the three columns\n# to convert into one, the name of the new longer column and the\n# name of the new scores column\n\nUKScores&lt;-pivot_longer(UKScores, cols = c('PV1MATH', 'PV1READ', 'PV1SCIE'),\n                       names_to = 'Subject', values_to = 'Score' )",
    "crumbs": [
      "Appendicies",
      "Self Study Tasks"
    ]
  },
  {
    "objectID": "chapters/A5-Self_Study_Tasks.html#task-4-graphing-practice-1-a-bar-chart",
    "href": "chapters/A5-Self_Study_Tasks.html#task-4-graphing-practice-1-a-bar-chart",
    "title": "Self Study Tasks",
    "section": "\n0.4 Task 4 Graphing Practice #1 A Bar Chart",
    "text": "0.4 Task 4 Graphing Practice #1 A Bar Chart\n\nDraw a bar chart of the mean mathematics scores for Germany, the UK, the US and China\n\nShow the codePlotdata&lt;-PISA_2022%&gt;%\n  select(CNT, PV1MATH)%&gt;%\n  filter(CNT == \"United Kingdom\"| CNT == \"United States\"|\n           CNT == \"Germany\"| CNT == \"B-S-J-Z (China)\")%&gt;%\n  group_by(CNT)%&gt;%\n  summarise(mean = mean(PV1MATH))\n\nggplot(Plotdata,               # Pass the data to be plotted to ggplot\n       aes(x = CNT, y = mean))+    # set the x and y varibale\n  geom_col(fill = \"red\")         # plot a column graph and fill in red",
    "crumbs": [
      "Appendicies",
      "Self Study Tasks"
    ]
  },
  {
    "objectID": "chapters/A5-Self_Study_Tasks.html#task-5-graphing-practice-2-a-bar-chart-with-two-series",
    "href": "chapters/A5-Self_Study_Tasks.html#task-5-graphing-practice-2-a-bar-chart-with-two-series",
    "title": "Self Study Tasks",
    "section": "\n0.5 Task 5 Graphing Practice #2 A Bar Chart with two series",
    "text": "0.5 Task 5 Graphing Practice #2 A Bar Chart with two series\n\nDraw a bar chart of the mean mathematics scores for Germany, the UK, the US and Korea for boys and girls\n\nShow the codePlotdata&lt;-PISA_2022%&gt;%\n  select(CNT, PV1MATH, ST004D01T)%&gt;%\n  filter(CNT == \"United Kingdom\"|CNT==\"United States\"|\n           CNT == \"Germany\"|CNT == \"Korea\")%&gt;%\n  group_by(CNT, ST004D01T)%&gt;%\n  summarise(mean = mean(PV1MATH))\n\nggplot(Plotdata,\n       aes(x = CNT, y=mean, fill = ST004D01T))+ # Setting the fill to the gender\n                                            # variable gives two series\n  geom_col(position = position_dodge())     # position_dodge here means the\n\n\n\n\n\n\nShow the code                                            # means the bars are plotted                                                # side by side",
    "crumbs": [
      "Appendicies",
      "Self Study Tasks"
    ]
  },
  {
    "objectID": "chapters/A5-Self_Study_Tasks.html#task-6-graphing-practice-3-a-scatter-plot",
    "href": "chapters/A5-Self_Study_Tasks.html#task-6-graphing-practice-3-a-scatter-plot",
    "title": "Self Study Tasks",
    "section": "\n0.6 Task 6 Graphing Practice #3 A scatter plot",
    "text": "0.6 Task 6 Graphing Practice #3 A scatter plot\n\nPlot a graph of science scores against mathematics scores for students in the UK\n\nShow the codePlotdata&lt;-PISA_2022%&gt;%              # Create a new data frame to be plotted\n  select(CNT, PV1MATH, PV1SCIE)%&gt;%  # Choose the country, and scores vectors\n  filter(CNT == \"United Kingdom\")    # Filter for only Uk results\n\nggplot(Plotdata,                  # Pass the data to be plotted to ggplot\n       aes(x = PV1MATH, y = PV1SCIE))+ # Define the x and y variable\n      geom_point(size = 0.1, alpha = 0.2, colour=\"red\")+ \n                                  # Use geom-point to create a scatter                                      # graph and set the size of the point \n                                    # alpha (i.e transparency)\n      labs(x = \"Math Score\", y = \"Science score\") # Add clearer labels",
    "crumbs": [
      "Appendicies",
      "Self Study Tasks"
    ]
  },
  {
    "objectID": "chapters/A5-Self_Study_Tasks.html#task-7-graphing-practice-4-a-scatter-plot-with-multiple-series",
    "href": "chapters/A5-Self_Study_Tasks.html#task-7-graphing-practice-4-a-scatter-plot-with-multiple-series",
    "title": "Self Study Tasks",
    "section": "\n0.7 Task 7 Graphing Practice #4 A scatter plot with multiple series",
    "text": "0.7 Task 7 Graphing Practice #4 A scatter plot with multiple series\n\nPlot a graph of science scores against mathematics scores for students in the UK, with data split into two series for boys and girls\n\nShow the codePlotdata&lt;-PISA_2022%&gt;%              # Create a new dataframe to be plotted\n  select(CNT, PV1MATH, PV1SCIE, ST004D01T)%&gt;%  \n  filter(CNT == \"United Kingdom\")    # Filter for only Uk results\n\nggplot(Plotdata,                  \n       aes(x = PV1MATH, y = PV1SCIE, colour = ST004D01T))+ \n      geom_point(size = 0.1, alpha = 0.2)+ \n                          # As above, but set colour by the gender varibale\n      labs(x = \"Math Score\", y = \"Science score\")",
    "crumbs": [
      "Appendicies",
      "Self Study Tasks"
    ]
  },
  {
    "objectID": "chapters/A5-Self_Study_Tasks.html#task-8-graphing-practice-4-a-scatter-plot-with-varying-size-points",
    "href": "chapters/A5-Self_Study_Tasks.html#task-8-graphing-practice-4-a-scatter-plot-with-varying-size-points",
    "title": "Self Study Tasks",
    "section": "\n0.8 Task 8 Graphing Practice #4 A scatter plot with varying size points",
    "text": "0.8 Task 8 Graphing Practice #4 A scatter plot with varying size points\n\nPlot a graph of mean science scores against mean mathematics scores for all the countries in the data set. Vary the point size by the number of students per country.\n\nShow the codePlotdata&lt;-PISA_2022%&gt;%\n  select(CNT, PV1MATH, PV1SCIE) %&gt;%\n  group_by(CNT) %&gt;%\n  summarise(meansci = mean(PV1SCIE), meanmath=mean(PV1MATH), total=n())\n\n  # Summarise finds mean scores by countries and n() is used to sum\n  # the number of students in each country\n\nggplot(Plotdata,\n       aes(x = meansci, y = meanmath, size = total, colour = \"red\"))+\n  # The size aesthetic is set to the total entries value computed\n  # for the data set\n  geom_point()+\n  labs(x = \"Mean science score\", y = \"Mean math score\")",
    "crumbs": [
      "Appendicies",
      "Self Study Tasks"
    ]
  },
  {
    "objectID": "chapters/A5-Self_Study_Tasks.html#task-9-graphing-practice-5-a-mosaic-plot",
    "href": "chapters/A5-Self_Study_Tasks.html#task-9-graphing-practice-5-a-mosaic-plot",
    "title": "Self Study Tasks",
    "section": "\n0.9 Task 9 Graphing Practice #5 A mosaic plot",
    "text": "0.9 Task 9 Graphing Practice #5 A mosaic plot\n\nPlot a mosaic plot of the number of students who speak (use LANGN) French and Spanish in the whole data set\n\nShow the codeLang&lt;-PISA_2022 %&gt;%\n  select(ST004D01T, LANGN) %&gt;%\n  filter(LANGN == \"French\" | LANGN == \"Spanish\") %&gt;%\n  na.omit() %&gt;%\n  droplevels()\n\nlibrary(ggmosaic)\nggplot(Lang)+\n  geom_mosaic(aes(x = product(ST004D01T, LANGN), fill = LANGN))",
    "crumbs": [
      "Appendicies",
      "Self Study Tasks"
    ]
  },
  {
    "objectID": "chapters/A5-Self_Study_Tasks.html#task-10-t-test-practice-1",
    "href": "chapters/A5-Self_Study_Tasks.html#task-10-t-test-practice-1",
    "title": "Self Study Tasks",
    "section": "\n0.10 Task 10 T-test practice #1",
    "text": "0.10 Task 10 T-test practice #1\n\nUsing the PISA 2022 data set, determine if there are statistically significant differences between the science, reading and mathematics scores of the UK and the US.\n\nShow the code# Create data frames with the score results for UK and US\nUKscores&lt;-PISA_2022%&gt;%\n  select(CNT,PV1MATH,PV1READ, PV1SCIE)%&gt;%\n  filter(CNT == \"United Kingdom\")\n\nUSscores&lt;-PISA_2022%&gt;%\n  select(CNT,PV1MATH,PV1READ, PV1SCIE)%&gt;%\n  filter(CNT == \"United States\")\n\n# Perform the t-test with maths results\n\nt.test(UKscores$PV1MATH, USscores$PV1MATH)\n\n\n    Welch Two Sample t-test\n\ndata:  UKscores$PV1MATH and USscores$PV1MATH\nt = 12.614, df = 7958.4, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n 17.45734 23.88158\nsample estimates:\nmean of x mean of y \n 482.5427  461.8733 \n\nShow the code# p-value is &lt; 2.2e-16 so significant differences exist for maths\n\nt.test(UKscores$PV1READ, USscores$PV1READ)\n\n\n    Welch Two Sample t-test\n\ndata:  UKscores$PV1READ and USscores$PV1READ\nt = -6.4317, df = 7555.2, p-value = 1.339e-10\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -15.887576  -8.465219\nsample estimates:\nmean of x mean of y \n 490.7616  502.9380 \n\nShow the code# p-value = 1.339e-10 - statistically significant differences exist for reading between Uk and US\n\nt.test(UKscores$PV1SCIE, USscores$PV1SCIE)\n\n\n    Welch Two Sample t-test\n\ndata:  UKscores$PV1SCIE and USscores$PV1SCIE\nt = -3.2425, df = 7545.7, p-value = 0.00119\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -9.604044 -2.366899\nsample estimates:\nmean of x mean of y \n 492.2651  498.2506 \n\nShow the code# p-value = 0.00119  significant differences exist for science between the UK and US",
    "crumbs": [
      "Appendicies",
      "Self Study Tasks"
    ]
  },
  {
    "objectID": "chapters/A5-Self_Study_Tasks.html#task-11-t-test-practice-2",
    "href": "chapters/A5-Self_Study_Tasks.html#task-11-t-test-practice-2",
    "title": "Self Study Tasks",
    "section": "\n0.11 Task 11 T-test practice #2",
    "text": "0.11 Task 11 T-test practice #2\n\nDivide the UK population into two groups, those that have internet access at home (ST250Q05JA) and those who do not. Are there statistically significant differences in the means of their reading, science and mathematics scores?\n\nShow the code# Create data frames with the score results for UK in two\n# groups, has internet and no internet, based on ST011Q06TA\n\nUKHasIntscores&lt;-PISA_2022%&gt;%\n  select(CNT,PV1MATH,PV1READ, PV1SCIE, ST250Q05JA)%&gt;%\n  filter(CNT==\"United Kingdom\" & ST250Q05JA == \"Yes\")\n\nUKNoIntscores&lt;-PISA_2022%&gt;%\n  select(CNT,PV1MATH,PV1READ, PV1SCIE, ST250Q05JA)%&gt;%\n  filter(CNT==\"United Kingdom\" & ST250Q05JA == \"No\")\n\n# Perform the t-test with maths results\nt.test(UKHasIntscores$PV1MATH, UKNoIntscores$PV1MATH)\n\n\n    Welch Two Sample t-test\n\ndata:  UKHasIntscores$PV1MATH and UKNoIntscores$PV1MATH\nt = 10.177, df = 86.803, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n  72.1637 107.1935\nsample estimates:\nmean of x mean of y \n 485.8926  396.2140 \n\nShow the code# p-value is &lt; 2.2e-16 so no significant differences for maths scores from\n\n# those with and without internet\n\nt.test(UKHasIntscores$PV1READ, UKNoIntscores$PV1READ)\n\n\n    Welch Two Sample t-test\n\ndata:  UKHasIntscores$PV1READ and UKNoIntscores$PV1READ\nt = 10.117, df = 86.294, p-value = 2.547e-16\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n  92.92909 138.37826\nsample estimates:\nmean of x mean of y \n 495.4067  379.7530 \n\nShow the code# p-value = 2.547e-16 so no signficant differences for reading scores from\n\n# those with and without internet\n\nt.test(UKHasIntscores$PV1SCIE, UKNoIntscores$PV1SCIE)\n\n\n    Welch Two Sample t-test\n\ndata:  UKHasIntscores$PV1SCIE and UKNoIntscores$PV1SCIE\nt = 9.3975, df = 86.657, p-value = 7.135e-15\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n  73.60024 113.08755\nsample estimates:\nmean of x mean of y \n 495.8116  402.4677 \n\nShow the code# p-value = 7.135e-15 so no signficant differences for science scores from\n# those with and without internet",
    "crumbs": [
      "Appendicies",
      "Self Study Tasks"
    ]
  },
  {
    "objectID": "chapters/A5-Self_Study_Tasks.html#task-12-t-test-practice-3",
    "href": "chapters/A5-Self_Study_Tasks.html#task-12-t-test-practice-3",
    "title": "Self Study Tasks",
    "section": "\n0.12 Task 12 T-test practice #3",
    "text": "0.12 Task 12 T-test practice #3\n\nUsing the PISA 2022 data set, are the mean mathematics scores of US boys and girls different to a statistically significant degree?\n\nShow the code# Create a data frame of US boys math scores\n\nUSboys &lt;- PISA_2022 %&gt;%\n  select(CNT, PV1MATH, ST004D01T)%&gt;%\n  filter(CNT == \"United States\")\n\n# Create a dataframe of US girls math scores\n\nUSgirls &lt;- PISA_2022 %&gt;%\n  select(CNT, PV1MATH, ST004D01T) %&gt;%\n  filter(CNT == \"United States\")\n\n# Perform the t-test, using $PVMATH to indicate which column of the data frame to use\n\nt.test(USboys$PV1MATH, USgirls$PV1MATH)\n\n\n    Welch Two Sample t-test\n\ndata:  USboys$PV1MATH and USgirls$PV1MATH\nt = 0, df = 9102, p-value = 1\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -3.90872  3.90872\nsample estimates:\nmean of x mean of y \n 461.8733  461.8733 \n\nShow the code# The p-value is 1 which is over 0.05 suggesting we accept the null hypothesis, there are no  statistically significant difference in US girls and boys math scores",
    "crumbs": [
      "Appendicies",
      "Self Study Tasks"
    ]
  },
  {
    "objectID": "chapters/A5-Self_Study_Tasks.html#task-13-t-test-practice-3",
    "href": "chapters/A5-Self_Study_Tasks.html#task-13-t-test-practice-3",
    "title": "Self Study Tasks",
    "section": "\n0.13 Task 13 T-test practice #3",
    "text": "0.13 Task 13 T-test practice #3\n\nAre the mean science scores of all students in the US and the UK different to a statistically significant degree?\n\nShow the code# Create a data frame of US science scores\n\nUSSci&lt;-PISA_2022 %&gt;%\n  select(CNT, PV1SCIE)%&gt;%\n  filter(CNT == \"United States\")\n\n# Create a data frame of UK science scores\n\nUKSci&lt;-PISA_2022 %&gt;%\n  select(CNT, PV1SCIE)%&gt;%\n  filter(CNT == \"United Kingdom\")\n\n# Perform the t-test, using $PV1SCIE to indicate which column of the dataframe to use\n\nt.test(USSci$PV1SCIE, UKSci$PV1SCIE)\n\n\n    Welch Two Sample t-test\n\ndata:  USSci$PV1SCIE and UKSci$PV1SCIE\nt = 3.2425, df = 7545.7, p-value = 0.00119\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n 2.366899 9.604044\nsample estimates:\nmean of x mean of y \n 498.2506  492.2651 \n\nShow the code# The p-value is 0.00119, less than 0.05, so we reject the null hypothesis, there are statistically significant differences between US and UK science scores",
    "crumbs": [
      "Appendicies",
      "Self Study Tasks"
    ]
  },
  {
    "objectID": "chapters/A5-Self_Study_Tasks.html#task-14-kruskal-wallis-practice-1",
    "href": "chapters/A5-Self_Study_Tasks.html#task-14-kruskal-wallis-practice-1",
    "title": "Self Study Tasks",
    "section": "\n0.14 Task 14 Kruskal Wallis practice #1",
    "text": "0.14 Task 14 Kruskal Wallis practice #1\n\nAre there statistically significant differences in the proportion of boys and girls who Working in household/take care of family members before or after school (WORKHOME) for the whole dataset? Note the responses are:\n\nNo work in household or care of family members\n1 time of working in household or caring for family members per week\n2 times of working in household or caring for family members per week\n3 times of working in household or caring for family members per week\n4 times of working in household or caring for family members per week\n5 times of working in household or caring for family members per week\n6 times of working in household or caring for family members per week\n7 times of working in household or caring for family members per week\n8 times of working in household or caring for family members per week\n9 times of working in household or caring for family members per week\n10 or more times of working in household or caring for family members per week\n\n\nShow the code# Create a data frame of including gender and working or caring\n\nworkcare &lt;- PISA_2022 %&gt;%\n  select(WORKHOME, ST004D01T) %&gt;%\n  filter(!is.na(WORKHOME))\n\n# As the data are ordinal, use a kurskal wallis test\n\nkruskal.test(data=workcare, WORKHOME ~ ST004D01T )\n\n# p-value &lt; 2.2e-16 so there are statistically significant differences between genders\n\n# plot the results\n\nworkcare&lt;-workcare %&gt;%\n  droplevels()%&gt;%\n  na.omit()\n\nggplot(data = workcare)+\n   geom_mosaic(aes(x=product(WORKHOME, ST004D01T), fill=WORKHOME))+\n  scale_y_discrete(label=abbreviate)",
    "crumbs": [
      "Appendicies",
      "Self Study Tasks"
    ]
  },
  {
    "objectID": "chapters/A5-Self_Study_Tasks.html#task-15-chi-square-practice-1",
    "href": "chapters/A5-Self_Study_Tasks.html#task-15-chi-square-practice-1",
    "title": "Self Study Tasks",
    "section": "\n0.15 Task 15 Chi-square practice #1",
    "text": "0.15 Task 15 Chi-square practice #1\n\nAre there statistically significant differences, in the US, in the languages spoken (LANGN) by boys and girls?\n\nShow the code# Create a data frame of languages spoken in the US, including gender\n\nUSLang &lt;- PISA_2022 %&gt;%\n  filter(CNT == \"United States\") %&gt;%\n  select(LANGN, ST004D01T) %&gt;%\n  na.omit() %&gt;%\n  droplevels()\n\n# Create a contingency table\n\nContab &lt;- xtabs(data=USLang, ~ LANGN + ST004D01T)\n\n# Run the chi.sq test\n\nchisq.test(Contab)\n\n\n    Pearson's Chi-squared test\n\ndata:  Contab\nX-squared = 7.9695, df = 3, p-value = 0.04665\n\nShow the code# The output p-value is 0.04665 which is less than 0.05. So reject the null hypothesis. There is a difference in language by gender",
    "crumbs": [
      "Appendicies",
      "Self Study Tasks"
    ]
  },
  {
    "objectID": "chapters/A5-Self_Study_Tasks.html#task-16-chi-square-practice-3",
    "href": "chapters/A5-Self_Study_Tasks.html#task-16-chi-square-practice-3",
    "title": "Self Study Tasks",
    "section": "\n0.16 Task 16 Chi-square practice #3",
    "text": "0.16 Task 16 Chi-square practice #3\n\nAre there statistically significant differences in numbers of students missing school for more than 3 months because they were bored (ST261Q01JA) between the UK and US\n\nShow the code# ST261Q01JA - Why miss school for 3+ months: I was bored.\n# Create a data frame for the two countries\n\nBored &lt;- PISA_2022 %&gt;%\n  select(CNT, ST261Q01JA) %&gt;%\n  filter(CNT == \"United Kingdom\" | CNT == \"United States\") %&gt;%\n  droplevels() %&gt;%\n  na.omit()\n\n# Create a contingency table\n\nContab &lt;- xtabs(data=Bored, ~ CNT + ST261Q01JA)\n\n# Do the chi squared test\n\nchisq.test(Contab)\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  Contab\nX-squared = 26.573, df = 1, p-value = 2.537e-07\n\nShow the code# p-value is less than 0.05 (2.537e-07), so reject the null hypotheses - there are statistically significant differences in boredom in the UK and the US",
    "crumbs": [
      "Appendicies",
      "Self Study Tasks"
    ]
  },
  {
    "objectID": "chapters/A5-Self_Study_Tasks.html#task-18-anova-practice-1",
    "href": "chapters/A5-Self_Study_Tasks.html#task-18-anova-practice-1",
    "title": "Self Study Tasks",
    "section": "\n0.17 Task 18 Anova practice #1",
    "text": "0.17 Task 18 Anova practice #1\n\nAre there statistically significant differences in mathematics scores of students in France, Germany, Spain, the UK and Italy? Find between which pairs of countries there are statistically significant differences in mathematics scores.\n\nShow the code# Create a data frame of the required countries\n\nEuroPISA &lt;- PISA_2022 %&gt;%\n  select(CNT, PV1MATH)%&gt;%\n  filter(CNT %in% c(\"Spain\", \"France\", \"United Kingdom\", \"Italy\", \"Germany\"))\n\n# Perform the anova\n\nresaov &lt;- aov(data = EuroPISA, PV1MATH ~ CNT)\nsummary(resaov)\n\n               Df    Sum Sq Mean Sq F value Pr(&gt;F)    \nCNT             4   1236408  309102      39 &lt;2e-16 ***\nResiduals   67205 532663398    7926                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nShow the code# Yes, statistically significant differences exist between the countries Pr(&gt;F) &lt;2e-16 ***\n# Perform a Tukey HSD test\n\nTukeyHSD(resaov)\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = PV1MATH ~ CNT, data = EuroPISA)\n\n$CNT\n                             diff         lwr       upr     p adj\nSpain-Germany            3.140287  -0.2593483  6.539922 0.0862603\nFrance-Germany          -9.679799 -13.9639526 -5.395645 0.0000000\nUnited Kingdom-Germany   4.767983   1.0011433  8.534822 0.0050336\nItaly-Germany           -2.548557  -6.4513428  1.354228 0.3845106\nFrance-Spain           -12.820085 -16.0798407 -9.560330 0.0000000\nUnited Kingdom-Spain     1.627696  -0.9141750  4.169566 0.4051954\nItaly-Spain             -5.688844  -8.4281440 -2.949544 0.0000001\nUnited Kingdom-France   14.447781  10.8066875 18.088875 0.0000000\nItaly-France             7.131241   3.3496782 10.912805 0.0000027\nItaly-United Kingdom    -7.316540 -10.5001420 -4.132937 0.0000000\n\nShow the code# Significant differences p&lt;0.05 exist for all countries except: Spain-Germany; Italy-Germany, UK-Spain.",
    "crumbs": [
      "Appendicies",
      "Self Study Tasks"
    ]
  },
  {
    "objectID": "chapters/A5-Self_Study_Tasks.html#task-19-anova-practice-2",
    "href": "chapters/A5-Self_Study_Tasks.html#task-19-anova-practice-2",
    "title": "Self Study Tasks",
    "section": "\n0.18 Task 19 Anova practice #2",
    "text": "0.18 Task 19 Anova practice #2\n\nFor the UK PISA 2022 data set, which variable out of HOMEPOS, ST004D01T, OCOD1 (Mother’s occupation), OCOD2 (Father’s occupation), ST250Q05JA (having a link to the internet), and highest level of parental education (HISCED) accounts for the most variation in science score? What percentage of variance is explained by each variable?\n! This is a big calculation so will take some time to compute !\n\nShow the code# Create a data frame for the UK\nUKPISA_2022 &lt;- PISA_2022 %&gt;%\n  filter(CNT == \"United Kingdom\")\n\n# Perform the anova calculation with science score as the dependent variable\n\nresaov &lt;- aov(data=UKPISA_2022, \n              PV1SCIE ~ HOMEPOS + ST004D01T + OCOD1 + OCOD2 + ST250Q05JA + HISCED)\n\n# Print the output\nsummary(resaov)\n\n              Df   Sum Sq  Mean Sq  F value   Pr(&gt;F)    \nHOMEPOS        1 13423366 13423366 1571.542  &lt; 2e-16 ***\nST004D01T      1   224779   224779   26.316 2.95e-07 ***\nOCOD1        406  7197744    17728    2.076  &lt; 2e-16 ***\nOCOD2        483  6944691    14378    1.683  &lt; 2e-16 ***\nST250Q05JA     1   110018   110018   12.880 0.000334 ***\nHISCED         9  1636209   181801   21.284  &lt; 2e-16 ***\n [ reached getOption(\"max.print\") -- omitted 1 row ]\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n2418 observations deleted due to missingness\n\nShow the code# Calculate the value of eta and multiple by a 100 to get the % of variance explained\neta &lt;- etaSquared(resaov)\neta &lt;- 100*eta\neta &lt;- as.data.frame(eta)\neta\n\n               eta.sq eta.sq.part\nHOMEPOS    3.99268041   5.1441641\nST004D01T  0.32032198   0.4331991\nOCOD1      4.63295284   5.9202525\nOCOD2      6.12139253   7.6762624\nST250Q05JA 0.08516107   0.1155381\nHISCED     1.46116663   1.9460370\n\nShow the code# The variable that explains most variation in science scores is father's occupation OCOD2 (7.7%), then home possession OCOD1 (5.9%), then wealth HOMEPOS (5.1%)",
    "crumbs": [
      "Appendicies",
      "Self Study Tasks"
    ]
  },
  {
    "objectID": "chapters/04-Introduction_to_PISA.html",
    "href": "chapters/04-Introduction_to_PISA.html",
    "title": "04 Introduction to PISA",
    "section": "",
    "text": "Please read section 1 (“What is PISA?”) of the PISA 2022 Assessment and Analytical Framework: PISA Assessment Framework\n\n\n\nRemember to load the PISA 2022 data set\n\nlibrary(arrow)\nlibrary(tidyverse)\n\nPISA_2022 &lt;- read_parquet(r\"[&lt;folder&gt;PISA_2022_student_subset.parquet]\")\n\n\n\n\n\nThe first International Large-Scale Assessment (ILSA) comparing the learning outcomes of school students between countries was attempted in the 1960s. However, ILSAs only became established and regular in the late 1990s and 2000s.\nThe Organisation for Economic Co-operation and Development’s (OECD) Programme for International Student Assessment (PISA) has tested 15-year-old students in a range of “literacies” or “competencies” every three years since 2000. There is a rotating focus on reading, mathematics and science, with PISA 2021 focusing on mathematics but delayed by the global pandemic until 2022 and the results only published in December 2023. Until then, PISA 2018, with a focus on reading, was the most recently available cycle and PISA 2015 remains the most recent cycle focusing on science.\nIn addition to reading, mathematics and science, PISA has tested students on a range of “novel” competencies including problem-solving, global competence, financial literacy, and creative thinking. In addition to these tests, PISA also administers questionnaires to students, teachers and parents to identify “factors” which explain test score differences within and between countries.\nSince 2000, more than 90 “countries and economies” and around 3,000,000 students have participated in PISA. The growth in the number of countries participating in each cycle of PISA is reflected in the growth in the number of students taking the PISA tests and responding to the PISA questionnaires, as shown in Table 1.\nTable 1: Number of students participating in PISA by year\n\n\n\nYear\nNumber completing assessment\n\n\n\n\n2000\n265,000\n\n\n2003\n275,000\n\n\n2006\n400,000\n\n\n2009\n470,000\n\n\n2012\n510,000\n\n\n2015\n540,000\n\n\n2018\n600,000\n\n\n2022\n690,000\n\n\n\nThere is a degree of inherent error in all educational and psychological assessments - and indeed in all social or physical measurement. ILSAs such as PISA may be more prone to error because their comparisons across large and diverse populations make them particularly complex. However, it is particularly important to minimise the error in ILSAs because they influence education policy and practice across a large number of education systems, impacting a vast population of students beyond those sampled for the assessments.\nAccording to the OECD (2019), three sources of error are worth considering. First, sampling error, uncertainty in the degree to which results from the sample generalise to the wider population - in 2018, the OECD average sampling error was 0.4 of a PISA point score (the value was not reported for 2022). Second, measurement error, uncertainty in the extent to which test items measure proficiency. In 2018, the measurement error was around 0.8 of a point in mathematics and science and 0.5 of a score point in reading (the measurement error was not reported for 2022). Third, the link error is the uncertainty in comparison between scores in different years. For comparisons of science scores between 2018 and 2015, the link error is 1.5 points. For 2018-2022, the link errors are reading (1.47), mathematics (2.24) and science (1.61) (OECD 2022, 293)\nPISA uses a probabilistic, stratified clustered survey design (Jerrim et al. 2017). However, sampling issues including sample representativeness, non-response rates and population coverage have been identified (Zieger et al. 2022; Rutkowski and Rutkowski 2016; Gillis, Polesel, and Wu 2016; Hopmann, Brinek, and Retzl 2007). Furthermore, Anders et al. (2021) and Jerrim (2021) have shown that assumptions for imputing values (imputing means estimating any missing values based on existing data - for example by adding a mean or mode score for a missing test) for non-participating students used to construct the sample may have significant impacts on achievement scores.\nSince PISA 2015, the majority of participating countries have switched from paper-based assessment to computer-based assessment (Jerrim 2016). A randomised controlled trial conducted by the OECD prior to the switch indicated a difference in score between the two modes of delivery. The OECD introduced an adjustment to compensate for this difference, but it is not entirely removed by the adjustment Jerrim et al. (2018), with implications for any time series comparisons between PISA cycles. Nonetheless, Jerrim (2016) notes that “in terms of cross-country rankings, there remains a high degree of consistency… the vast majority of countries are simply ‘shifted’ by a uniform amount” (pp. 508-509).\nIn summary, comparisons within and between countries and comparisons over time using ILSAs need careful interpretations that bear in mind the specific design of each ILSA. In practice, this means considering a range of potential explanations for score differences. Does a difference in science ranking between two countries simply reflect sampling error? Does the same parental occupation or home possessions amount to the same economic, social and cultural status in different countries (e.g. the social status of a parent as a teacher or the economic status of the number of cars a family owns)? Does a difference in mathematical self-efficacy (i.e. student self-confidence in mathematics) between the USA and Japan reflect sociocultural differences in self-enhancement and modesty, respectively? How do score differences between boys and girls indicate gender inequalities in education that reflect wider society?\n\n\n\n\n\n\nTip\n\n\n\nFor useful critique and discussion of the construction of the measure of socio-economic status in PISA data see: Avvisati’s (2020) paper.\n\n\n\n\n\n\n\nRecall you can use group_by and summarise to group individual student measures and find means and standard deviations for countries. For example, to find the mean wealth scores for the countries, and rank in descending order, we first select the variables of interest CNT and HOMEPOS (home possessions, a proxy for wealth), then group_by CNT and summarise to get the mean. As there are some NA values, we need to include na.rm=TRUE to tell summarise to ignore the missing values. Finally, we arrange in descending order by the new variable we create meanwealth. We can do the same and add a calculation to get the standard deviation.\n\n# Create a data frame of PISA 2022 data of country mean wealth\n\nPISA2022WealthRank &lt;- PISA_2022 %&gt;%\n2  select(CNT, HOMEPOS) %&gt;%\n3  group_by(CNT) %&gt;%\n4  summarise(meanwealth = mean(HOMEPOS, na.rm = TRUE)) %&gt;%\n5  arrange(desc(meanwealth))\n\nPISA2022WealthRank\n\n# With standard deviations\n\nPISA2022WealthRank &lt;- PISA_2022 %&gt;%\n  select(CNT, HOMEPOS) %&gt;% \n  group_by(CNT) %&gt;% \n  summarise(meanwealth = mean(HOMEPOS, na.rm = TRUE),  \n            sdwealth=sd(HOMEPOS, na.rm = TRUE)) %&gt;%\n  arrange(desc(meanwealth)) \n\nPISA2022WealthRank\n\n\n2\n\nline 2 - select the variables of interest\n\n3\n\nline 3 - treat the data as grouped by country (group_by(CNT))\n\n4\n\nline 4 - summarise to calculate the mean score of HOMEPOS in a new column meanwealth, setting na.rm=TRUE to ignore NA values\n\n5\n\nline 5 - arrange in descending order by meanwealth\n\n\n\n\n# A tibble: 80 × 2\n   CNT         meanwealth\n   &lt;fct&gt;            &lt;dbl&gt;\n 1 Norway           0.547\n 2 Australia        0.483\n 3 Korea            0.371\n 4 New Zealand      0.367\n 5 Canada           0.348\n 6 Iceland          0.346\n 7 Sweden           0.327\n 8 Ireland          0.318\n 9 Malta            0.308\n10 Austria          0.280\n# ℹ 70 more rows\n# A tibble: 80 × 3\n   CNT         meanwealth sdwealth\n   &lt;fct&gt;            &lt;dbl&gt;    &lt;dbl&gt;\n 1 Norway           0.547    0.970\n 2 Australia        0.483    0.861\n 3 Korea            0.371    1.01 \n 4 New Zealand      0.367    0.862\n 5 Canada           0.348    0.867\n 6 Iceland          0.346    0.805\n 7 Sweden           0.327    0.878\n 8 Ireland          0.318    0.818\n 9 Malta            0.308    0.857\n10 Austria          0.280    0.938\n# ℹ 70 more rows\n\n\n\n\n\nRecall you can use geom_bar to plot a bar graph. For example, if we wanted to plot the PISA2022WealthRank data frame we just created, we pass the data to ggplot. Recall that if you are passing geom_bar the exact values you want to plot, rather than making it count (for example, by including the original dataset with all student entries), you need to specify geom_bar(stat='identity')\nI have added +theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) which rotates the text on the x-axis.\n\n# Plot a bar graph of wealth by country\n\n1ggplot(PISA2022WealthRank, aes(x = CNT, y = meanwealth)) +\n2  geom_bar(stat = 'identity') +\n3  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))\n\n\n1\n\nline 1 - pass the PISA2022WealthRank to ggplot and set the x and y variables\n\n2\n\nline 2 - as the data are already summarised, we don’t want geom_bar to count items, but tell it to just plot the data as it is\n\n3\n\nline 3 - rotate the x-axis text\n\n\n\n\n\n\n\n\n\n\n\nWe can improve this plot by reordering the x-axis to rank the countries - we switch x=CNT to x=reorder(CNT, -meanwealth) that is we reorder the x axis based on descending (indicated by the minus sign -meanwealth) meanwealth.\n\n# Plot the wealth data frame as a bar graph, reordering the x axis by wealth\n\n1ggplot(PISA2022WealthRank, aes(x=reorder(CNT, -meanwealth), y = meanwealth)) +\n  geom_bar(stat='identity') +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))       \n\n\n1\n\nline 1 - rather than simply specifying the x axis (e.g. x=CNT) to change the order of the x-axis by the meanwealth score we can use x=reorder(CNT, -meanwealth). Note the - before meanwealth sets the order is descending.\n\n\n\n\n\n\n\n\n\n\n\nIf you like, you can add colour, tidy up the axis labels, and give a title:\n\n# Plot the wealth data frame as a bar graph, reordering the x axis by wealth\n\nggplot(PISA2022WealthRank, aes(x = reorder(CNT, -meanwealth), \n                               y = meanwealth)) +\n3  geom_bar(stat='identity', fill = \"skyblue\") +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +\n5  ggtitle(\"Countries ranked by HOMEPOS\") +\n6  xlab(\"Country\") +\n  ylab(\"Mean HOMEPOS\")\n\n\n3\n\nline 3 - set the bar fill colour to sky blue (fill = \"skyblue\")\n\n5\n\nline 6 - set the x-axis title\n\n6\n\nline 7 - set the y-axis title\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTo plot a scatter plot, recall we use geom_point. For example, to plot reading scores against mathematics scores in the UK we: a) create a data set of reading and science scores after filtering for UK; b) pass the data to ggplot; c) use aes to specify the x and y variables and d) plot with geom_point().\n\n# Create a data.frame of the UK's science and reading scores\n\nUKplot &lt;- PISA_2022 %&gt;%\n  select(CNT, PV1READ, PV1SCIE) %&gt;%\n  filter(CNT == \"United Kingdom\")\n\n# Plot the data on a scatter graph using geom_point\n\nggplot(UKplot, aes(x = PV1READ, y = PV1SCIE)) +\n  geom_point()\n\n\n\n\n\n\n\n\nThat graph is quite dense, so we can use the alpha function to make the points slightly transparent, size to make them smaller, and set their colour. I will also tidy up the axis names and add a line (note that in: geom_smooth(method = \"lm\", colour = \"black\") method = \"lm\" sets the line to a straight (i.e., linear model, lm) line).\n\n# Create a data.frame of the UK's science and reading scores\n\nUKplot &lt;- PISA_2022 %&gt;%\n  select(CNT, PV1READ, PV1SCIE) %&gt;%\n  filter(CNT == \"United Kingdom\")\n\n# Plot the data on a scatter graph using geom_point\n\n4ggplot(UKplot, aes(x = PV1READ, y = PV1SCIE)) +\n5  geom_point(alpha = 0.6, size = 0.1, colour = \"red\") +\n6  xlab(\"Reading score\") +\n7  ylab(\"Science score\") +\n8  geom_smooth(method = \"lm\", colour = \"black\")\n\n\n4\n\nline 4 - set the data to plot and set which variable goes on the x and y axis\n\n5\n\nline 5 - set the point size (size=0.1), colour (colour = \"red\") and opacity (alpha = 0.6)\n\n6\n\nline 6 - set the x-axis title\n\n7\n\nline 7 - set the y-axis title\n\n8\n\nline 8 - plot a straight line (method = \"lm\") and set its colour to black\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAn alternative type of plot is the density plot, which is a kind of continuous histogram. The density plot can be useful for visualising the achievement scores of students. For example, the mathematics scores of girls and boys (recall the gender variable is ST004D01T) in the US. We use na.omit to omit NAs. Notice, for the plot, I use aes to set my x variable, and then specify that the plot should fill by gender (fill=ST004D01T). Finally, in geom_density(alpha=0.6) I set the alpha to 0.6 to make the fill areas partially transparent.\n\n\n\n\n\n\nTip\n\n\n\nThe y-axis on a density plot is chosen so that the total area under the graph adds up to 1\n\n\n\n# Create a data.frame of US Math data including gender\n\nUSMathplot &lt;- PISA_2022 %&gt;%\n  select(CNT, PV1MATH, ST004D01T) %&gt;%\n  filter(CNT == \"United States\") %&gt;%\n  na.omit()\n\n# PLot a density chart, seeting the fill by gender, and setting the opacity to\n# 0.6 to show both gender plots\n\nggplot(USMathplot, aes(x = PV1MATH, fill = ST004D01T)) +\n  geom_density(alpha = 0.6)\n\n\n\n\n\n\n\n\n\n\n\nA powerful feature of ggplot is being able to produce the same graph for multiple values of a variable, for example, for multiple countries. For example, we may want to produce the density graph of PV1MATH score by gender, for several countries in the data set. To do that, we produce a data set of PV1MATH scores, and gender (ST004D01T) and filter for four countries (Philippines, UK, Bulgaria and Germany). We use the same code as above to plot the graphs but add +facet_wrap(.~CNT) - facet_wrap tells ggplot to produce a multi-panel plot and .~CNT means do the same as above (the . means, as above), but vary across countries (~CNT).\n\n# Create a data.frame of the maths scores for the 4 countries\nMathplot &lt;- PISA_2022 %&gt;%\n  select(CNT, PV1MATH, ST004D01T) %&gt;%\n  filter(CNT == \"Philippines\"|CNT == \"United Kingdom\"|CNT == \"Bulgaria\" |\n           CNT == \"Germany\")\n\n# Plot the data, changing colour by gender, and faceting for the countries\n\n5ggplot(Mathplot, aes(x = PV1MATH, fill = ST004D01T)) +\n6  geom_density(alpha = 0.6) +\n7  facet_wrap(. ~ CNT)\n\n\n5\n\nline 5 - pass the data to plot Mathplot and set the x axis (no y is needed for a geom_density plot) - set that we want two series, with the colour set by gender (ST004D01T)\n\n6\n\nline 6 - set fill (alpha = 0.6) so both gender plots are visible where they overlap\n\n7\n\nline 7 - facet_wrap repeats the initial graph for some variable. In this case we specify we want the same graph as above (.) but we want to produce versions for each country (~CNT) to give facet_wrap(. ~ CNT)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA useful analytical choice is to categorise some a numerical variable into ordinal classes. For example, rather than treating HOMEPOS as a continuous scale, you might want to split into high and low wealth groups (for example, those above and below the mean value).\nTo do this, first calculate the mean mean(HOMEPOS). Then we add a new vector, which we will call wealthclass using the mutate function. We set the value of wealthclass using case_when. If HOMEPOS is more than the mean score, we set wealthclass to High, and if it is less than the mean, we set it to Low. We do that using mutate(wealthclass =  case_when(HOMEPOS &gt; mean(HOMEPOS, na.rm =TRUE) ~ \"High\", HOMEPOS &lt; mean(HOMEPOS, na.rm =TRUE) ~ \"Low\", .default = NA)). This means that in the case when HOMEPOS is more than the mean (note the na.rm =TRUE to remove missing values) the value of the new column wealthclass is set to High. When HOMEPOS is less than mean(HOMEPOS, na.rm =TRUE), weatlthclass is set to Low. The .default sets what to return if neither of those conditions are met.\nFor example, create a data frame of UK participants HOMEPOS sorted into HIGH and LOW categories.\n\n# Create a data frame of UK responses\nUKPISA2022 &lt;- PISA_2022 %&gt;%\n  select(CNT, HOMEPOS) %&gt;%\n  filter(CNT == \"United Kingdom\") %&gt;%\n4  mutate(wealthclass =  case_when(HOMEPOS &gt; mean(HOMEPOS, na.rm =TRUE) ~ \"High\",\n                                  HOMEPOS &lt; mean(HOMEPOS, na.rm =TRUE) ~ \"Low\",\n                                   .default = NA)) \nUKPISA2022\n\n\n4\n\nline 4 - mutate to create a new column wealthclass - if HOMEPOS is more than mean(HOMEPOS), set the column to “High” otherwise set it to “Low”\n\n\n\n\n# A tibble: 12,972 × 3\n   CNT            HOMEPOS wealthclass\n   &lt;fct&gt;            &lt;dbl&gt; &lt;chr&gt;      \n 1 United Kingdom  -1.09  Low        \n 2 United Kingdom  -0.418 Low        \n 3 United Kingdom   1.13  High       \n 4 United Kingdom  -0.829 Low        \n 5 United Kingdom  -0.274 Low        \n 6 United Kingdom  NA     &lt;NA&gt;       \n 7 United Kingdom  -0.606 Low        \n 8 United Kingdom  NA     &lt;NA&gt;       \n 9 United Kingdom   0.425 High       \n10 United Kingdom   0.998 High       \n# ℹ 12,962 more rows\n\n\n\n\n\n\n\n\n\n\nDiscuss the design features of PISA (for example, sampling, forms of tests etc.) and the sources of error that arise from them.\nAs researchers, what issues should we bear in mind when interpreting the data? (Consider, for example, measures of wealth, gender and “competency”)\nWhat caveats should policy makers bear in mind when making high stakes decisions based on the PISA measures (for example, what to include to curricula, where to target funding)?\n\n\n\n\n\n\n\n\nTip\n\n\n\nNote that the PISA data collection protocol allows countries to exclude up to 5% of the relevant population (see the PISA 2018 technical report (OECD 2018), Annex A2), in particular allowing the exclusion from the data of either individual students by their disability status, or whole schools which provide specialist education (e.g. for blind students). Permitted exclusions include: “intellectual disability, i.e. a mental or emotional disability resulting in the student being so cognitively delayed that he/she could not perform in the PISA testing environment”, and “functional disability, i.e. a moderate to severe permanent physical disability resulting in the student being unable to perform in the PISA testing environment” along with other exclusions.\n\n\n\n\n\n\nCreate a ranked list of countries by their mean science scores (PV1SCIE). What are the top five countries for science? Do the same for wealth (HOMEPOS). What patterns do you notice? Why might a researcher be critical of such rankings [Extension: Include the standard deviation of each country (hint: use the sd function) - can you detect any patterns?]\n\n\n\n\n\n\n\nTip\n\n\n\nNote that the PISA 2022 links wealth to HOMEPOS (a self reported measure of possessions in the home). You might want to consider the implications of that definition for interpreting the data\n\n\n\n\nShow the answer\n# Create a ranked data data frame for science\n\nPISA2022SciRank &lt;- PISA_2022 %&gt;%\n  select(CNT, PV1SCIE) %&gt;% # Select variables of interest\n  group_by(CNT) %&gt;% # group by country\n  summarise(meansci = mean(PV1SCIE)) %&gt;% \n     # summarise  country data to find the mean Sci score\n  arrange(desc(meansci)) # arrange in descending order based on the meansci score\n\nprint(PISA2022SciRank)\n\n\n# A tibble: 80 × 2\n   CNT               meansci\n   &lt;fct&gt;               &lt;dbl&gt;\n 1 Singapore            561.\n 2 Japan                546.\n 3 Macao (China)        543.\n 4 Korea                531.\n 5 Estonia              527.\n 6 Chinese Taipei       527.\n 7 Hong Kong (China)    525.\n 8 Czech Republic       511.\n 9 Australia            508.\n10 Poland               505.\n# ℹ 70 more rows\n\n\nShow the answer\n# And repeat the ranking for wealth\n\nPISA2022WealthRank &lt;- PISA_2022 %&gt;%\n  select(CNT, HOMEPOS) %&gt;% # Select variables of interest\n  group_by(CNT) %&gt;% # group by country\n  summarise(meanwel = mean(HOMEPOS, na.rm=TRUE)) %&gt;% \n     # summarise  country data to find the mean Sci score\n  arrange(desc(meanwel)) # arrange in descending order based on the meansci score\n\nprint(PISA2022WealthRank)\n\n\n# A tibble: 80 × 2\n   CNT         meanwel\n   &lt;fct&gt;         &lt;dbl&gt;\n 1 Norway        0.547\n 2 Australia     0.483\n 3 Korea         0.371\n 4 New Zealand   0.367\n 5 Canada        0.348\n 6 Iceland       0.346\n 7 Sweden        0.327\n 8 Ireland       0.318\n 9 Malta         0.308\n10 Austria       0.280\n# ℹ 70 more rows\n\n\nShow the answer\n# With standard deviations\n\nPISA2022SciRank &lt;- PISA_2022 %&gt;%\n  select(CNT, PV1SCIE) %&gt;% # Select variables of interest\n  group_by(CNT) %&gt;% # group by country\n  summarise(meansci = mean(PV1SCIE), \n            sdsci = sd(PV1SCIE)) %&gt;% \n  # summarise  country data to find the mean Sci score\n  arrange(desc(meansci)) # arrange in descending order based on the meansci score\n\nprint(PISA2022SciRank)\n\n\n# A tibble: 80 × 3\n   CNT               meansci sdsci\n   &lt;fct&gt;               &lt;dbl&gt; &lt;dbl&gt;\n 1 Singapore            561.  99.6\n 2 Japan                546.  92.7\n 3 Macao (China)        543.  86.6\n 4 Korea                531. 104. \n 5 Estonia              527.  87.7\n 6 Chinese Taipei       527. 102. \n 7 Hong Kong (China)    525.  91.1\n 8 Czech Republic       511. 103. \n 9 Australia            508. 107. \n10 Poland               505.  94.2\n# ℹ 70 more rows\n\n\nShow the answer\nPISA2022WealthRank &lt;- PISA_2022%&gt;%\n  select(CNT, HOMEPOS)%&gt;% # Select variables of interest\n  group_by(CNT) %&gt;% # group by country\n  summarise(meanwel = mean(HOMEPOS, na.rm=TRUE),\n            sdwel = sd(HOMEPOS, na.rm=TRUE)) %&gt;% \n  # summarise  country data to find  mean wealth score\n  arrange(desc(meanwel)) \n  # arrange in descending order based on the meanwel score\nprint(PISA2022WealthRank)\n\n\n# A tibble: 80 × 3\n   CNT         meanwel sdwel\n   &lt;fct&gt;         &lt;dbl&gt; &lt;dbl&gt;\n 1 Norway        0.547 0.970\n 2 Australia     0.483 0.861\n 3 Korea         0.371 1.01 \n 4 New Zealand   0.367 0.862\n 5 Canada        0.348 0.867\n 6 Iceland       0.346 0.805\n 7 Sweden        0.327 0.878\n 8 Ireland       0.318 0.818\n 9 Malta         0.308 0.857\n10 Austria       0.280 0.938\n# ℹ 70 more rows\n\n\n\n\n\n\nUse a scatter plot to show the correlation between HOMEPOS and ESCS. Use a facet_wrap to show the charts for the UK, Japan, Colombia and Sweden. Discuss the different relationships between the two variables across the countries.\n\n\n\n\n\n\n\nTip\n\n\n\nNote that the PISA variable, Economic, Social and Cultural Status ESCS is based on highest parental occupation (‘HISEI’), highest parental education (‘PARED’), and home possessions (‘HOMEPOS’), including books in the home. Do consider the implications of this definition.\n\n\n\n\nShow the answer\n# Create a data frame with the ESCS, gender (ST004D01T) and HOMEPOS variables for the 4 countries \n\nWealthcompPISA&lt;-PISA_2022 %&gt;%\n  select(CNT, ESCS, HOMEPOS, ST004D01T)%&gt;%\n  filter(CNT == \"Japan\" | CNT == \"United Kingdom\" | CNT == \"Colombia\" | CNT == \"Sweden\")\n\n# Use ggplot to create a scatter graph\n# Set the x variable to ESCS and the y to HOMEPOS, set the colour to gender\n# Set point size and transparency\n# Facet wrap to produce graphs for each country\n\nggplot(WealthcompPISA, aes(x = ESCS, y = HOMEPOS, colour=ST004D01T))+\n  geom_point(size=0.1, alpha=0.5)+\n  facet_wrap(.~CNT)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUse geom_density to plot distributions to plot the distribution of Japanese and UK mathematics scores - what patterns do you notice?\n\n\n\n\n\n\n\n\nTip\n\n\n\nTo plot a distribution, you can use geom_density to plot a distribution curve. In ggplot you specify the data, and then in aes set the x-value (the variable of interest, and set the fill to change by different groups). Within the geom_density call you can specify the alpha, the opacity of the plot.\nFor example, to plot science scores in the UK by gender, you would use the code below:\n\n# Create a data frame of UK science scores including gender\n\nUKSci&lt;-PISA_2022 %&gt;%\n  select(CNT, PV1SCIE, ST004D01T) %&gt;%\n  filter(CNT == \"United Kingdom\")\n\n# Plot the density chart, changing colour by gender, and setting the alpha (opacity) to 0.5\nggplot(data = UKSci,\n       aes(x = PV1SCIE, fill = ST004D01T)) +\n  geom_density(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\nShow the answer\n# Create a data frame of UK and Japanese mathematics scores\n\nJPUKMath&lt;-PISA_2022 %&gt;%\n  select(CNT, PV1MATH) %&gt;%\n  filter(CNT == \"United Kingdom\"|CNT == \"Japan\")\n\n# Plot the density chart, changing colour by country, and setting the alpha (opacity) to 0.5\nggplot(data = JPUKMath,\n       aes(x = PV1MATH, fill = CNT)) +\n  geom_density(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExamine gender differences: Plot the distributions of mathematics achievement in the UK by gender. What patterns can you see?\n\n\n\n\nShow the answer\nUKMathGender &lt;- PISA_2022 %&gt;%\n  select(CNT, PV1MATH, ST004D01T) %&gt;%\n  filter(CNT == \"United Kingdom\")\n\nggplot(data = UKMathGender,\n       aes(x = PV1MATH, fill = ST004D01T)) +\n  geom_density(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\n\nPlot density graphs of gender differences in mathematics scores in the UK, Spain, Japan, Korea and Finland. Hint use facet_wrap(.~CNT)\n\n\n\nShow the answer\n# Create a data frame of mathematics scores, gender and country\n# Filter by the five countries of interest\n\nMathGender &lt;- PISA_2022 %&gt;%\n  select(CNT, PV1MATH, ST004D01T) %&gt;%\n  filter(CNT == \"United Kingdom\"|CNT == \"Spain\"|CNT == \"Japan\"\n         | CNT==\"Korea\"|CNT == \"Finland\")\n\n# Plot a density graph of mathematics scores, splitting into groups, with coloured fills by gender. Set transparency to 0.5 to show overlap \n\nggplot(data = MathGender,\n       aes(x = PV1MATH, fill = ST004D01T)) +\n  geom_density(alpha = 0.5) +\n  facet_wrap(.~CNT)\n\n\n\n\n\n\n\n\n\n\n\n\n\nPlot a scatter graph of mean mathematics achievement (y-axis) by mean wealth (x-axis) with each country as a single point. Hint: You will first need to use group_by and then summarise to create a data frame of mean scores.\n\n\n\n\n\n\n\nTip\n\n\n\nNote that the competency tests for Vietnam in PISA are all NA at the student level. This is because many students finish compulsory schooling before 15. Hence, we add an na.omit to remove the data from Vietnam\n\n\n\n\nShow the answer\n# Create a summary data frame\n# Group by country, and then summarise the mean meath and wealth scores\n\nWealthdata &lt;- PISA_2022 %&gt;%\n  select(CNT, HOMEPOS, PV1MATH) %&gt;%\n  filter(CNT!=\"Vietnam\")%&gt;%  # To cut Vietnam due to lack of data\n  group_by(CNT) %&gt;%\n  summarise(MeanWealth=mean(HOMEPOS, na.rm = TRUE),\n            MeanMath=mean(PV1MATH, na.rm = TRUE))\n\n# Use ggplot to create a scatter graph\n\nggplot(data = Wealthdata,\n       aes(x = MeanWealth, y = MeanMath)) +\n  geom_point(alpha = 0.5, colour=\"red\") +\n  xlab(\"Home Possessions (Wealth proxy)\") +\n  ylab(\"Mathematics score\")\n\n\n\n\n\n\n\n\n\n\nIn the previous scatter of mathematics vs wealth scores, highlight outlier countries (any score of over 500) in a different colour. Hint, mutate the data frame to include a label column (by the condition of the maths score being over 550). Then set the colour in ggplot by theis label column.\n\n\n\nShow the answer\n# Create a summary data frame\n# Group by country, and then summarise the mean math and wealth scores\n\nWealthdata &lt;- PISA_2022 %&gt;%\n  select(CNT, HOMEPOS, PV1MATH) %&gt;%\n  group_by(CNT) %&gt;%\n  filter(CNT!=\"Vietnam\")%&gt;%\n  summarise(MeanWealth = mean(HOMEPOS, na.rm = TRUE),\n            MeanMath = mean(PV1MATH, na.rm = TRUE)) %&gt;%\n  mutate(label=ifelse(MeanMath &gt; 500, \"Red\", \"Blue\")) # mutate to add a label\n# the column label is \"Red\" if MeanMath &gt; 500 and \"Blue\" otherwise\n\n# Use ggplot to create a scatter graph\n\nggplot(data = Wealthdata,\n       aes(x = MeanWealth, y = MeanMath, colour = label)) +\n  geom_point() +\n  xlab(\"Wealth\") +\n  ylab(\"Mathematics score\")\n\n\n\n\n\n\n\n\n\n\nAdd the country names as a label to the outliers. Hint: add an additional column labelname to which the country name as.charachter(CNT) is added if the MeanMath score is over 500. Hint: you can use geom_label_repel to add the labels. You can set: (aes(label = labelname), colour = \"black\", check_overlap = TRUE) to give the source of the lables (labelname) the colour and to force the lables not to overlap.\n\n\n\nShow the answer\n# Mutate to give a new column labelname, set to the country name (CNT) if Meanmath is over 500, or NA if not.\nWealthdata &lt;- PISA_2022 %&gt;%\n  select(CNT, HOMEPOS, PV1MATH) %&gt;%\n  group_by(CNT) %&gt;%\n  filter(CNT!=\"Vietnam\")%&gt;%\n  summarise(MeanWealth = mean(HOMEPOS, na.rm = TRUE),\n            MeanMath = mean(PV1MATH, na.rm = TRUE)) %&gt;%\n  mutate(label = ifelse(MeanMath&gt;500, \"Red\", \"Blue\")) %&gt;%\n  mutate(labelname = ifelse(MeanMath&gt;500, as.character(CNT), NA))\n  \n# Use geom_label_repel to add the labelname column to the graph\nggplot(data = Wealthdata,\n       aes(x = MeanWealth, y = MeanMath, colour = label)) +\n  geom_point() +\n  geom_label_repel(aes(label = labelname), \n            colour = \"black\", \n            check_overlap = TRUE) +\n  xlab(\"Wealth\") +\n  ylab(\"Mathematics score\") \n\n\n\n\n\n\n\n\n\n\n\n\n\nExamine Likert responses by country using facet plot.\nFor ST125Q01NA - How old were you when you started early childhood education? Plot responses, first, for the whole data set, then facet plot for the UK, Germany, Belgium, Austria, France, Poland, Estonia, Finland and Italy.\n• What international differences can you note?\n\n\n\nShow the answer\n# Create a data frame of childhood education data for the whole data frame \nChildhoodEd&lt;-PISA_2022 %&gt;%\n  select(CNT, ST125Q01NA) %&gt;%\n  group_by(CNT)\n\n# Plot a bar graph of responses  \n\nggplot(data = ChildhoodEd,\n       aes(x = ST125Q01NA, fill = ST125Q01NA)) +\n  geom_bar() +\n  xlab(\"How old were you when you started early childhood education?\") +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))\n\n\n\n\n\n\n\n\n\nThen use faceting to split the plots by country\n\n\nShow the answer\n# Repeat filtering for UK, Germany, Belgium, Austria, France, Poland, Estonia, Finland and Italy\n\nChildhoodEd &lt;- PISA_2022 %&gt;%\n  select(CNT, ST125Q01NA) %&gt;%\n  filter(CNT == \"United Kingdom\"|CNT == \"Germany\" | CNT == \"Belgium\"\n         | CNT == \"Austria\"| CNT == \"France\" | CNT == \"Poland\"\n         | CNT == \"Estonia\" | CNT==\"Finland\"| CNT==\"Italy\")\n\n# Plot the data and facet wrap by country\n\nggplot(data = ChildhoodEd,\n       aes(x = ST125Q01NA, fill = CNT))+\n  geom_bar()+\n  xlab(\"How old were you when you started early childhood education?\") +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +\n  facet_wrap(. ~ CNT)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCategorising Variables\nSplit the HOMEPOS variable for the UK and Germany into the following groups:\n\n\n\nHOMEPOS\nName of category\n\n\n\n\n&gt;1\nVery High\n\n\n0&gt;HOMEPOS&lt;1\nHigh\n\n\n0&lt;\nLow\n\n\n\nPlot bar graphs of participants in these categories for both countries.\n• What differences can you observe between the countries?\nHint: You can use mutate with case_when to do the categorisation. For example in combination with teh mutate to create the new column maths_scores_category, we use case_when(PV1MATH &lt; 400 ~ \"Low\" to set the maths_scores_category to Low when PV1MATH is below 400. Then maths_scores_category becomes High if the score is between 400 and 500 (note the use of & and the repeat of PV1MATH: PV1MATH &gt;= 400 & PV1MATH &gt; 500. Here &lt;= means less than or equal to).\n\n\n\nShow the answer\n# Create a data frame for the UK and Germany\n# Mutate the wealth_cat (wealth category) column by the boundaries of wealth categories\nWealth &lt;- PISA_2022 %&gt;%\n  select(CNT, HOMEPOS) %&gt;%\n  filter(CNT == \"United Kingdom\" | CNT == \"Germany\") %&gt;%\n  mutate(wealth_cat = case_when(HOMEPOS &lt; 0 ~ \"Low\",\n                                HOMEPOS &gt;= 0 & HOMEPOS &lt; 1 ~ \"High\",\n                                HOMEPOS &gt;= 1 ~ \"Very High\",\n                                .default = NA)) %&gt;%\n  group_by(CNT) %&gt;%\n  droplevels()\n\n# You can set the factors to a logical order for plotting\n# The default is alphabetical which gives High, Low, Very High which \n# doesn't make sense\n\nWealth$wealth_cat &lt;- factor(Wealth$wealth_cat, levels = c(\"Low\", \"High\", \"Very High\"))\n\n# Plot the data\nggplot(data = Wealth, \n       aes(x = wealth_cat, fill = wealth_cat))+\n  geom_bar()+\n  facet_wrap(.~CNT)+\n  xlab(\"Wealth grouping\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nPlot scatter plots of science versus mathematics achievement in United Kingdom, Qatar and Brazil. What differences can you see between the countries?\n\n\n\nShow the answer\n# Create a data frame of science and mathematics scores, across the countries Including gender)\n\nSciMaths &lt;- PISA_2022 %&gt;%\n  select(CNT, PV1MATH, PV1SCIE, ST004D01T) %&gt;%\n  filter(CNT == \"Colombia\" | CNT == \"New Zealand\" | CNT == \"Qatar\"|\n           CNT == \"Israel\") %&gt;%\n  droplevels()\n\n# Scatter plot the data, faceting by country\n\nggplot(data = SciMaths, \n       aes(x = PV1MATH, y = PV1SCIE, colour = ST004D01T))+\n  geom_point(size = 0.1, alpha = 0.5)+\n  facet_wrap(.~CNT)\n\n\n\n\n\n\n\n\n\nShow the answer\n# Low achieving (filter for scores less than 400)\n\nSciMaths &lt;- PISA_2022 %&gt;%\n  select(CNT, PV1MATH, PV1SCIE, ST004D01T) %&gt;%\n  filter(CNT == \"Colombia\" | CNT == \"New Zealand\" | CNT == \"Qatar\"|\n           CNT == \"Israel\") %&gt;%\n  filter(PV1MATH &lt; 400)%&gt;%\n  filter(PV1SCIE &lt; 400)%&gt;%\n  droplevels()\n\nggplot(data = SciMaths, \n       aes(x = PV1MATH, y = PV1SCIE, colour = ST004D01T))+\n  geom_point(size = 0.1, alpha = 0.5)+\n  facet_wrap(.~CNT)",
    "crumbs": [
      "04 Introduction to PISA"
    ]
  },
  {
    "objectID": "chapters/04-Introduction_to_PISA.html#pre-session-tasks",
    "href": "chapters/04-Introduction_to_PISA.html#pre-session-tasks",
    "title": "04 Introduction to PISA",
    "section": "",
    "text": "Please read section 1 (“What is PISA?”) of the PISA 2022 Assessment and Analytical Framework: PISA Assessment Framework\n\n\n\nRemember to load the PISA 2022 data set\n\nlibrary(arrow)\nlibrary(tidyverse)\n\nPISA_2022 &lt;- read_parquet(r\"[&lt;folder&gt;PISA_2022_student_subset.parquet]\")",
    "crumbs": [
      "04 Introduction to PISA"
    ]
  },
  {
    "objectID": "chapters/04-Introduction_to_PISA.html#the-pisa-assessments",
    "href": "chapters/04-Introduction_to_PISA.html#the-pisa-assessments",
    "title": "04 Introduction to PISA",
    "section": "",
    "text": "The first International Large-Scale Assessment (ILSA) comparing the learning outcomes of school students between countries was attempted in the 1960s. However, ILSAs only became established and regular in the late 1990s and 2000s.\nThe Organisation for Economic Co-operation and Development’s (OECD) Programme for International Student Assessment (PISA) has tested 15-year-old students in a range of “literacies” or “competencies” every three years since 2000. There is a rotating focus on reading, mathematics and science, with PISA 2021 focusing on mathematics but delayed by the global pandemic until 2022 and the results only published in December 2023. Until then, PISA 2018, with a focus on reading, was the most recently available cycle and PISA 2015 remains the most recent cycle focusing on science.\nIn addition to reading, mathematics and science, PISA has tested students on a range of “novel” competencies including problem-solving, global competence, financial literacy, and creative thinking. In addition to these tests, PISA also administers questionnaires to students, teachers and parents to identify “factors” which explain test score differences within and between countries.\nSince 2000, more than 90 “countries and economies” and around 3,000,000 students have participated in PISA. The growth in the number of countries participating in each cycle of PISA is reflected in the growth in the number of students taking the PISA tests and responding to the PISA questionnaires, as shown in Table 1.\nTable 1: Number of students participating in PISA by year\n\n\n\nYear\nNumber completing assessment\n\n\n\n\n2000\n265,000\n\n\n2003\n275,000\n\n\n2006\n400,000\n\n\n2009\n470,000\n\n\n2012\n510,000\n\n\n2015\n540,000\n\n\n2018\n600,000\n\n\n2022\n690,000\n\n\n\nThere is a degree of inherent error in all educational and psychological assessments - and indeed in all social or physical measurement. ILSAs such as PISA may be more prone to error because their comparisons across large and diverse populations make them particularly complex. However, it is particularly important to minimise the error in ILSAs because they influence education policy and practice across a large number of education systems, impacting a vast population of students beyond those sampled for the assessments.\nAccording to the OECD (2019), three sources of error are worth considering. First, sampling error, uncertainty in the degree to which results from the sample generalise to the wider population - in 2018, the OECD average sampling error was 0.4 of a PISA point score (the value was not reported for 2022). Second, measurement error, uncertainty in the extent to which test items measure proficiency. In 2018, the measurement error was around 0.8 of a point in mathematics and science and 0.5 of a score point in reading (the measurement error was not reported for 2022). Third, the link error is the uncertainty in comparison between scores in different years. For comparisons of science scores between 2018 and 2015, the link error is 1.5 points. For 2018-2022, the link errors are reading (1.47), mathematics (2.24) and science (1.61) (OECD 2022, 293)\nPISA uses a probabilistic, stratified clustered survey design (Jerrim et al. 2017). However, sampling issues including sample representativeness, non-response rates and population coverage have been identified (Zieger et al. 2022; Rutkowski and Rutkowski 2016; Gillis, Polesel, and Wu 2016; Hopmann, Brinek, and Retzl 2007). Furthermore, Anders et al. (2021) and Jerrim (2021) have shown that assumptions for imputing values (imputing means estimating any missing values based on existing data - for example by adding a mean or mode score for a missing test) for non-participating students used to construct the sample may have significant impacts on achievement scores.\nSince PISA 2015, the majority of participating countries have switched from paper-based assessment to computer-based assessment (Jerrim 2016). A randomised controlled trial conducted by the OECD prior to the switch indicated a difference in score between the two modes of delivery. The OECD introduced an adjustment to compensate for this difference, but it is not entirely removed by the adjustment Jerrim et al. (2018), with implications for any time series comparisons between PISA cycles. Nonetheless, Jerrim (2016) notes that “in terms of cross-country rankings, there remains a high degree of consistency… the vast majority of countries are simply ‘shifted’ by a uniform amount” (pp. 508-509).\nIn summary, comparisons within and between countries and comparisons over time using ILSAs need careful interpretations that bear in mind the specific design of each ILSA. In practice, this means considering a range of potential explanations for score differences. Does a difference in science ranking between two countries simply reflect sampling error? Does the same parental occupation or home possessions amount to the same economic, social and cultural status in different countries (e.g. the social status of a parent as a teacher or the economic status of the number of cars a family owns)? Does a difference in mathematical self-efficacy (i.e. student self-confidence in mathematics) between the USA and Japan reflect sociocultural differences in self-enhancement and modesty, respectively? How do score differences between boys and girls indicate gender inequalities in education that reflect wider society?\n\n\n\n\n\n\nTip\n\n\n\nFor useful critique and discussion of the construction of the measure of socio-economic status in PISA data see: Avvisati’s (2020) paper.",
    "crumbs": [
      "04 Introduction to PISA"
    ]
  },
  {
    "objectID": "chapters/04-Introduction_to_PISA.html#a-reminder-about-summarising-data-graphing-and-categorising",
    "href": "chapters/04-Introduction_to_PISA.html#a-reminder-about-summarising-data-graphing-and-categorising",
    "title": "04 Introduction to PISA",
    "section": "",
    "text": "Recall you can use group_by and summarise to group individual student measures and find means and standard deviations for countries. For example, to find the mean wealth scores for the countries, and rank in descending order, we first select the variables of interest CNT and HOMEPOS (home possessions, a proxy for wealth), then group_by CNT and summarise to get the mean. As there are some NA values, we need to include na.rm=TRUE to tell summarise to ignore the missing values. Finally, we arrange in descending order by the new variable we create meanwealth. We can do the same and add a calculation to get the standard deviation.\n\n# Create a data frame of PISA 2022 data of country mean wealth\n\nPISA2022WealthRank &lt;- PISA_2022 %&gt;%\n2  select(CNT, HOMEPOS) %&gt;%\n3  group_by(CNT) %&gt;%\n4  summarise(meanwealth = mean(HOMEPOS, na.rm = TRUE)) %&gt;%\n5  arrange(desc(meanwealth))\n\nPISA2022WealthRank\n\n# With standard deviations\n\nPISA2022WealthRank &lt;- PISA_2022 %&gt;%\n  select(CNT, HOMEPOS) %&gt;% \n  group_by(CNT) %&gt;% \n  summarise(meanwealth = mean(HOMEPOS, na.rm = TRUE),  \n            sdwealth=sd(HOMEPOS, na.rm = TRUE)) %&gt;%\n  arrange(desc(meanwealth)) \n\nPISA2022WealthRank\n\n\n2\n\nline 2 - select the variables of interest\n\n3\n\nline 3 - treat the data as grouped by country (group_by(CNT))\n\n4\n\nline 4 - summarise to calculate the mean score of HOMEPOS in a new column meanwealth, setting na.rm=TRUE to ignore NA values\n\n5\n\nline 5 - arrange in descending order by meanwealth\n\n\n\n\n# A tibble: 80 × 2\n   CNT         meanwealth\n   &lt;fct&gt;            &lt;dbl&gt;\n 1 Norway           0.547\n 2 Australia        0.483\n 3 Korea            0.371\n 4 New Zealand      0.367\n 5 Canada           0.348\n 6 Iceland          0.346\n 7 Sweden           0.327\n 8 Ireland          0.318\n 9 Malta            0.308\n10 Austria          0.280\n# ℹ 70 more rows\n# A tibble: 80 × 3\n   CNT         meanwealth sdwealth\n   &lt;fct&gt;            &lt;dbl&gt;    &lt;dbl&gt;\n 1 Norway           0.547    0.970\n 2 Australia        0.483    0.861\n 3 Korea            0.371    1.01 \n 4 New Zealand      0.367    0.862\n 5 Canada           0.348    0.867\n 6 Iceland          0.346    0.805\n 7 Sweden           0.327    0.878\n 8 Ireland          0.318    0.818\n 9 Malta            0.308    0.857\n10 Austria          0.280    0.938\n# ℹ 70 more rows\n\n\n\n\n\nRecall you can use geom_bar to plot a bar graph. For example, if we wanted to plot the PISA2022WealthRank data frame we just created, we pass the data to ggplot. Recall that if you are passing geom_bar the exact values you want to plot, rather than making it count (for example, by including the original dataset with all student entries), you need to specify geom_bar(stat='identity')\nI have added +theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) which rotates the text on the x-axis.\n\n# Plot a bar graph of wealth by country\n\n1ggplot(PISA2022WealthRank, aes(x = CNT, y = meanwealth)) +\n2  geom_bar(stat = 'identity') +\n3  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))\n\n\n1\n\nline 1 - pass the PISA2022WealthRank to ggplot and set the x and y variables\n\n2\n\nline 2 - as the data are already summarised, we don’t want geom_bar to count items, but tell it to just plot the data as it is\n\n3\n\nline 3 - rotate the x-axis text\n\n\n\n\n\n\n\n\n\n\n\nWe can improve this plot by reordering the x-axis to rank the countries - we switch x=CNT to x=reorder(CNT, -meanwealth) that is we reorder the x axis based on descending (indicated by the minus sign -meanwealth) meanwealth.\n\n# Plot the wealth data frame as a bar graph, reordering the x axis by wealth\n\n1ggplot(PISA2022WealthRank, aes(x=reorder(CNT, -meanwealth), y = meanwealth)) +\n  geom_bar(stat='identity') +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))       \n\n\n1\n\nline 1 - rather than simply specifying the x axis (e.g. x=CNT) to change the order of the x-axis by the meanwealth score we can use x=reorder(CNT, -meanwealth). Note the - before meanwealth sets the order is descending.\n\n\n\n\n\n\n\n\n\n\n\nIf you like, you can add colour, tidy up the axis labels, and give a title:\n\n# Plot the wealth data frame as a bar graph, reordering the x axis by wealth\n\nggplot(PISA2022WealthRank, aes(x = reorder(CNT, -meanwealth), \n                               y = meanwealth)) +\n3  geom_bar(stat='identity', fill = \"skyblue\") +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +\n5  ggtitle(\"Countries ranked by HOMEPOS\") +\n6  xlab(\"Country\") +\n  ylab(\"Mean HOMEPOS\")\n\n\n3\n\nline 3 - set the bar fill colour to sky blue (fill = \"skyblue\")\n\n5\n\nline 6 - set the x-axis title\n\n6\n\nline 7 - set the y-axis title\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTo plot a scatter plot, recall we use geom_point. For example, to plot reading scores against mathematics scores in the UK we: a) create a data set of reading and science scores after filtering for UK; b) pass the data to ggplot; c) use aes to specify the x and y variables and d) plot with geom_point().\n\n# Create a data.frame of the UK's science and reading scores\n\nUKplot &lt;- PISA_2022 %&gt;%\n  select(CNT, PV1READ, PV1SCIE) %&gt;%\n  filter(CNT == \"United Kingdom\")\n\n# Plot the data on a scatter graph using geom_point\n\nggplot(UKplot, aes(x = PV1READ, y = PV1SCIE)) +\n  geom_point()\n\n\n\n\n\n\n\n\nThat graph is quite dense, so we can use the alpha function to make the points slightly transparent, size to make them smaller, and set their colour. I will also tidy up the axis names and add a line (note that in: geom_smooth(method = \"lm\", colour = \"black\") method = \"lm\" sets the line to a straight (i.e., linear model, lm) line).\n\n# Create a data.frame of the UK's science and reading scores\n\nUKplot &lt;- PISA_2022 %&gt;%\n  select(CNT, PV1READ, PV1SCIE) %&gt;%\n  filter(CNT == \"United Kingdom\")\n\n# Plot the data on a scatter graph using geom_point\n\n4ggplot(UKplot, aes(x = PV1READ, y = PV1SCIE)) +\n5  geom_point(alpha = 0.6, size = 0.1, colour = \"red\") +\n6  xlab(\"Reading score\") +\n7  ylab(\"Science score\") +\n8  geom_smooth(method = \"lm\", colour = \"black\")\n\n\n4\n\nline 4 - set the data to plot and set which variable goes on the x and y axis\n\n5\n\nline 5 - set the point size (size=0.1), colour (colour = \"red\") and opacity (alpha = 0.6)\n\n6\n\nline 6 - set the x-axis title\n\n7\n\nline 7 - set the y-axis title\n\n8\n\nline 8 - plot a straight line (method = \"lm\") and set its colour to black\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAn alternative type of plot is the density plot, which is a kind of continuous histogram. The density plot can be useful for visualising the achievement scores of students. For example, the mathematics scores of girls and boys (recall the gender variable is ST004D01T) in the US. We use na.omit to omit NAs. Notice, for the plot, I use aes to set my x variable, and then specify that the plot should fill by gender (fill=ST004D01T). Finally, in geom_density(alpha=0.6) I set the alpha to 0.6 to make the fill areas partially transparent.\n\n\n\n\n\n\nTip\n\n\n\nThe y-axis on a density plot is chosen so that the total area under the graph adds up to 1\n\n\n\n# Create a data.frame of US Math data including gender\n\nUSMathplot &lt;- PISA_2022 %&gt;%\n  select(CNT, PV1MATH, ST004D01T) %&gt;%\n  filter(CNT == \"United States\") %&gt;%\n  na.omit()\n\n# PLot a density chart, seeting the fill by gender, and setting the opacity to\n# 0.6 to show both gender plots\n\nggplot(USMathplot, aes(x = PV1MATH, fill = ST004D01T)) +\n  geom_density(alpha = 0.6)\n\n\n\n\n\n\n\n\n\n\n\nA powerful feature of ggplot is being able to produce the same graph for multiple values of a variable, for example, for multiple countries. For example, we may want to produce the density graph of PV1MATH score by gender, for several countries in the data set. To do that, we produce a data set of PV1MATH scores, and gender (ST004D01T) and filter for four countries (Philippines, UK, Bulgaria and Germany). We use the same code as above to plot the graphs but add +facet_wrap(.~CNT) - facet_wrap tells ggplot to produce a multi-panel plot and .~CNT means do the same as above (the . means, as above), but vary across countries (~CNT).\n\n# Create a data.frame of the maths scores for the 4 countries\nMathplot &lt;- PISA_2022 %&gt;%\n  select(CNT, PV1MATH, ST004D01T) %&gt;%\n  filter(CNT == \"Philippines\"|CNT == \"United Kingdom\"|CNT == \"Bulgaria\" |\n           CNT == \"Germany\")\n\n# Plot the data, changing colour by gender, and faceting for the countries\n\n5ggplot(Mathplot, aes(x = PV1MATH, fill = ST004D01T)) +\n6  geom_density(alpha = 0.6) +\n7  facet_wrap(. ~ CNT)\n\n\n5\n\nline 5 - pass the data to plot Mathplot and set the x axis (no y is needed for a geom_density plot) - set that we want two series, with the colour set by gender (ST004D01T)\n\n6\n\nline 6 - set fill (alpha = 0.6) so both gender plots are visible where they overlap\n\n7\n\nline 7 - facet_wrap repeats the initial graph for some variable. In this case we specify we want the same graph as above (.) but we want to produce versions for each country (~CNT) to give facet_wrap(. ~ CNT)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA useful analytical choice is to categorise some a numerical variable into ordinal classes. For example, rather than treating HOMEPOS as a continuous scale, you might want to split into high and low wealth groups (for example, those above and below the mean value).\nTo do this, first calculate the mean mean(HOMEPOS). Then we add a new vector, which we will call wealthclass using the mutate function. We set the value of wealthclass using case_when. If HOMEPOS is more than the mean score, we set wealthclass to High, and if it is less than the mean, we set it to Low. We do that using mutate(wealthclass =  case_when(HOMEPOS &gt; mean(HOMEPOS, na.rm =TRUE) ~ \"High\", HOMEPOS &lt; mean(HOMEPOS, na.rm =TRUE) ~ \"Low\", .default = NA)). This means that in the case when HOMEPOS is more than the mean (note the na.rm =TRUE to remove missing values) the value of the new column wealthclass is set to High. When HOMEPOS is less than mean(HOMEPOS, na.rm =TRUE), weatlthclass is set to Low. The .default sets what to return if neither of those conditions are met.\nFor example, create a data frame of UK participants HOMEPOS sorted into HIGH and LOW categories.\n\n# Create a data frame of UK responses\nUKPISA2022 &lt;- PISA_2022 %&gt;%\n  select(CNT, HOMEPOS) %&gt;%\n  filter(CNT == \"United Kingdom\") %&gt;%\n4  mutate(wealthclass =  case_when(HOMEPOS &gt; mean(HOMEPOS, na.rm =TRUE) ~ \"High\",\n                                  HOMEPOS &lt; mean(HOMEPOS, na.rm =TRUE) ~ \"Low\",\n                                   .default = NA)) \nUKPISA2022\n\n\n4\n\nline 4 - mutate to create a new column wealthclass - if HOMEPOS is more than mean(HOMEPOS), set the column to “High” otherwise set it to “Low”\n\n\n\n\n# A tibble: 12,972 × 3\n   CNT            HOMEPOS wealthclass\n   &lt;fct&gt;            &lt;dbl&gt; &lt;chr&gt;      \n 1 United Kingdom  -1.09  Low        \n 2 United Kingdom  -0.418 Low        \n 3 United Kingdom   1.13  High       \n 4 United Kingdom  -0.829 Low        \n 5 United Kingdom  -0.274 Low        \n 6 United Kingdom  NA     &lt;NA&gt;       \n 7 United Kingdom  -0.606 Low        \n 8 United Kingdom  NA     &lt;NA&gt;       \n 9 United Kingdom   0.425 High       \n10 United Kingdom   0.998 High       \n# ℹ 12,962 more rows",
    "crumbs": [
      "04 Introduction to PISA"
    ]
  },
  {
    "objectID": "chapters/04-Introduction_to_PISA.html#seminar-activities",
    "href": "chapters/04-Introduction_to_PISA.html#seminar-activities",
    "title": "04 Introduction to PISA",
    "section": "",
    "text": "Discuss the design features of PISA (for example, sampling, forms of tests etc.) and the sources of error that arise from them.\nAs researchers, what issues should we bear in mind when interpreting the data? (Consider, for example, measures of wealth, gender and “competency”)\nWhat caveats should policy makers bear in mind when making high stakes decisions based on the PISA measures (for example, what to include to curricula, where to target funding)?\n\n\n\n\n\n\n\n\nTip\n\n\n\nNote that the PISA data collection protocol allows countries to exclude up to 5% of the relevant population (see the PISA 2018 technical report (OECD 2018), Annex A2), in particular allowing the exclusion from the data of either individual students by their disability status, or whole schools which provide specialist education (e.g. for blind students). Permitted exclusions include: “intellectual disability, i.e. a mental or emotional disability resulting in the student being so cognitively delayed that he/she could not perform in the PISA testing environment”, and “functional disability, i.e. a moderate to severe permanent physical disability resulting in the student being unable to perform in the PISA testing environment” along with other exclusions.\n\n\n\n\n\n\nCreate a ranked list of countries by their mean science scores (PV1SCIE). What are the top five countries for science? Do the same for wealth (HOMEPOS). What patterns do you notice? Why might a researcher be critical of such rankings [Extension: Include the standard deviation of each country (hint: use the sd function) - can you detect any patterns?]\n\n\n\n\n\n\n\nTip\n\n\n\nNote that the PISA 2022 links wealth to HOMEPOS (a self reported measure of possessions in the home). You might want to consider the implications of that definition for interpreting the data\n\n\n\n\nShow the answer\n# Create a ranked data data frame for science\n\nPISA2022SciRank &lt;- PISA_2022 %&gt;%\n  select(CNT, PV1SCIE) %&gt;% # Select variables of interest\n  group_by(CNT) %&gt;% # group by country\n  summarise(meansci = mean(PV1SCIE)) %&gt;% \n     # summarise  country data to find the mean Sci score\n  arrange(desc(meansci)) # arrange in descending order based on the meansci score\n\nprint(PISA2022SciRank)\n\n\n# A tibble: 80 × 2\n   CNT               meansci\n   &lt;fct&gt;               &lt;dbl&gt;\n 1 Singapore            561.\n 2 Japan                546.\n 3 Macao (China)        543.\n 4 Korea                531.\n 5 Estonia              527.\n 6 Chinese Taipei       527.\n 7 Hong Kong (China)    525.\n 8 Czech Republic       511.\n 9 Australia            508.\n10 Poland               505.\n# ℹ 70 more rows\n\n\nShow the answer\n# And repeat the ranking for wealth\n\nPISA2022WealthRank &lt;- PISA_2022 %&gt;%\n  select(CNT, HOMEPOS) %&gt;% # Select variables of interest\n  group_by(CNT) %&gt;% # group by country\n  summarise(meanwel = mean(HOMEPOS, na.rm=TRUE)) %&gt;% \n     # summarise  country data to find the mean Sci score\n  arrange(desc(meanwel)) # arrange in descending order based on the meansci score\n\nprint(PISA2022WealthRank)\n\n\n# A tibble: 80 × 2\n   CNT         meanwel\n   &lt;fct&gt;         &lt;dbl&gt;\n 1 Norway        0.547\n 2 Australia     0.483\n 3 Korea         0.371\n 4 New Zealand   0.367\n 5 Canada        0.348\n 6 Iceland       0.346\n 7 Sweden        0.327\n 8 Ireland       0.318\n 9 Malta         0.308\n10 Austria       0.280\n# ℹ 70 more rows\n\n\nShow the answer\n# With standard deviations\n\nPISA2022SciRank &lt;- PISA_2022 %&gt;%\n  select(CNT, PV1SCIE) %&gt;% # Select variables of interest\n  group_by(CNT) %&gt;% # group by country\n  summarise(meansci = mean(PV1SCIE), \n            sdsci = sd(PV1SCIE)) %&gt;% \n  # summarise  country data to find the mean Sci score\n  arrange(desc(meansci)) # arrange in descending order based on the meansci score\n\nprint(PISA2022SciRank)\n\n\n# A tibble: 80 × 3\n   CNT               meansci sdsci\n   &lt;fct&gt;               &lt;dbl&gt; &lt;dbl&gt;\n 1 Singapore            561.  99.6\n 2 Japan                546.  92.7\n 3 Macao (China)        543.  86.6\n 4 Korea                531. 104. \n 5 Estonia              527.  87.7\n 6 Chinese Taipei       527. 102. \n 7 Hong Kong (China)    525.  91.1\n 8 Czech Republic       511. 103. \n 9 Australia            508. 107. \n10 Poland               505.  94.2\n# ℹ 70 more rows\n\n\nShow the answer\nPISA2022WealthRank &lt;- PISA_2022%&gt;%\n  select(CNT, HOMEPOS)%&gt;% # Select variables of interest\n  group_by(CNT) %&gt;% # group by country\n  summarise(meanwel = mean(HOMEPOS, na.rm=TRUE),\n            sdwel = sd(HOMEPOS, na.rm=TRUE)) %&gt;% \n  # summarise  country data to find  mean wealth score\n  arrange(desc(meanwel)) \n  # arrange in descending order based on the meanwel score\nprint(PISA2022WealthRank)\n\n\n# A tibble: 80 × 3\n   CNT         meanwel sdwel\n   &lt;fct&gt;         &lt;dbl&gt; &lt;dbl&gt;\n 1 Norway        0.547 0.970\n 2 Australia     0.483 0.861\n 3 Korea         0.371 1.01 \n 4 New Zealand   0.367 0.862\n 5 Canada        0.348 0.867\n 6 Iceland       0.346 0.805\n 7 Sweden        0.327 0.878\n 8 Ireland       0.318 0.818\n 9 Malta         0.308 0.857\n10 Austria       0.280 0.938\n# ℹ 70 more rows\n\n\n\n\n\n\nUse a scatter plot to show the correlation between HOMEPOS and ESCS. Use a facet_wrap to show the charts for the UK, Japan, Colombia and Sweden. Discuss the different relationships between the two variables across the countries.\n\n\n\n\n\n\n\nTip\n\n\n\nNote that the PISA variable, Economic, Social and Cultural Status ESCS is based on highest parental occupation (‘HISEI’), highest parental education (‘PARED’), and home possessions (‘HOMEPOS’), including books in the home. Do consider the implications of this definition.\n\n\n\n\nShow the answer\n# Create a data frame with the ESCS, gender (ST004D01T) and HOMEPOS variables for the 4 countries \n\nWealthcompPISA&lt;-PISA_2022 %&gt;%\n  select(CNT, ESCS, HOMEPOS, ST004D01T)%&gt;%\n  filter(CNT == \"Japan\" | CNT == \"United Kingdom\" | CNT == \"Colombia\" | CNT == \"Sweden\")\n\n# Use ggplot to create a scatter graph\n# Set the x variable to ESCS and the y to HOMEPOS, set the colour to gender\n# Set point size and transparency\n# Facet wrap to produce graphs for each country\n\nggplot(WealthcompPISA, aes(x = ESCS, y = HOMEPOS, colour=ST004D01T))+\n  geom_point(size=0.1, alpha=0.5)+\n  facet_wrap(.~CNT)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUse geom_density to plot distributions to plot the distribution of Japanese and UK mathematics scores - what patterns do you notice?\n\n\n\n\n\n\n\n\nTip\n\n\n\nTo plot a distribution, you can use geom_density to plot a distribution curve. In ggplot you specify the data, and then in aes set the x-value (the variable of interest, and set the fill to change by different groups). Within the geom_density call you can specify the alpha, the opacity of the plot.\nFor example, to plot science scores in the UK by gender, you would use the code below:\n\n# Create a data frame of UK science scores including gender\n\nUKSci&lt;-PISA_2022 %&gt;%\n  select(CNT, PV1SCIE, ST004D01T) %&gt;%\n  filter(CNT == \"United Kingdom\")\n\n# Plot the density chart, changing colour by gender, and setting the alpha (opacity) to 0.5\nggplot(data = UKSci,\n       aes(x = PV1SCIE, fill = ST004D01T)) +\n  geom_density(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\nShow the answer\n# Create a data frame of UK and Japanese mathematics scores\n\nJPUKMath&lt;-PISA_2022 %&gt;%\n  select(CNT, PV1MATH) %&gt;%\n  filter(CNT == \"United Kingdom\"|CNT == \"Japan\")\n\n# Plot the density chart, changing colour by country, and setting the alpha (opacity) to 0.5\nggplot(data = JPUKMath,\n       aes(x = PV1MATH, fill = CNT)) +\n  geom_density(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExamine gender differences: Plot the distributions of mathematics achievement in the UK by gender. What patterns can you see?\n\n\n\n\nShow the answer\nUKMathGender &lt;- PISA_2022 %&gt;%\n  select(CNT, PV1MATH, ST004D01T) %&gt;%\n  filter(CNT == \"United Kingdom\")\n\nggplot(data = UKMathGender,\n       aes(x = PV1MATH, fill = ST004D01T)) +\n  geom_density(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\n\nPlot density graphs of gender differences in mathematics scores in the UK, Spain, Japan, Korea and Finland. Hint use facet_wrap(.~CNT)\n\n\n\nShow the answer\n# Create a data frame of mathematics scores, gender and country\n# Filter by the five countries of interest\n\nMathGender &lt;- PISA_2022 %&gt;%\n  select(CNT, PV1MATH, ST004D01T) %&gt;%\n  filter(CNT == \"United Kingdom\"|CNT == \"Spain\"|CNT == \"Japan\"\n         | CNT==\"Korea\"|CNT == \"Finland\")\n\n# Plot a density graph of mathematics scores, splitting into groups, with coloured fills by gender. Set transparency to 0.5 to show overlap \n\nggplot(data = MathGender,\n       aes(x = PV1MATH, fill = ST004D01T)) +\n  geom_density(alpha = 0.5) +\n  facet_wrap(.~CNT)\n\n\n\n\n\n\n\n\n\n\n\n\n\nPlot a scatter graph of mean mathematics achievement (y-axis) by mean wealth (x-axis) with each country as a single point. Hint: You will first need to use group_by and then summarise to create a data frame of mean scores.\n\n\n\n\n\n\n\nTip\n\n\n\nNote that the competency tests for Vietnam in PISA are all NA at the student level. This is because many students finish compulsory schooling before 15. Hence, we add an na.omit to remove the data from Vietnam\n\n\n\n\nShow the answer\n# Create a summary data frame\n# Group by country, and then summarise the mean meath and wealth scores\n\nWealthdata &lt;- PISA_2022 %&gt;%\n  select(CNT, HOMEPOS, PV1MATH) %&gt;%\n  filter(CNT!=\"Vietnam\")%&gt;%  # To cut Vietnam due to lack of data\n  group_by(CNT) %&gt;%\n  summarise(MeanWealth=mean(HOMEPOS, na.rm = TRUE),\n            MeanMath=mean(PV1MATH, na.rm = TRUE))\n\n# Use ggplot to create a scatter graph\n\nggplot(data = Wealthdata,\n       aes(x = MeanWealth, y = MeanMath)) +\n  geom_point(alpha = 0.5, colour=\"red\") +\n  xlab(\"Home Possessions (Wealth proxy)\") +\n  ylab(\"Mathematics score\")\n\n\n\n\n\n\n\n\n\n\nIn the previous scatter of mathematics vs wealth scores, highlight outlier countries (any score of over 500) in a different colour. Hint, mutate the data frame to include a label column (by the condition of the maths score being over 550). Then set the colour in ggplot by theis label column.\n\n\n\nShow the answer\n# Create a summary data frame\n# Group by country, and then summarise the mean math and wealth scores\n\nWealthdata &lt;- PISA_2022 %&gt;%\n  select(CNT, HOMEPOS, PV1MATH) %&gt;%\n  group_by(CNT) %&gt;%\n  filter(CNT!=\"Vietnam\")%&gt;%\n  summarise(MeanWealth = mean(HOMEPOS, na.rm = TRUE),\n            MeanMath = mean(PV1MATH, na.rm = TRUE)) %&gt;%\n  mutate(label=ifelse(MeanMath &gt; 500, \"Red\", \"Blue\")) # mutate to add a label\n# the column label is \"Red\" if MeanMath &gt; 500 and \"Blue\" otherwise\n\n# Use ggplot to create a scatter graph\n\nggplot(data = Wealthdata,\n       aes(x = MeanWealth, y = MeanMath, colour = label)) +\n  geom_point() +\n  xlab(\"Wealth\") +\n  ylab(\"Mathematics score\")\n\n\n\n\n\n\n\n\n\n\nAdd the country names as a label to the outliers. Hint: add an additional column labelname to which the country name as.charachter(CNT) is added if the MeanMath score is over 500. Hint: you can use geom_label_repel to add the labels. You can set: (aes(label = labelname), colour = \"black\", check_overlap = TRUE) to give the source of the lables (labelname) the colour and to force the lables not to overlap.\n\n\n\nShow the answer\n# Mutate to give a new column labelname, set to the country name (CNT) if Meanmath is over 500, or NA if not.\nWealthdata &lt;- PISA_2022 %&gt;%\n  select(CNT, HOMEPOS, PV1MATH) %&gt;%\n  group_by(CNT) %&gt;%\n  filter(CNT!=\"Vietnam\")%&gt;%\n  summarise(MeanWealth = mean(HOMEPOS, na.rm = TRUE),\n            MeanMath = mean(PV1MATH, na.rm = TRUE)) %&gt;%\n  mutate(label = ifelse(MeanMath&gt;500, \"Red\", \"Blue\")) %&gt;%\n  mutate(labelname = ifelse(MeanMath&gt;500, as.character(CNT), NA))\n  \n# Use geom_label_repel to add the labelname column to the graph\nggplot(data = Wealthdata,\n       aes(x = MeanWealth, y = MeanMath, colour = label)) +\n  geom_point() +\n  geom_label_repel(aes(label = labelname), \n            colour = \"black\", \n            check_overlap = TRUE) +\n  xlab(\"Wealth\") +\n  ylab(\"Mathematics score\") \n\n\n\n\n\n\n\n\n\n\n\n\n\nExamine Likert responses by country using facet plot.\nFor ST125Q01NA - How old were you when you started early childhood education? Plot responses, first, for the whole data set, then facet plot for the UK, Germany, Belgium, Austria, France, Poland, Estonia, Finland and Italy.\n• What international differences can you note?\n\n\n\nShow the answer\n# Create a data frame of childhood education data for the whole data frame \nChildhoodEd&lt;-PISA_2022 %&gt;%\n  select(CNT, ST125Q01NA) %&gt;%\n  group_by(CNT)\n\n# Plot a bar graph of responses  \n\nggplot(data = ChildhoodEd,\n       aes(x = ST125Q01NA, fill = ST125Q01NA)) +\n  geom_bar() +\n  xlab(\"How old were you when you started early childhood education?\") +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))\n\n\n\n\n\n\n\n\n\nThen use faceting to split the plots by country\n\n\nShow the answer\n# Repeat filtering for UK, Germany, Belgium, Austria, France, Poland, Estonia, Finland and Italy\n\nChildhoodEd &lt;- PISA_2022 %&gt;%\n  select(CNT, ST125Q01NA) %&gt;%\n  filter(CNT == \"United Kingdom\"|CNT == \"Germany\" | CNT == \"Belgium\"\n         | CNT == \"Austria\"| CNT == \"France\" | CNT == \"Poland\"\n         | CNT == \"Estonia\" | CNT==\"Finland\"| CNT==\"Italy\")\n\n# Plot the data and facet wrap by country\n\nggplot(data = ChildhoodEd,\n       aes(x = ST125Q01NA, fill = CNT))+\n  geom_bar()+\n  xlab(\"How old were you when you started early childhood education?\") +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +\n  facet_wrap(. ~ CNT)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCategorising Variables\nSplit the HOMEPOS variable for the UK and Germany into the following groups:\n\n\n\nHOMEPOS\nName of category\n\n\n\n\n&gt;1\nVery High\n\n\n0&gt;HOMEPOS&lt;1\nHigh\n\n\n0&lt;\nLow\n\n\n\nPlot bar graphs of participants in these categories for both countries.\n• What differences can you observe between the countries?\nHint: You can use mutate with case_when to do the categorisation. For example in combination with teh mutate to create the new column maths_scores_category, we use case_when(PV1MATH &lt; 400 ~ \"Low\" to set the maths_scores_category to Low when PV1MATH is below 400. Then maths_scores_category becomes High if the score is between 400 and 500 (note the use of & and the repeat of PV1MATH: PV1MATH &gt;= 400 & PV1MATH &gt; 500. Here &lt;= means less than or equal to).\n\n\n\nShow the answer\n# Create a data frame for the UK and Germany\n# Mutate the wealth_cat (wealth category) column by the boundaries of wealth categories\nWealth &lt;- PISA_2022 %&gt;%\n  select(CNT, HOMEPOS) %&gt;%\n  filter(CNT == \"United Kingdom\" | CNT == \"Germany\") %&gt;%\n  mutate(wealth_cat = case_when(HOMEPOS &lt; 0 ~ \"Low\",\n                                HOMEPOS &gt;= 0 & HOMEPOS &lt; 1 ~ \"High\",\n                                HOMEPOS &gt;= 1 ~ \"Very High\",\n                                .default = NA)) %&gt;%\n  group_by(CNT) %&gt;%\n  droplevels()\n\n# You can set the factors to a logical order for plotting\n# The default is alphabetical which gives High, Low, Very High which \n# doesn't make sense\n\nWealth$wealth_cat &lt;- factor(Wealth$wealth_cat, levels = c(\"Low\", \"High\", \"Very High\"))\n\n# Plot the data\nggplot(data = Wealth, \n       aes(x = wealth_cat, fill = wealth_cat))+\n  geom_bar()+\n  facet_wrap(.~CNT)+\n  xlab(\"Wealth grouping\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nPlot scatter plots of science versus mathematics achievement in United Kingdom, Qatar and Brazil. What differences can you see between the countries?\n\n\n\nShow the answer\n# Create a data frame of science and mathematics scores, across the countries Including gender)\n\nSciMaths &lt;- PISA_2022 %&gt;%\n  select(CNT, PV1MATH, PV1SCIE, ST004D01T) %&gt;%\n  filter(CNT == \"Colombia\" | CNT == \"New Zealand\" | CNT == \"Qatar\"|\n           CNT == \"Israel\") %&gt;%\n  droplevels()\n\n# Scatter plot the data, faceting by country\n\nggplot(data = SciMaths, \n       aes(x = PV1MATH, y = PV1SCIE, colour = ST004D01T))+\n  geom_point(size = 0.1, alpha = 0.5)+\n  facet_wrap(.~CNT)\n\n\n\n\n\n\n\n\n\nShow the answer\n# Low achieving (filter for scores less than 400)\n\nSciMaths &lt;- PISA_2022 %&gt;%\n  select(CNT, PV1MATH, PV1SCIE, ST004D01T) %&gt;%\n  filter(CNT == \"Colombia\" | CNT == \"New Zealand\" | CNT == \"Qatar\"|\n           CNT == \"Israel\") %&gt;%\n  filter(PV1MATH &lt; 400)%&gt;%\n  filter(PV1SCIE &lt; 400)%&gt;%\n  droplevels()\n\nggplot(data = SciMaths, \n       aes(x = PV1MATH, y = PV1SCIE, colour = ST004D01T))+\n  geom_point(size = 0.1, alpha = 0.5)+\n  facet_wrap(.~CNT)",
    "crumbs": [
      "04 Introduction to PISA"
    ]
  },
  {
    "objectID": "chapters/07-ChisqPISA.html",
    "href": "chapters/07-ChisqPISA.html",
    "title": "07 Hypothesis testing and Chi-square tests",
    "section": "",
    "text": "Before the session, you may find it useful to read chapter 6, the basic elements of hypothesis testing, in Geher and Hall (2014) (available here).\n\n\n\nWe will continue to use the PISA_2022 dataset, make sure it is loaded.\n\n# Load PISA data\n\nlibrary(arrow)\nlibrary(tidyverse)\n\nPISA_2022 &lt;- read_parquet(r\"[&lt;folder&gt;PISA_2022_student_subset.parquet]\")",
    "crumbs": [
      "07 Hypothesis testing and Chi-square tests"
    ]
  },
  {
    "objectID": "chapters/07-ChisqPISA.html#pre-reading",
    "href": "chapters/07-ChisqPISA.html#pre-reading",
    "title": "07 Hypothesis testing and Chi-square tests",
    "section": "",
    "text": "Before the session, you may find it useful to read chapter 6, the basic elements of hypothesis testing, in Geher and Hall (2014) (available here).",
    "crumbs": [
      "07 Hypothesis testing and Chi-square tests"
    ]
  },
  {
    "objectID": "chapters/07-ChisqPISA.html#pre-session-task---loading-the-data",
    "href": "chapters/07-ChisqPISA.html#pre-session-task---loading-the-data",
    "title": "07 Hypothesis testing and Chi-square tests",
    "section": "",
    "text": "We will continue to use the PISA_2022 dataset, make sure it is loaded.\n\n# Load PISA data\n\nlibrary(arrow)\nlibrary(tidyverse)\n\nPISA_2022 &lt;- read_parquet(r\"[&lt;folder&gt;PISA_2022_student_subset.parquet]\")",
    "crumbs": [
      "07 Hypothesis testing and Chi-square tests"
    ]
  },
  {
    "objectID": "chapters/07-ChisqPISA.html#choosing-a-hypothesis-test",
    "href": "chapters/07-ChisqPISA.html#choosing-a-hypothesis-test",
    "title": "07 Hypothesis testing and Chi-square tests",
    "section": "2.1 Choosing a Hypothesis Test",
    "text": "2.1 Choosing a Hypothesis Test\nWhen conducting a hypothesis test we need to choose the most appropriate test depending on the type of data we are working with, what we are trying to test and whether certain conditions are met or not. Here is a basic summary of what you may need to consider.\nType(s) of data:\n\nCategorical (ordinal, nominal, binary);\nQuantitative (continuous, discrete).\n\nWhat you are trying to test:\n\nRelationships between variables;\nComparison of means.\n\nDistribution of data:\n\nNormally distributed (parametric tests);\nNot normally distributed (nonparametric tests).\n\nWhen we consider each of the types of tests the conditions for the test will be stated, so it will be clear which test can be used when.",
    "crumbs": [
      "07 Hypothesis testing and Chi-square tests"
    ]
  },
  {
    "objectID": "chapters/07-ChisqPISA.html#performing-a-hypothesis-test---fisher",
    "href": "chapters/07-ChisqPISA.html#performing-a-hypothesis-test---fisher",
    "title": "07 Hypothesis testing and Chi-square tests",
    "section": "2.2 Performing a hypothesis test - Fisher",
    "text": "2.2 Performing a hypothesis test - Fisher\nFisher, one of the statisticians who moved the field of hypothesis testing forward and formalised some of the procedures used for hypothesis testing, suggested using the following steps when conducting hypothesis testing.\n\nSelect an appropriate test.\nHere, we need to consider the type(s) of data, what we are trying to test and whether the data is normally distributed or not, along with other conditions needed for the different tests.\nSet up the null and alternative hypotheses.\nThis heavily depends on which test is being used, so more guidance will be given under each of the tests.\nCalculate the theoretical probability of the null hypothesis being true.\nThis is where the test itself is used to calculate the probability of the null hypothesis being true (i.e. returning the p-value from the test).\nAssess the statistical significance of the result.\nThis is where the p-value from step 3 is compared with a predetermined threshold, such as 0.05 or 0.01 to determine if the null hypothesis is true or false.\nInterpret the statistical significance of the results.\nHere, we take the result from step 4, so deciding whether to accept the null hypothesis or reject the null hypothesis and accept the alternative hypothesis and then what this means in the context of the problem being posed.",
    "crumbs": [
      "07 Hypothesis testing and Chi-square tests"
    ]
  },
  {
    "objectID": "chapters/07-ChisqPISA.html#conditions-of-chi-square-tests",
    "href": "chapters/07-ChisqPISA.html#conditions-of-chi-square-tests",
    "title": "07 Hypothesis testing and Chi-square tests",
    "section": "3.1 Conditions of Chi-Square Tests",
    "text": "3.1 Conditions of Chi-Square Tests\nFour assumptions need to be met in order to use a chi-square test:\n\nThe data (both variables) should be categorical (for ordinal data, see the section on Kruskal Wallis tests below);\nAll observations are independent;\nCells in the contingency table (see below) are mutually exclusive;\nExpected values in each cell in the contingency table should be five or greater for more than 80% of cells.\n\nSee Section 12.5 in Navaro’s Learning Statistics with R",
    "crumbs": [
      "07 Hypothesis testing and Chi-square tests"
    ]
  },
  {
    "objectID": "chapters/07-ChisqPISA.html#types-of-chi-square-tests",
    "href": "chapters/07-ChisqPISA.html#types-of-chi-square-tests",
    "title": "07 Hypothesis testing and Chi-square tests",
    "section": "3.2 Types of Chi-Square Tests",
    "text": "3.2 Types of Chi-Square Tests\nChi-square tests can be categorised in two groups:\n\nA test of goodness of fit - this is a form of hypothesis test which determines whether a sample fits a wider population. For example, does the pattern of exam results in one school fit the national distribution?\nA test of independence - allows inference to be made about whether two categorical variables in a population are related. For example, are there differences in the uptake of careers by gender?\n\nFor more information on chi-square tests, see chapter 12, in Navaro’s Learning Statistics with R.",
    "crumbs": [
      "07 Hypothesis testing and Chi-square tests"
    ]
  },
  {
    "objectID": "chapters/07-ChisqPISA.html#creating-contingency-tables",
    "href": "chapters/07-ChisqPISA.html#creating-contingency-tables",
    "title": "07 Hypothesis testing and Chi-square tests",
    "section": "4.1 Creating contingency tables",
    "text": "4.1 Creating contingency tables\nChi-square calculations depend on contingency tables. A contingency table is a table that shows the frequency counts for two variables. We can use the xtabs function to create contingency tables in R.\nFor example, imagine we want to create a contingency table for the number of boys and girls in the UK and US in the PISA sample. First we create a subset of the PISA_2022 data.frame including country and gender, and filter for the two countries. We use the xtabs function to create the table. We pass the subset data (UKUSgender) to xtabs and indicate the columns and rows we want ~CNT + ST004D01T\n\n# Example contingency table\n\n# First create a data frame with the gender data for the UK and US \n\nUKUSgender &lt;- PISA_2022 %&gt;%\n1  select(CNT, ST004D01T) %&gt;%\n2  filter(CNT == \"United Kingdom\" | CNT == \"United States\") %&gt;%\n3  droplevels()\n\n# The use xtabs to create a contingency table by ('~') country (CNT) and gender (ST004D01T)\n\n4ContTable &lt;- xtabs(data = UKUSgender, ~ CNT + ST004D01T)\nContTable\n\n\n1\n\nselect the needed columns gender (ST004D01T) and country (CNT)\n\n2\n\nfilter for countries of interest, the UK and the US\n\n3\n\ndroplevels() to avoid empty country levels (those not selecting) cluttering the table at 0 counts\n\n4\n\nuse xtabs to create a contingency table comparing CNT with ST004D01T\n\n\n\n\n                ST004D01T\nCNT              Female Male\n  United Kingdom   6397 6575\n  United States    2235 2312",
    "crumbs": [
      "07 Hypothesis testing and Chi-square tests"
    ]
  },
  {
    "objectID": "chapters/07-ChisqPISA.html#an-example-does-the-distribution-of-male-and-female-students-in-the-uk-fit-the-expected-pattern-5050",
    "href": "chapters/07-ChisqPISA.html#an-example-does-the-distribution-of-male-and-female-students-in-the-uk-fit-the-expected-pattern-5050",
    "title": "07 Hypothesis testing and Chi-square tests",
    "section": "5.1 An example: Does the distribution of male and female students in the UK fit the expected pattern (50:50)?",
    "text": "5.1 An example: Does the distribution of male and female students in the UK fit the expected pattern (50:50)?\nTo perform the goodness of fit test, we make a subset dataframe of the UK data including the ST004D01T (gender variable).\n\n# Perform a chi-square goodness of fit test on categorical data related to gender in the UK\n\n# Create a data frame of UK genders\n\nUKPISAgender&lt;-PISA_2022 %&gt;%\n1  select(CNT, ST004D01T) %&gt;%\n2  filter(CNT == \"United Kingdom\") %&gt;%\n3  droplevels()\n\n# Use cross tabs to create a contingency table of the dataframe, by CNT and ST004D01T (gender)\n\n4GenderContTable&lt;-xtabs(data = UKPISAgender, ~CNT + ST004D01T)\n\n# Perfom the chisq test, comparing against the expected probabilities of 50:50 (e.g. 1/2 to 1/2)\n\n5chisq.test(GenderContTable, p=c(1/2, 1/2))\n\n\n1\n\nselect the needed columns gender (ST004D01T) and country (CNT)\n\n2\n\nfilter for country of interest, the UK\n\n3\n\ndroplevels() to avoid empty country levels (those not selecting) cluttering the table at 0 counts\n\n4\n\nuse xtabs to create a contingency table comparing CNT with ST004D01T\n\n5\n\nperform the chi-sq test of goodness of fit, comparing against an expected probability of 50:50\n\n\n\n\n\n    Chi-squared test for given probabilities\n\ndata:  GenderContTable\nX-squared = 2.4425, df = 1, p-value = 0.1181\n\n\nThe outcome of the chi squared test returns a p-value = 0.1181. This is greater than 0.05, suggesting we accept the null hypothesis, and the numbers of boys and girls in the UK sample matches a 50:50 distribution.",
    "crumbs": [
      "07 Hypothesis testing and Chi-square tests"
    ]
  },
  {
    "objectID": "chapters/07-ChisqPISA.html#an-example-gender-distribution-in-the-pisa-sample",
    "href": "chapters/07-ChisqPISA.html#an-example-gender-distribution-in-the-pisa-sample",
    "title": "07 Hypothesis testing and Chi-square tests",
    "section": "5.2 An example: Gender distribution in the PISA sample",
    "text": "5.2 An example: Gender distribution in the PISA sample\n\n\nShould we accept or reject the hypothesis that the populations of boys and girls in the United States, Japan and Korea are 50:50?\n\n\n\nShow the code\n# Perform a chi-square goodness of fit test on categorical data related \n# to gender in the US, Japan and China\n\nUSPISAgender&lt;-PISA_2022 %&gt;%\n1  select(CNT, ST004D01T) %&gt;%\n2  filter(CNT == \"United States\") %&gt;%\n3  droplevels()\n\n# produce the contingency table by country and gender\n\n4GenderContTable&lt;-xtabs(data = USPISAgender, ~ CNT + ST004D01T)\n\n# Perform the chisq test, comparing against the expected probabilities of 50:50 (e.g. 1/2 to 1/2)\n\n5chisq.test(GenderContTable, p = c(1/2, 1/2))\n\n# In the US,  p= 0.2535, accept null hypothesis of equality, population of M:F does not differ from 50:50\n\nJPNPISAgender&lt;-PISA_2022 %&gt;%\n  select(CNT, ST004D01T) %&gt;% # Select gender and country variables\n  filter(CNT == \"Japan\") %&gt;% # Filter for the Japan\n  droplevels() # To prevent the levels for other countries confusing the table\n\n# produce the contingency table by country and gender\n\nGenderContTable&lt;-xtabs(data = JPNPISAgender,~ CNT + ST004D01T)\n\n# Perfom the chisq test, comparing against the expected probabilities of 50:50 (e.g. 1/2 to 1/2)\n\nchisq.test(GenderContTable, p = c(1/2, 1/2))\n\n# In Japan, p= 0.5271, accept null hypothesis of equality, population of M:F does not differ from 50:50\n\nKoreaPISAgender&lt;-PISA_2022 %&gt;%\n  select(CNT, ST004D01T) %&gt;% # Select gender and country variables\n  filter(CNT == \"Korea\") %&gt;% # Filter for Korea\n  droplevels() # To prevent the levels for other countries confusing the table\n\n\n# produce the contingency table by country and gender\n\nGenderFreqTable&lt;-xtabs(data=KoreaPISAgender, ~CNT + ST004D01T)\n\n# Perform the chisq test, comparing against the expected probabilities of 50:50 (e.g. 1/2 to 1/2)\n\nchisq.test(GenderFreqTable, p = c(1/2, 1/2))\n# In Korea, p=0.0147, reject null hypothesis of equality, population distribution differs from 50:50\n\n\n\n1\n\nselect the needed columns gender (ST004D01T) and country (CNT)\n\n2\n\nfilter for country of interest, the US\n\n3\n\ndroplevels() to avoid empty country levels (those not selecting) cluttering the table at 0 counts\n\n4\n\nuse xtabs to create a contingency table comparing CNT with ST004D01T\n\n5\n\nperform the chi-sq test of goodness of fit, comparing against an expected probability of 50:50\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nR uses standard form: an output of p= 3.724e-06, represents, p=3.724x10-6, or p = 0.0000003724.",
    "crumbs": [
      "07 Hypothesis testing and Chi-square tests"
    ]
  },
  {
    "objectID": "chapters/07-ChisqPISA.html#plotting-the-chi-square-relationships",
    "href": "chapters/07-ChisqPISA.html#plotting-the-chi-square-relationships",
    "title": "07 Hypothesis testing and Chi-square tests",
    "section": "6.1 Plotting the chi-square relationships",
    "text": "6.1 Plotting the chi-square relationships\nThe numbers in the contingency table are hard to interpret - it is challenging to see how far out the numbers for each row are from each other. Alternatively, we can visualise the data from the contingency table by building a mosaic plot, a form of stacked bar chart. Mosaic plots can be a useful visulations before running a chi-squared test.\nTo create a mosaic plot, you are going to need to install and load the ggmosaic package. See ?@sec-load-run-pckges for more details on how to do this.\nImagine we want to plot the ‘accomplishment’ data (WB178Q01HA) from the previous section for the Netherlands, Mexico and New Zealand.\nTo create the mosaic plot we use ggplot, as we used for previous graphs. As before, we first pass the data (in this case Accomp) to ggplot. Then, to create the graph, geom_mosaic is used. geom_mosaic does not have a direct mapping of input to x and y variable so we need to pass it what we want plotted on the y-axis (WB178Q01HA) and x-axis (CNT) within the product function (product(WB178Q01HA, CNT)). We can also specify how we want the rectangles to be coloured (in our case, by CNT).\n\n # install.packages(\"ggmosaic\")\nlibrary(ggmosaic)\n\n# Create a data frame of accomplishment data for the 3 countries\nAccomp&lt;-PISA_2022 %&gt;%\n  select(WB178Q01HA, CNT) %&gt;%\n  filter(CNT == \"Netherlands\" | CNT == \"Mexico\"| CNT == \"New Zealand\") %&gt;%\n  droplevels()\n\n# plot results\n# Note that with geom_mosaic you pass the x and y variables using: aes(x = product(WB178Q01HA, CNT))\n\n1ggplot(data = Accomp) +\n2  geom_mosaic(aes(x = product(WB178Q01HA, CNT), fill = CNT)) +\n3  xlab(\"Country\") +\n4  ylab(\"Did you accomplish something yesterday?\")\n\n\n1\n\nset the data to be plotted (data = Accomp)\n\n2\n\nin geom_mosaic the x and y variables are set using x= product (x, y). Here we set x = product(WB178Q01HA, CNT) and set the fill by country (fill = CNT)\n\n3\n\nset the x-axis label\n\n4\n\nset the y-axis label\n\n\n\n\n\n\n\n\n\n\n\nNote that in the mosaic plot the width of the bars represents the number of students in the sample for each country.",
    "crumbs": [
      "07 Hypothesis testing and Chi-square tests"
    ]
  },
  {
    "objectID": "chapters/07-ChisqPISA.html#running-chi-square-tests-of-independence",
    "href": "chapters/07-ChisqPISA.html#running-chi-square-tests-of-independence",
    "title": "07 Hypothesis testing and Chi-square tests",
    "section": "6.2 Running Chi-square tests of independence",
    "text": "6.2 Running Chi-square tests of independence\nThe mosaic plot suggests that students’ feeling of accomplishment is different in Mexico, the Netherlands and New Zealand. Simply looking at the data does not tell us if the distributions are different - a Chi-square tests of independence can report the significance level, which can help us make a judgement.\nThe null hypothesis in a test of independence is that the categorical variables are not related. So in the case of comparing Mexico and the Netherlands the null hypothesis is: ‘There is no relationship between the country (Mexico or the Netherlands) in students’ feeling of accomplishment’.\n\n# Produce tables of counts of having accomplished something for Mexico and new Zealand\n\nAccompNZM &lt;- PISA_2022 %&gt;%\n1  select(WB178Q01HA, CNT) %&gt;%\n2  filter(CNT == \"New Zealand\"| CNT == \"Mexico\") %&gt;%\n3  droplevels()\n\n# Produce the contingency table for the NZ and Mexico\n\n4AccompNZMFreqTable&lt;-xtabs(~ WB178Q01HA + CNT, data = AccompNZM)\n\n# Print the table\nprint(AccompNZMFreqTable)\n\n# Perform Chisq test between NZ and Mexico\n\n5chisq.test(AccompNZMFreqTable)\n\n# p-value &lt; 0.5938, more than 0.05, so there are no statistically significant differences in feelings of accomplishment between NZ and Mexico, the null hypothesis is accepted\n\n\n1\n\nselect the accomplishment (WB178Q01HA) and country variable\n\n2\n\nfilter for New Zealand and Mexico\n\n3\n\ndrop levels to keep the table clean\n\n4\n\nuse xtabs to create the contingency table for accomplishment (WB178Q01HA) by country\n\n5\n\nperform the chisq.test\n\n\n\n\n          CNT\nWB178Q01HA Mexico New Zealand\n       Yes   4213        2690\n       No    1818        1190\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  AccompNZMFreqTable\nX-squared = 0.28447, df = 1, p-value = 0.5938\n\n\nThe test here returns a p-value=0.5938. This is more than 0.05 so the null hypothesis can be accepted. The null hypothesis is that there is no difference between feelings of accomplishment in New Zealand and Mexico.",
    "crumbs": [
      "07 Hypothesis testing and Chi-square tests"
    ]
  },
  {
    "objectID": "chapters/07-ChisqPISA.html#likert-scale-data",
    "href": "chapters/07-ChisqPISA.html#likert-scale-data",
    "title": "07 Hypothesis testing and Chi-square tests",
    "section": "7.1 Likert Scale Data",
    "text": "7.1 Likert Scale Data\nOne particular form of data that regularly comes up in PISA is data with responses on a Likert scale. Often, these responses are closed, with ‘strongly agree’, ‘agree’, ‘disagree’ and ‘strongly disagree’ as the most common responses. As responses on a likert scale are ordinal then we can apply a Kruskal- Wallis test when comparing different groups. As before, we use the kruskal.test function and pass through raw data, rather than a contingency table. There is no need to create a contingency table for the Kruskal Wallis test.\nFor example,ST324Q11JA asks students to report how much they agree with the statement ‘school is a waste of time’ on a 4-point Likert scale, with responses being “strongly agree”, “agree”, “disagree” and “strongly disagree”. Let’s say we want to compare to responses from males and females in the PISA data set to see if they are statistically different from one another or not. As with the previous example, we need to create a data.frame of responses to ST324Q11JA, but this time for the whole PISA set by gender. The one key difference is that Likert scale data is not numerical, which means we need to recode the data so that it is numeric using the as.numeric function. This means that “strongly agree” will be recoded to “4”, “agree” will be recoded to “3” and so on.\n\n# Create a data frame including data on 'school is a waste of time' and gender \n\nGW &lt;- PISA_2022 %&gt;%\n1  select(ST004D01T,ST324Q11JA)%&gt;%\n2  filter(ST004D01T!=\"NA\"&ST324Q11JA!=\"NA\")%&gt;%\n3  droplevels()\n\nGW_recoded &lt;- GW %&gt;%                                      \n4  mutate(ST324Q11JA = as.numeric(ST324Q11JA))\n\n5kruskal.test(data = GW_recoded, ST324Q11JA ~ ST004D01T)\n\n# The p-value is less than 0.05 (p-value&lt;2.2e-16), therefore we reject the null hypothesis and accept the alternative hypothesis that opinions on 'school is a waste of time' are statistically different for boys and girls.\n\n\n1\n\nchoose ‘waste of time’ and gender\n\n2\n\nfilter out NA values\n\n3\n\ndrop country variable now filtering is done\n\n4\n\nrecode worded responses as numerical responses\n\n5\n\nperform the kruskal test\n\n\n\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  ST324Q11JA by ST004D01T\nKruskal-Wallis chi-squared = 3244.5, df = 1, p-value &lt; 2.2e-16\n\n\nThe test is interpreted in the same way as a chi square test. The null hypothesis is that there are no differences in the ordinal data of the groups being tested. If the p-value is over 0.05 the null hypothesis is accepted, if it is below, the null hypothesis is rejected.",
    "crumbs": [
      "07 Hypothesis testing and Chi-square tests"
    ]
  },
  {
    "objectID": "chapters/07-ChisqPISA.html#task-1---creating-contingency-tables",
    "href": "chapters/07-ChisqPISA.html#task-1---creating-contingency-tables",
    "title": "07 Hypothesis testing and Chi-square tests",
    "section": "8.1 Task 1 - Creating contingency tables",
    "text": "8.1 Task 1 - Creating contingency tables\n\n\nCreate a contingency table for UK, Germany and France levels of maternal education (ST005Q01JA). In which countries are most mothers (in total) educated to post school level?\n\n\n\n\n\n\n\nTip\n\n\n\nThe responses to ST005Q01JA are:\n\n\n\n\n\n\n\nISCED Level\nDescription\n\n\n\n\n&lt;ISCED level 3.4&gt;\nPost-secondary non-Tertiary Education\n\n\n&lt;ISCED level 3.3&gt;\nUpper Secondary Education\n\n\n&lt;ISCED level 2&gt;\nLower Secondary Education\n\n\nISCED level 1&gt;\nPrimary Education\n\n\nShe did not complete &lt;ISCED level 1&gt;\n\n\n\n\n\n\n\n\nShow the code\n# Create contingency table of mother's level of education\n# Create a data frame of mother's level of education\n\nMatEd &lt;- PISA_2022%&gt;%\n  select(CNT, ST005Q01JA)%&gt;% # Select maternal ed and country variables\n  filter(CNT == \"United Kingdom\"| CNT == \"France\"| CNT == \"Germany\")%&gt;% \n          # Filter for CNT\n  droplevels() # To prevent the levels for other countries confusing the table\n\n# Turn data frame into a contingency table\n\nContTab &lt;- xtabs( ~ST005Q01JA + CNT, data = MatEd)\nContTab\n\n\n                                       CNT\nST005Q01JA                              Germany France United Kingdom\n  &lt;ISCED level 3.4&gt;                        2021   4697           5929\n  &lt;ISCED level 3.3&gt;                           0    982           3769\n  &lt;ISCED level 2&gt;                          2546    416            534\n  &lt;ISCED level 1&gt;                             0     86             88\n  She did not complete &lt;ISCED level 1&gt;.     175    171             86\n\n\nShow the code\n# The country with the highest number of level 3A mothers is the UK\n\n\n\nST261Q04JA asks if, in the last 3 months, students’ transport difficulties stopped students getting to school. Create a contingency table by gender for this variable for students in the UK. Do more girls or boys have transport difficulties?\n\n\n\nShow the code\n# Create contingency table of having transport difficulties\n# First, create a data frame of having a desk in the UK\n\nDeskUK &lt;- PISA_2022 %&gt;%\n  select(CNT, ST261Q04JA, ST004D01T) %&gt;% # Select transport & country variables\n  filter(CNT == \"United Kingdom\") %&gt;% # Filter for the UK\n  droplevels() # To prevent the levels for other countries confusing the table\n\n# Convert the data frame to a contingency table\n\nContTab&lt;-xtabs(~ST261Q04JA + ST004D01T, data = DeskUK)\n\nContTab\n\n\n          ST004D01T\nST261Q04JA Female Male\n       Yes     26   38\n       No     334  392\n\n\nShow the code\n# More boys have transport problems\n\n\n\nST250Q05JA asks if students have access to the internet. In which country in the data frame do students report the highest levels of access to the internet?\n\n\n\n\n\n\n\n\nTip\n\n\n\nTo sort a table, the easiest way is to convert it to a data frame and then use the arrange function. The default order for arrange is ascending, adding desc switches to descending.\n\n# Arranging a table\n\nPISA_2022 %&gt;%\n  select(CNT, ST250Q05JA) %&gt;% # Select internet and country variables\n  filter(ST250Q05JA == \"Yes\") %&gt;% \n  group_by(CNT) %&gt;%\n  count() %&gt;%\n  arrange(desc(n))\n\n# A tibble: 79 × 2\n# Groups:   CNT [79]\n   CNT                      n\n   &lt;fct&gt;                &lt;int&gt;\n 1 Spain                29350\n 2 United Arab Emirates 22206\n 3 Canada               21206\n 4 Kazakhstan           17450\n 5 Australia            12808\n 6 United Kingdom       11236\n 7 Argentina            10484\n 8 Italy                10026\n 9 Finland               9745\n10 Brazil                9379\n# ℹ 69 more rows",
    "crumbs": [
      "07 Hypothesis testing and Chi-square tests"
    ]
  },
  {
    "objectID": "chapters/07-ChisqPISA.html#task-2---goodness-of-fit-test.-are-the-responses-of-the-survey-in-proportion-to-populations",
    "href": "chapters/07-ChisqPISA.html#task-2---goodness-of-fit-test.-are-the-responses-of-the-survey-in-proportion-to-populations",
    "title": "07 Hypothesis testing and Chi-square tests",
    "section": "8.2 Task 2 - Goodness of fit test. Are the responses of the survey in proportion to populations?",
    "text": "8.2 Task 2 - Goodness of fit test. Are the responses of the survey in proportion to populations?\n\nThe populations of three countries in the sample are:\n\n\n\nCountry\nPopulation\nRatio\n\n\n\n\nUS\n332 million\n0.69\n\n\nGermany\n83 million\n0.17\n\n\nUK\n67 million\n0.14\n\n\n\nAre the number of responses in the sample a good fit for the overall populations?\nUse a goodness of fit implementation of Chi square with the null hypothesis that the proportion of students in the sample of PISA match that of the overall population.\nHint: As we only have one variable here, numbers in each country, we don’t use xtabs to count - instead we can use group_by(CNT) and count() (don’t forget to use drop_levels() . For example, to create counts of the number of entries in the PISA data for France, Spain and Italy, you can use the code below:\n\n# Create a data frame of the entries for Spain, France and Italy\n\nPISAFRSPIT&lt;-PISA_2022%&gt;%\n  select(CNT)%&gt;%\n  filter(CNT == \"France\" | CNT== \"Spain\" | CNT == \"Italy\")%&gt;%\n  group_by(CNT)%&gt;%\n  count()%&gt;%\n  droplevels()\n\nPISAFRSPIT\n\n# A tibble: 3 × 2\n# Groups:   CNT [3]\n  CNT        n\n  &lt;fct&gt;  &lt;int&gt;\n1 Spain  30800\n2 France  6770\n3 Italy  10552\n\n\n\n\n\nShow the code\n# Create a data frame of entries in the data for the UK, US and Germany\n\nSubset &lt;- PISA_2022 %&gt;%\n  select(CNT) %&gt;%\n  filter(CNT == \"United Kingdom\"|CNT == \"United States\"|CNT == \"Germany\") %&gt;%\n  group_by(CNT)%&gt;%\n  count()%&gt;%\n  droplevels()\n\n# perfom the test \nchisq.test(Subset$n, p = c(0.17, 0.14, 0.69))\n\n# P is &lt; 2.2e-16 indicating that\n# The UK has many more responses that expected by proportion of its size.",
    "crumbs": [
      "07 Hypothesis testing and Chi-square tests"
    ]
  },
  {
    "objectID": "chapters/07-ChisqPISA.html#task-3---goodness-of-fit-test-birth-month-distribution",
    "href": "chapters/07-ChisqPISA.html#task-3---goodness-of-fit-test-birth-month-distribution",
    "title": "07 Hypothesis testing and Chi-square tests",
    "section": "8.3 Task 3 - Goodness of fit test: Birth month distribution",
    "text": "8.3 Task 3 - Goodness of fit test: Birth month distribution\n\nPerform a goodness of fit test to determine if the birth months (ST003D02T) of respondents are distributed as expected in\n\nthe whole sample;\nin the UK. Use ggplot to plot a column graph of both data sets (the world and the UK).\nWhat might explain any patterns you see.\n\nHint - you can use the rep function to save you typing. For example, if you want to set a variable to be 0.1 ten times, you use variable&lt;-c(rep(0.1, times=10))\n\n\n\nShow the code\n# Create a data frame of counts of birth monts\nWorldmonth &lt;- PISA_2022 %&gt;%\n  select(ST003D02T) %&gt;%\n  group_by(ST003D02T) %&gt;%\n  count() %&gt;%\n  droplevels() %&gt;%\n  na.omit()\n\n# Create an expected variable - hint rep repeats a value a specified number of times - to reduce typing\n\nExpected &lt;- c(rep(1/12, times=12))\n\nchisq.test(Worldmonth$n, p=Expected)\n\n# p-value &lt; 2.2e-16, which is less than 0.05, reject the null hypothesis.The world data does not follow the expect distribution\n\nUKmonth &lt;- PISA_2022 %&gt;%\n  select(ST003D02T, CNT) %&gt;%\n  filter(CNT==\"United Kingdom\") %&gt;%\n  group_by(ST003D02T) %&gt;%\n  count() %&gt;%\n  droplevels() %&gt;%\n  na.omit()\n\n# Set the expected values\nExpected &lt;- c(rep(1/12, times=12))\n\n# Perform the test\n\nchisq.test(UKmonth$n, p=Expected)\n\n# p-value &lt; 0.0002224, which is less than 0.05, reject the null hypothesis. The UK data do not follow the expect distribution\n\nggplot(data = Worldmonth,\n       aes(x=ST003D02T, y = n, fill = ST003D02T)) +\n  geom_col() +\n  ggtitle(\"World birth months\")\n\nggplot(data = UKmonth,\n       aes(x=ST003D02T,y = n, fill = ST003D02T)) +\n  geom_col() +\n  ggtitle(\"UK birth months\")",
    "crumbs": [
      "07 Hypothesis testing and Chi-square tests"
    ]
  },
  {
    "objectID": "chapters/07-ChisqPISA.html#task-4---country-differences---hypothesis-testing",
    "href": "chapters/07-ChisqPISA.html#task-4---country-differences---hypothesis-testing",
    "title": "07 Hypothesis testing and Chi-square tests",
    "section": "8.4 Task 4 - Country differences - hypothesis testing",
    "text": "8.4 Task 4 - Country differences - hypothesis testing\n\nPerform a hypothesis test to determine:\n\n`ST250Q01JA’ asks students if they have a room of there own. Test the hypothesis that there is no difference in having a room between students in the UK, US, New Zealand and Australia.\n\nPlot a mosaic plot of the proportions\n\n\nShow the code\n# Create a data frame of having a room (ST250Q01JA) for the 4 countries\n\nRoom &lt;- PISA_2022 %&gt;%\n  select(CNT, ST250Q01JA) %&gt;% # choose country and room\n  filter(CNT == \"United Kingdom\"|CNT == \"United States\"|\n           CNT == \"New Zealand\"|CNT == \"Australia\") %&gt;% # filter by four countries\n  droplevels() # Remove other countries which exist as factors\n\n# Create a contingency table\nRoomCont&lt;-xtabs(data=Room, ~ ST250Q01JA + CNT)\n\nchisq.test(RoomCont) # Perform the test\n\n# The p-value is less than 0.05 (p-value &lt; 2.2e-16), therefore we reject the null hypothesis that the distributions of rooms are the same in the countries\n\n# Create a geom mosaic plot of LANGN by CNT\n\nggplot(data=Room) +\n  geom_mosaic(aes(x = product(ST250Q01JA,CNT), fill = ST250Q01JA))\n\n\n\n\n\nAre there significant differences between Japan, Greece and the UK in ST250Q02JA, A computer (laptop, desktop, or tablet) that you can use for school work? (Yes or No). Produce a mosaic plot.\n\n\n\nShow the code\n# Create a data frame of ST250Q02JA (computers at home) for the 3 countries of interest\n\nComp &lt;- PISA_2022 %&gt;%\n  select(CNT, ST250Q02JA) %&gt;% # choose country and use of computer\n  filter(CNT == \"United Kingdom\"|CNT == \"Japan\"| CNT == \"Greece\") %&gt;% \n  # filter by countries\n  droplevels() # Remove other countries which exist as factors\n\n# Produce a contingency table\nContComp &lt;- xtabs(data=Comp, ~ CNT + ST250Q02JA)\n\nchisq.test(ContComp) # Perform the test\n# The p-value is less than 0.05 (p-value &lt; 2.2e-16), therefore we reject the null hypothesis that the distributions are the same\n\n# Produce a geom_mosaic plot by CNT\n\nggplot(data=Comp) +\n  geom_mosaic(aes(x = product(ST250Q02JA, CNT), fill = ST250Q02JA))\n\n\n\n\nPerform a hypothesis test to determine if ST007Q01JA - the highest level of schooling completed by respondents’ fathers, is different in the UK, US, France and Germany.\nPlot a mosaic plot of the proportions.\nFollow up question: Are the proportions of paternal education different in the three European countries (UK, France and Germany)?\n\n\n\n\n\n\nTip\n\n\n\nHint: assume the null hypothesis is that fathers have the same level of qualifications in the four countries.\n\n\n\n\nShow the code\n# Create a data frame of paternal education ST007Q01TA for the 3 countries\n\nPatEdTypes&lt;-PISA_2022 %&gt;%\n  select(CNT, ST007Q01JA) %&gt;% # choose country and type of school\n  filter(CNT ==\"United Kingdom\"|CNT == \"United States\"|\n           CNT== \"France\"|CNT == \"Germany\")%&gt;% # filter by four countries\n  droplevels() # Remove other countries which exist as factors\n\n# Create a contingency table\n\nConttable&lt;-xtabs(data=PatEdTypes, ~ CNT, ST007Q01JA)\n\n# Perform the chi.sq test\n\nchisq.test(Conttable) # Perform the test\n# The p-value is less than 0.05 (p-value &lt; 2.2e-16), therefore we reject the null hypothesis that the distributions are the same\n\n# Create a geom_mosaic\nggplot(data = PatEdTypes) +\n  geom_mosaic(aes(x = product(ST007Q01JA, CNT), fill = ST007Q01JA)) +\n  ylab(\"Frequency of father's level of qualification\") +\n  xlab(\"Country\") +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))# Rotate x-axis labels\n\n# Follow up Question\n# Create a data frame of paternal education ST007Q01JA for the 3 countries\nPatEdTypes&lt;-PISA_2022 %&gt;%\n  select(CNT, ST007Q01JA) %&gt;% # choose country and type of school\n  filter(CNT == \"United Kingdom\" | CNT == \"France\" | CNT == \"Germany\") %&gt;% \n  droplevels() # Remove other countries which exist as factors\n\nConttable&lt;-xtabs(data = PatEdTypes, ~CNT ,ST007Q01JA)\nchisq.test(Conttable) # Perform the test\n# The p-value is less than 0.05 (p-value &lt; 2.2e-16), therefore we reject the null hypothesis that the distributions are the same\n\n# Create a geom_mosaic\nggplot(data = PatEdTypes) +\n  geom_mosaic(aes(x = product(ST007Q01JA,CNT), fill = ST007Q01JA)) +\n  ylab(\"Frequency of father's level of qualification\") +\n  xlab(\"Country\") +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) # Rotate labels",
    "crumbs": [
      "07 Hypothesis testing and Chi-square tests"
    ]
  },
  {
    "objectID": "chapters/07-ChisqPISA.html#task-5---comparing-different-groups-with-likert-scale-responses",
    "href": "chapters/07-ChisqPISA.html#task-5---comparing-different-groups-with-likert-scale-responses",
    "title": "07 Hypothesis testing and Chi-square tests",
    "section": "8.5 Task 5 - Comparing different groups with Likert Scale responses",
    "text": "8.5 Task 5 - Comparing different groups with Likert Scale responses\n\nPerform a hypothesis test to determine:\n\n`ST355Q03JA’ asks students if they are confident in finding resources online. Test the hypothesis that there is no difference in confidence in finding resources online by gender. Plot a mosaic plot with the different proportions.\n\n\n\nShow the code\n# Create a data frame of confidence in finding resources online on their own (ST355Q03JA) and gender\n\nonline_res &lt;- PISA_2022 %&gt;%\n  select(ST004D01T, ST355Q03JA)%&gt;%\n  filter(ST004D01T!=\"NA\"& ST355Q03JA!=\"NA\")%&gt;%\n  droplevels()\n\n#Mosiac Plot\nggplot(data = online_res) +\n  geom_mosaic(aes(x = product(ST004D01T, ST355Q03JA), fill = ST004D01T)) +\n  ylab(\"Confidence in finding online resources\") +\n  xlab(\"Gender\") +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) \n\n# Recode as numeric\n\nonline_res_recoded &lt;- online_res %&gt;%\n  mutate(ST355Q03JA = as.numeric(ST355Q03JA))  \n\n# Perform the KW test\nkruskal.test(data = online_res_recoded, ST355Q03JA ~ ST004D01T)\n\n# The p-value is less than 0.05 (p-value &lt; 2.2e-16), therefore we reject the null hypothesis and accept the alternative hypothesis that confidence in finding resources online on their own and gender are statistically different (dependent)\n\n\n\n\n\nIC172Q01JA asks students how much they agree or disagree that there are enough digital resources for every student at my school. Determine if there are statistical differences in the responses between the United Kingdom and the United States or not. Plot a mosaic plot with the different proportions.\n\n\n\nShow the code\n#Create a data frame of there is enough digital resources in my school for every student (IC172Q01JA) and the United Kingdom and United States\n\ndigital_res &lt;- PISA_2022 %&gt;%\n  select(CNT, IC172Q01JA) %&gt;% \n  filter(CNT == \"United Kingdom\"|CNT == \"United States\") %&gt;% \n  filter(IC172Q01JA != \"NA\") %&gt;%\n  droplevels()\n\n#Mosiac Plot\nggplot(data = digital_res) +\n  geom_mosaic(aes(x = product(CNT, IC172Q01JA), fill=CNT))\n\n# Convert to numeric\ndigital_res_recoded &lt;- digital_res %&gt;%\n  mutate(IC172Q01JA = as.numeric(IC172Q01JA))\n\n# Perform the KW test\nkruskal.test(data = digital_res_recoded, IC172Q01JA ~ CNT)\n\n# The p-value is less than 0.05 (p-value &lt; 2.2e-16), therefore we reject the null hypothesis and accept the alternative hypothesis that there is enough digital resources in my school are statistically different in the United Kingdom and United States (dependent)\n\n\n\n\n\nAre there differences in the number of televisions in the home ST254Q01JA in the UK and the United States? Create a mosaic plot\n\n\n\nShow the code\nUKUSTV&lt;-PISA_2022 %&gt;%\n  select(CNT, ST254Q01JA ) %&gt;% # choose country and no of TVs\n  filter(CNT == \"United Kingdom\"| CNT == \"United States\")%&gt;% \n  # filter for the UK and US\n  droplevels() # Remove other countries which exist as factors\n\n# Perform the test\n\nkruskal.test(data = UKUSTV,ST254Q01JA ~ CNT) \n\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  ST254Q01JA by CNT\nKruskal-Wallis chi-squared = 11.157, df = 1, p-value = 0.000837\n\n\nShow the code\n# The p-value is less than 0.05 (p-value=2.2e-16), therefore we reject the null hypothesis that the number of books is the same for respondents in the UK and the US\n\n# Create a geom_mosaic\n\nggplot(data = UKUSTV)+\n  geom_mosaic(aes(x = product(ST254Q01JA,CNT), fill = ST254Q01JA))+\n  ylab(\"Number of TVs in the home\")+\n  xlab(\"Country\")+\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))\n\n\n\n\n\n\n\n\n\nShow the code\n# Rotate x-axis labels\n\n\n\n\n\nIn the UK, are there differences for boys and girls for the number of instruments in the home (ST251Q06JA)? Create a mosaic plot.\n\n\n\nShow the code\n# Create a data frame of instruments in the UK including gender\n\nUKInstruments&lt;-PISA_2022%&gt;%\n  select(CNT, ST251Q06JA, ST004D01T ) %&gt;% \n  # choose CNT, no of instruments, gender\n  filter(CNT == \"United Kingdom\") %&gt;% # filter for the UK\n  select(ST251Q06JA, ST004D01T) %&gt;% \n  #drop the country variable now filtering is done\n  droplevels() # Remove other countries which exist as factors\n\n\n# Perform the test\n\nkruskal.test(data = UKInstruments, ST251Q06JA ~ ST004D01T) \n\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  ST251Q06JA by ST004D01T\nKruskal-Wallis chi-squared = 15.366, df = 1, p-value = 8.859e-05\n\n\nShow the code\n# The p-value is less than 0.05 (p-value = 6.146e-07), therefore we reject the null hypothesis. Girls and boys have different access to instruments in the home.\n\n# Create a geom_mosaic\n\nggplot(data = UKInstruments)+\n  geom_mosaic(aes(x = product(ST251Q06JA, ST004D01T), fill = ST251Q06JA))+\n  ylab(\"Number of instruments in the home for UK young people\")+\n  xlab(\"Gender\")+\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))# Rotate x-axis labels\n\n\n\n\n\n\n\n\n\n\n\n\nIn the UK, are there differences for boys and girls working for pay in the UK (WORKPAY)? Plot the data as a mosaic plot.\n\n\n\nShow the code\n# Create a data frame of working in the Uk with gender\n\nUKWork&lt;-PISA_2022 %&gt;%\n  select(CNT, WORKPAY, ST004D01T) %&gt;% # choose CNT, WORKPAY, gender\n  filter(CNT == \"United Kingdom\") %&gt;% # filter for the UK\n  select(WORKPAY, ST004D01T)%&gt;% \n  #drop the country variable now filtering is done\n  droplevels() # Remove other countries which exist as factors\n\n# Perform the test\n\nkruskal.test(UKWork, WORKPAY ~ ST004D01T) # Perform the test\n\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  UKWork\nKruskal-Wallis chi-squared = 19522, df = 1, p-value &lt; 2.2e-16\n\n\nShow the code\n# The p-value is less than 0.05 (p-value &lt; 2.2e-16), therefore we reject the null hypothesis. Girls and boys have different levels of work\n\n# Create a geom_mosaic\n\nggplot(data = UKWork)+\n  geom_mosaic(aes(x = product(WORKPAY, ST004D01T), fill = WORKPAY))+\n  ylab(\"Frequency of work\")+\n  xlab(\"Gender\")+\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust= 1))+\n  theme(axis.text.y = element_text(size=rel(0.5))) # Reduce y-axis font size\n\n\n\n\n\n\n\n\n\nShow the code\n# Rotate x-axis labels",
    "crumbs": [
      "07 Hypothesis testing and Chi-square tests"
    ]
  },
  {
    "objectID": "chapters/07-ChisqPISA.html#doing-chi-square-tests-in-r",
    "href": "chapters/07-ChisqPISA.html#doing-chi-square-tests-in-r",
    "title": "07 Hypothesis testing and Chi-square tests",
    "section": "10.1 Doing Chi-Square tests in R",
    "text": "10.1 Doing Chi-Square tests in R\n\n\nYou can find the code used in the video below\n\n# Introduction to Chi-square\n#\n# Download data from /Users/k1765032/Library/CloudStorage/GoogleDrive-richardandrewbrock@gmail.com/.shortcut-targets-by-id/1c3CkaEBOICzepArDfjQUP34W2BYhFjM4/PISR/Data/PISA/subset/Students_2018_RBDP_none_levels.rds\n# You want the file: Students_2018_RBDP_none_levels.rds\n# and place in your own file system\n# change loc to load the data directly. Loading into R might take a few minutes\n\nloc &lt;- \"https://drive.google.com/open?id=14pL2Bz677Kk5_nn9BTmEuuUGY9S09bDb&authuser=richardandrewbrock%40gmail.com&usp=drive_fs\"\nPISA_2018 &lt;- read_rds(loc)\n\n# Are there differences between how often students change school?\n# ST004D01T is the gender variable (Male, Female)\n# SCCHANGE is a categorical variable (No change / One change / Two or more changes)\n\nchidata &lt;- PISA_2018 %&gt;%\n  select(CNT,ST004D01T,SCCHANGE) %&gt;%\n  filter(CNT==\"United Kingdom\")\n\nchidata&lt;-chidata[-c(1)]\nchidata&lt;-drop_na(chidata)\n\n chidata &lt;- PISA_2018 %&gt;%\n   filter(CNT==\"United Kingdom\")\n   select(ST004D01T,SCCHANGE) %&gt;% \n   drop_na()\n# Above is the approiach I took in the video\n# An alternative, Pete suggests, which is more elegant, is below\n# Note he drops the country varibale, within the piped section\n# using: elect(-CNT)\n#    \n# chidata &lt;- PISA_2018 %&gt;%\n#   select(CNT,ST004D01T,SCCHANGE) %&gt;%\n#   filter(CNT==\"United Kingdom\") %&gt;%\n#   select(-CNT) %&gt;% \n#   drop_na()\n\n# run the test\nchisq.test(chidata$ST004D01T, chidata$SCCHANGE)",
    "crumbs": [
      "07 Hypothesis testing and Chi-square tests"
    ]
  },
  {
    "objectID": "chapters/02-2-Intro_to_analysis_software.html",
    "href": "chapters/02-2-Intro_to_analysis_software.html",
    "title": "Loading packages and exploring data",
    "section": "",
    "text": "This course focuses on using the tidyverse; a free collection of programming packages that will allow you to write code that imports data, tidys it, transforms it into useful datasets, visualises findings, creates statistical models and communicates findings to others data using a standardised set of commands.\nFor many people the tidyverse is the main reason that they use R. The tidyverse is used widely in government, academia, NGOs and industry, notable examples include the Financial Times and the BBC. Code in the tidyverse can be (relatively) easily understood by others and you, when you come back to a project after several months.",
    "crumbs": [
      "02 Introduction to R",
      "Loading packages and exploring data"
    ]
  },
  {
    "objectID": "chapters/02-2-Intro_to_analysis_software.html#proper-addresses",
    "href": "chapters/02-2-Intro_to_analysis_software.html#proper-addresses",
    "title": "Loading packages and exploring data",
    "section": "\n5.1 Proper addresses",
    "text": "5.1 Proper addresses\nYou might have found that you get an error if you don’t convert your backslashes \\ into forwardslashes /. It’s common mistake and very annoying. In most programming languages a backslash signifies the start of a special command, for example \\n signifies a newline.\nWith R there are three ways to get around the problem of backslashes in file locations, for the location:\"C:\\myfolder\\\" we could:\n\nreplace them with forwardslashes (as shown above):\"C:/myfolder/\"\n\nreplace them with double backslashes (the special character specified by two backslashes is one backslash!):\"C:\\\\myfolder\\\\\"\n\nuse the inbuilt R command to deal with filenames: r\"[C:\\myfolder\\]\"",
    "crumbs": [
      "02 Introduction to R",
      "Loading packages and exploring data"
    ]
  },
  {
    "objectID": "chapters/02-2-Intro_to_analysis_software.html#questions",
    "href": "chapters/02-2-Intro_to_analysis_software.html#questions",
    "title": "Loading packages and exploring data",
    "section": "\n8.1 Questions",
    "text": "8.1 Questions\n\nUsing the PISA_2022 dataset:\n\nuse the Environment window to view the dataset, what is the name and the label of the 26th column?\n\n\nanswer# the 26th column is ST062Q02TA\n# the label is: \"In the last two full weeks of school, how often: I [skipped] some classes\"\n\n# you could use View() instead of the environment window, note the capital V\nView(PISA_2022)\n# use could use the vector subset to fetch the 100th name\nnames(PISA_2022)[26]\n# [1] \"ST062Q02JA\"\n\n# you could use the attr function to find the label\nattr(PISA_2022$ST062Q02TA, \"label\")\n#  \"In the last two full weeks of school, how often: I [skipped] some classes\"\n\n# or using the dollar sign to load this field will also give the label\nPISA_2022$ST062Q02TA\n\n\n\nUse the dollar sign $ to return the column ST004D01T. What is stored in this column?\n\n\nanswer# Student (Standardized) Gender\nPISA_2022$ST004D01T\n\n#  [1] Female Male   Male   Female Female Male   Male   Female Female Female Male  \n#  [12] Male   Male   Male   Female Female Male   Female Female Female Male   Male  \n#  [23] Male   Female Female Female Female Female Male   Female Male   Male   Male  \n#  [34] Female Female Male   Female Female Female Female Female Male   Female Male  \n#   [ reached getOption(\"max.print\") -- omitted 612744 entries ]\n# attr(,\"label\")\n# [1] Student (Standardized) Gender\n# Levels: Female Male Valid Skip Not Applicable Invalid No Response\n\n\n\nHow many students results are in the whole table?\n\n\nanswernrow(PISA_2022)\n# [1] 613744\n\n\n\nWhat unique values does the dataset hold for Mother’s occupation OCOD1 and Father’s occupation OCOD2? Which is larger?\n\n\nanswerunique(PISA_2022$OCOD1)\nunique(PISA_2022$OCOD2)\n\n# you can read the length from the above, or you could use the\n# length command to tell you the length of the vector\n\nlength(unique(PISA_2022$OCOD1))\n# [1] 590\nlength(unique(PISA_2022$OCOD2))\n# [1] 590\n\n# Both fields are the same size implying there are no jobs that women do, but men don't.\n# to confirm this we can use the set difference command `setdiff(vector1, vector2)`.\n\nsetdiff(unique(PISA_2022$OCOD1),\n        unique(PISA_2022$OCOD2))\n# character(0)\n\n\n\nWhat are the maximum, mean, median and minumum science grades PV1SCIE achieved by any student\n\n\nanswer# remember to set the na.rm = TRUE\nmax(PISA_2022$PV1SCIE, na.rm=TRUE)\n# [1] 895.375\nmean(PISA_2022$PV1SCIE, na.rm=TRUE)\n# [1] 450.4625\nmedian(PISA_2022$PV1SCIE, na.rm=TRUE)\n# [1] 444.464\nmin(PISA_2022$PV1SCIE, na.rm=TRUE)\n# [1] 0\n\n\n\nExplore the dataset and makes notes about the range of values of 2 other columns",
    "crumbs": [
      "02 Introduction to R",
      "Loading packages and exploring data"
    ]
  },
  {
    "objectID": "chapters/02-2-Intro_to_analysis_software.html#footnotes",
    "href": "chapters/02-2-Intro_to_analysis_software.html#footnotes",
    "title": "Loading packages and exploring data",
    "section": "Footnotes",
    "text": "Footnotes\n\nEven in this cut down format the PISA data might take a few minutes to load. You can find the full dataset here, but be warned, it might crash you machine when trying to load it! Plug your laptop into a power supply, and having 16GB of RAM is highly recommended! You might also need to wrangle some of the fields to make them work for your purposes, you might enjoy the challenge!↩︎",
    "crumbs": [
      "02 Introduction to R",
      "Loading packages and exploring data"
    ]
  },
  {
    "objectID": "chapters/02-1-Intro_to_analysis_software.html",
    "href": "chapters/02-1-Intro_to_analysis_software.html",
    "title": "Introduction to R",
    "section": "",
    "text": "This short course aims to take you through the process of writing your first programs in the R statistical programming language to analyse national and international educational datasets. To do this we will be using the R Studio integrated development environment (IDE), a desktop application to support you in writing R scripts. R Studio supports your programming by flagging up errors in your code as you write it, and helping you manage your analysis environment by giving you quick access to tables, objects and graphs as you develop them. In addition, we will be looking at data analysis using the tidyverse code packages. The tidyverse is a standardised collection of supporting code that helps you read data, tidy it into a usable format, analyse it and present your findings.\nThe R programming language offers similar functionality to an application based statistical tool such as SPSS, with more of a focus on you writing code to solve your problems, rather than using prebuilt tools. R is open source, meaning that it is free to use and that lots of people have written code in R that they have shared with others. R statistical libraries are some of the most comprehensive in existence. R is popular1 in academia and industry, being used for everything from sales modelling to cancer detection.\n# This example shows how R can pull data directly from the internet\n# tidy it and start making graphs. All within 9 lines of code\nlibrary(tidyverse)\n\neducation &lt;- read_csv(\n  \"https://barrolee.github.io/BarroLeeDataSet/BLData/BL_v3_MF.csv\")\n\neducation %&gt;%\n  filter(agefrom == 15, ageto == 24,\n         country %in% c(\"Germany\",\"France\",\"Italy\",\"United Kingdom\")) %&gt;%\n  ggplot(aes(x=year, y=yr_sch, colour=country)) +\n  geom_point() +\n  geom_line()\nWhilst it is possible to use R through menu systems and drop down tools, the focus of this course is for you to write your own R scripts. These are text files that will tell the computer how to go through the process of loading, cleaning, analysing and presenting data. The sequential and modular nature of these files makes it very easy to develop and test each stage separately, reuse code in the future, and share with others.\nThis booklet is written with the following sections to support you:\n# Code examples and questions appear like this\na &lt;- 1 + 3\nCourier font indicates keyboard presses, column names, column values and function names.\n&lt;folder&gt; Courier font within brackets describe values that can be passed to functions and that you need to define yourself. I.e. copying and pasting these code chunks verbatim won’t work!",
    "crumbs": [
      "02 Introduction to R",
      "Introduction to R"
    ]
  },
  {
    "objectID": "chapters/02-1-Intro_to_analysis_software.html#sec-installation",
    "href": "chapters/02-1-Intro_to_analysis_software.html#sec-installation",
    "title": "Introduction to R",
    "section": "\n1.1 Installation (on your own machine)",
    "text": "1.1 Installation (on your own machine)\n\n\nInstall R (default settings should be fine)\n\n\nWindows users visit: here\n\n\nMac users visit: here and make sure you get the correct version of R for M1/2 Macs (~November 2020 onwards), or Intel Macs (~up to November 2020)\n\n\nInstall RStudio, visit here and it should present you with the version suitable for your operating system.\n\n(If the above doesn’t work follow the instructions here)",
    "crumbs": [
      "02 Introduction to R",
      "Introduction to R"
    ]
  },
  {
    "objectID": "chapters/02-1-Intro_to_analysis_software.html#sec-packages",
    "href": "chapters/02-1-Intro_to_analysis_software.html#sec-packages",
    "title": "Introduction to R",
    "section": "\n1.2 Setting up RStudio and the tidyverse",
    "text": "1.2 Setting up RStudio and the tidyverse\n\nOpen RStudio\n\nOn the bottom right-hand side, select Packages, then select Install, then type “tidyverse” into the Packages field of the new window:\n\n\nClick Install and you should see things happening in the console (bottom left). Wait for the console activity to finish (it’ll be downloading and checking packages). If it asks any questions, type N for no and press enter.\n\nAdd a new R Script using the  button\n\n\n\nIn the new R script, write the following:\n\n\n\nSelect all the lines and press Control or Command ⌘ and Enter on your keyboard at the same time. Alternatively, press the  button\n\n\n\nCheck that you have the following in the console window (depending on your screen size you might have fewer columns):\n\n\nInstall the arrow package, repeat step 2, above.\nDownload the PISA_student_2022_subset.parquet dataset from here and download it on your computer, make a note of the full folder location where you have saved this!\n\n\n\n\n\n\n\nNote\n\n\n\nIf you need help with finding the full folder location of your file, often a hurdle for Mac users, go to ?@sec-loading-computer\n\n\n\nCopy the following code and replace &lt;folder&gt; with the full folder location of where your dataset was saved, make sure that you have .parquet on the end. And keep the (r\"[  ]\")!\n\n\nexamples of what this should look like for PC and Mac# For Pete (PC) the address format was:\nPISA_2022 &lt;- read_parquet(r\"[C:\\Users\\Peter\\KCL\\MASTEMR\\PISA_student_2022_subset.parquet]\")\n\n# For Richard (Mac) the address format was:\nPISA_2022 &lt;- read_parquet(r\"[/Users/k1765032/Documents/Teaching/STEM MA/Quantitative module/Data sets/PISA_student_2022_subset.parquet]\")\n\n\n\nlibrary(arrow)\nlibrary(tidyverse)\n\nPISA_2022 &lt;- read_parquet(r\"[&lt;folder&gt;PISA_student_2022_subset.parquet]\")\n\n\nUnderneath the code you have already written, copy the code below (you don’t have to write it yourself), and run it. Try and figure out what each line does and what it’s telling you.\n\n\nlibrary(tidyverse)\n\nPISA_2022 %&gt;%\n  mutate(maths_better = PV1MATH &gt; PV1READ) %&gt;%\n  select(CNT, ST004D01T, maths_better, PV1MATH, PV1READ) %&gt;% \n  filter(!is.na(ST004D01T), !is.na(maths_better)) %&gt;%\n  group_by(ST004D01T) %&gt;%\n  mutate(students_n = n()) %&gt;%\n  group_by(ST004D01T, maths_better) %&gt;%\n  summarise(n = n(),\n            per = n/unique(students_n))\n\n\nThat’s it, you should be set up!\nAny issues, please drop a message on the Teams group, or mail peter.kemp@kcl.ac.uk and richard.brock@kcl.ac.uk",
    "crumbs": [
      "02 Introduction to R",
      "Introduction to R"
    ]
  },
  {
    "objectID": "chapters/02-1-Intro_to_analysis_software.html#objects-and-instructions",
    "href": "chapters/02-1-Intro_to_analysis_software.html#objects-and-instructions",
    "title": "Introduction to R",
    "section": "\n3.1 Objects and instructions",
    "text": "3.1 Objects and instructions\nIn programming languages we can attach data to a name, this is called assigning a value to an object (you might also call them variables). To do this in R we use the &lt;- arrow command. For example, I want to put the word \"Pete\" into an object called myname (note that words and sentences such as \"Pete\" need speech marks):\n\nmyname &lt;- \"Pete\"\nprint(myname)\n\n[1] \"Pete\"\n\n\nWe can also perform quick calculations and assign them to objects:\n\nHoursInYear &lt;- 365 * 24\nprint(HoursInYear) \n\n[1] 8760\n\n\n\nType the two examples above into your RStudio script file and check that they work. Adapt them to say your full name and give the number of MinutesInADay\n\n\n\n\n\n\n\nTip\n\n\n\nRemember to select code and press control or command and Enter to run it\n\n\nObjects can form part of calculations, for example, the code below shows how we can use the number HoursInYear to (roughly!) calculate the number of HoursInWeek:\n\nHoursInYear &lt;- 365 * 24\n\nHoursInWeek &lt;- HoursInYear / 52\nprint(HoursInWeek)\n\n[1] 168.4615\n\n\nNotice from the above we can perform the main arithmetic commands using keyboard symbols: + (add); - (minus); * (multiply); / (divide); ^ (power)\nObjects can change values when you run code. For example in the code below:\n\na &lt;- 2000\nb &lt;- 5\n\na &lt;- b\n\na &lt;- a * b\nprint(a)\n\n[1] 25\n\n\nWhat’s going on here?\n\nline 1 sets a to equal 2000 (note: don’t use commas in writing numbers a &lt;- 2,000 would bring up an error),\nline 2 sets b to equal 5,\nline 4 overwrites the value of a with the value stored in b, making object a now equal to 5\nline six is now 5 * 5\n\n\n\n3.1.1 Questions\n\nwhat are the outputs of the following code snippets/what do they do? One of the examples might not output anything, why is that? Type the code into your script file to check your answers:\ncode example 1\n\nrabbits &lt;- 50\nfeet &lt;- 4\n\ntotalfeet &lt;- rabbits * feet\nprint(totalfeet)\n\n\nanswer200\n\n\ncode example 2\n\np &lt;- 3.14 - 0.14\nr &lt;- 5\n\nprint(p * r^2)\n\n\nanswer75\n\n\ncode example 3\n\ntax &lt;- 17.5\nprice &lt;- 4.50\nsales &lt;- 128\ntax &lt;- 20\n\nincome &lt;- (sales * price) * (1 + (tax/100))\n\n\nanswer# prints nothing! there isn't a print statement",
    "crumbs": [
      "02 Introduction to R",
      "Introduction to R"
    ]
  },
  {
    "objectID": "chapters/02-1-Intro_to_analysis_software.html#naming-objects",
    "href": "chapters/02-1-Intro_to_analysis_software.html#naming-objects",
    "title": "Introduction to R",
    "section": "\n3.2 Naming objects",
    "text": "3.2 Naming objects\nCorrectly naming objects is very important. You can give an object almost any name, but there are a few rules to follow:\n\nName them something sensible\nR is case sensitive, myName is not equal to (!=) myname\n\nDon’t use spaces in names\nDon’t start a name with a number\nKeep punctuation in object names to underscore (_ and full stop .) e.g. my_name, my.name.\nStick to a convention for all your objects, it’ll make your code easier to read, e.g.\n\n\nmyName, yourName, ourName (this is camelCase 2)\n\nmy_name, your_name, our_name (this is snake case)\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nThe actual name of an object has no effect on what it does (other than invalid names breaking your program!). For example age &lt;- \"Barry\" is perfectly valid to R, it’s just a real pain for a human to read.\n\n\n\n3.2.1 Questions\n\nWhich of these are valid R object names:\n\nmy_Number\nmy-Number\nmyNumber!\nfirst name\nFIRSTname\ni\n3names\nnames3\n\n\nanswers# my_Number  (VALID)\n# my-Number  (INVALID due to -)\n# myNumber!  (INVALID due to !)\n# first name (INVALID due to space)\n# FIRSTname  (VALID but don't recommend so many caps)\n# i          (VALID)\n# 3names     (INVALID starts with a 3)\n# names3     (VALID)\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nFor more information on the R programming style guide, see this",
    "crumbs": [
      "02 Introduction to R",
      "Introduction to R"
    ]
  },
  {
    "objectID": "chapters/02-1-Intro_to_analysis_software.html#comments",
    "href": "chapters/02-1-Intro_to_analysis_software.html#comments",
    "title": "Introduction to R",
    "section": "\n3.3 Comments",
    "text": "3.3 Comments\nCode can often look confusing and it’s a good idea to add # comments to your code to make it more understandable for you and others. The computer ignores comments when running your code:\n\n# this calculates the average sales per shop\n\nincome1 &lt;- 132\nincome2 &lt;- 665\nincome3 &lt;- 233\nincome4 &lt;- 1200\n\nshops &lt;- 4 # everything after the hash is a comment\n\navgSales &lt;- sum(income1, income2, income3, income4) / shops  \n\n# sometimes you might want to comment out code that\n# is no longer needed, but might be useful later\n# standard_deviation &lt;- sd(c(income1, income2, income3, income4) )\n# the above code isn't run\n\nprint(avgSales) # but this code is\n\n[1] 557.5",
    "crumbs": [
      "02 Introduction to R",
      "Introduction to R"
    ]
  },
  {
    "objectID": "chapters/02-1-Intro_to_analysis_software.html#sec-datatypes",
    "href": "chapters/02-1-Intro_to_analysis_software.html#sec-datatypes",
    "title": "Introduction to R",
    "section": "\n3.4 Datatypes",
    "text": "3.4 Datatypes\nWe have already met two different datatypes, the character datatype for words and letters (e.g. \"Peter\") and the numeric datatype for numbers (e.g. 12). Datatypes tell R how to handle data in certain circumstances. Sometimes data will be of the wrong datatype and you will need to convert between datatypes.\n\nweeks &lt;- 4\ndays_in_week &lt;- \"7\"\n\n# we now attempt to multiply a number by a string\n# but it doesn't work!\ntotal_days &lt;- weeks * days_in_week \n\nError in weeks * days_in_week: non-numeric argument to binary operator\n\n\nWhilst R will understand what to do when we multiply numbers with numbers, it gets very confused and raises an error when we try to perform an arithmetic operation using words and numbers.\nTo perform the calculation we will need to convert the days_in_week from a string to a number, using the as.numeric(&lt;text&gt;) command:\n\nweeks &lt;- 4\ndays_in_week &lt;- \"7\"\n\n# we now attempt to multiply a number by a string\ntotal_days &lt;- weeks * as.numeric(days_in_week)\n\nThere is a logical datatype for boolean values of TRUE and FALSE. This will become a lot more useful later.\n\nlegs_snake &lt;- FALSE # you can specify logical values directly\ndogs_legs &lt;- 4\nlegs_dog &lt;- dogs_legs &gt; 0 # or as part of a calculation\n\n# Do dog's have legs?\nprint(legs_dog)\n\n[1] TRUE\n\n\nThere are actually three datatypes for numbers in R, numeric for most of your work, the rarer integer specifically for whole numbers and the even rarer complex for complex numbers. When you are looking at categorical data, factors are used on top of the underlying datatype to store the different values, for example you might have a field of character to store countries, factors would then list the different countries stored in this character field.\nTo change from one datatype to another we use the as.____ command: as.numeric(&lt;text&gt;), as.logical(&lt;data&gt;), as.character(&lt;numeric&gt;).\n\n3.4.1 Questions\n\n\nCan you spot the error(s) in this code and fix them so it outputs: “July is month 7”?\n\n\nmonth &lt;- \"July\"\norder &lt;- 7\n  \nprint(month)\nPrint(\"is\")\nprint(month)\nprint(\"order\")\n\n\nanswermonth &lt;- \"July\"\norder &lt;- 7\n  \nprint(month)    \nprint(\"is\")     #1 print needs a lowercase p\nprint(\"month\")  #2 month is a character not an object, use speech marks\nprint(order)    #3 order is an object, not a character, so drop the speech marks\n\n\n\nCan you spot the error(s) in this code and fix it?\n\n\na &lt;- 7\nb &lt;- \"8\"\nc &lt; - 3\n  \nprint(a + b + c)\n\n\nanswera &lt;- 7\nb &lt;- 8 #1 b is numeric so drop the speech marks\nc &lt;- 3 #2 the arrow needs to be together, remove the space\n  \nprint(a + b + c)\n\n\n\nCan you spot the error(s) in this code and fix it?\n\n\npass mark &lt;- 50 \nexam_grade &lt;- 50\n\n# did the student pass?\nprint(exam_grade &gt; pass_mark)\n\n\nanswerpass_mark &lt;- 50 #1 the variable name can't have any spaces\nexam_grade &lt;- 50\n\n# did the student pass?\nprint(exam_grade &gt;= pass_mark) # this needs to be &gt;= as they had a passing grade\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nIf you want to find out the datatype of an object you can use the structure str command to give you more information about the object. In this instance chr means that month is of character datatype and num means it is of the numeric datatype.\n\nmonth &lt;- \"July\"\nstr(month)\n\n chr \"July\"\n\nmonth &lt;- 7\nstr(month)\n\n num 7",
    "crumbs": [
      "02 Introduction to R",
      "Introduction to R"
    ]
  },
  {
    "objectID": "chapters/02-1-Intro_to_analysis_software.html#questions-3",
    "href": "chapters/02-1-Intro_to_analysis_software.html#questions-3",
    "title": "Introduction to R",
    "section": "\n4.1 Questions",
    "text": "4.1 Questions\n\n\nCan you spot the three problems with this code:\n\n\nnums &lt;- v(1,2,\"3\",4,7,2,2)\nsum(nums)\nmean(nums)\n# return a vector of all numbers greater than 2\nnums(nums &gt;= 2)\n\n\nanswernums &lt;- c(1,2,3,4,7,2,2) \n#1 a vector is declared using c(), not v()\n#2 3 should be numeric, so no need for speech marks\n# (though technically R would do this conversion for you!)\n\nsum(nums)\nmean(nums)\n# return a vector of all numbers greater than 2\nnums[nums &gt;= 2] #3 to pick items from another vector, use square brackets\n\n\n\nCreate a vector to store the number of glasses of water you have drunk for each day in the last 7 days. Work out:\n\nthe mean average number of glasses for the week,\nthe total number of glasses,\nthe number of days where you drank less than 2 glasses (feel free to replace water with your own tipple: wine, coffee, tea, coke, etc.)\n\n\n\n\nanswerglasses &lt;- c(6,1,3,2,3,0,3)\nmean(glasses)\nsum(glasses)\nsum(glasses &lt; 2)\n\n\n\nUsing the vectors below, create a program that will find out the average grade for females taking English:\n\n\nenglish_grade &lt;- c(8,5,3,2,3,6,9)\ngenders &lt;- c(\"F\", \"M\", \"M\", \"F\", \"M\", \"F\", \"M\")\n\n\nanswerenglish_grade &lt;- c(8,5,3,2,3,6,9)\ngenders &lt;- c(\"F\", \"M\", \"M\", \"F\", \"M\", \"F\", \"M\")\nmean(english_grade[genders == \"F\"])",
    "crumbs": [
      "02 Introduction to R",
      "Introduction to R"
    ]
  },
  {
    "objectID": "chapters/02-1-Intro_to_analysis_software.html#sec-load-run-pckges",
    "href": "chapters/02-1-Intro_to_analysis_software.html#sec-load-run-pckges",
    "title": "Introduction to R",
    "section": "\n6.1 Installing and loading packages",
    "text": "6.1 Installing and loading packages\nTo install a package you can use the package tab in the bottom right-hand panel of RStudio and follow the steps from Section 1.2. Alternatively you can install things by typing:\n\ninstall.packages(\"tidyverse\")\n\nNote that the instruction is to install packages, you can pass a vector of package names to install multiple packages at the same time:\n\ninstall.packages(c(\"tidyverse\",\"readxl\",\"haven\"))\n\nOnce a package is installed it doesn’t mean that you can use it, yet. You will need to load the package. To do this you need to use the library(&lt;package_name&gt;) command, for example:\n\nlibrary(tidyverse)\n\n\n\n\n\n\n\nImportant\n\n\n\nSome packages might use the same function names as other packages, for example select might do different things depending on which package you loaded last. As a rule of thumb, when you start RStudio afresh, make sure that you load the tidyverse package after you have loaded all your other packages. To read more about this problem see ?@sec-QANDA",
    "crumbs": [
      "02 Introduction to R",
      "Introduction to R"
    ]
  },
  {
    "objectID": "chapters/02-1-Intro_to_analysis_software.html#footnotes",
    "href": "chapters/02-1-Intro_to_analysis_software.html#footnotes",
    "title": "Introduction to R",
    "section": "Footnotes",
    "text": "Footnotes\n\nAs of December 2022, Tiobe has R as the 11th most popular programming language. Many other, contradictory, ranking systems exist.↩︎\ncamelCase has a capital letter in the front or front and middle forming the camel’s hump(s), there are multiple naming conventions, it doesn’t matter which you pick, just stick to one of them.↩︎\nR was created to allow for vector programming, that is a programming language where you can apply operations to entire sets of values (vectors) at the same time, rather than having to cycle through them individually. Vector languages work in a way that is close to how mathematical notation works, making them well suited for performing mathematical functions.↩︎\nYou’ll sometimes see the words package and library used interchangeably, technically the library is the place where the packages are stored.↩︎",
    "crumbs": [
      "02 Introduction to R",
      "Introduction to R"
    ]
  },
  {
    "objectID": "chapters/02-3-Intro_to_analysis_software.html",
    "href": "chapters/02-3-Intro_to_analysis_software.html",
    "title": "Piping and dplyr",
    "section": "",
    "text": "Piping allows us to break down complex tasks into manageable chunks that can be written and tested one after another. There are several powerful commands in the tidyverse as part of the dplyr package that can help us group, filter, select, mutate and summarise datasets. With this small set of commands we can use piping to convert massive datasets into simple and useful results.\nUsing the pipe %&gt;% command, we can feed the results from one command into the next command making for reusable and easy to read code.\nLet’s look at an example of using the pipe on the PISA_2022 table to calculate the best performing OECD countries for maths PV1MATH by gender ST004D01T:\n1PISA_2022 %&gt;%\n2  filter(OECD == \"Yes\") %&gt;%\n3  group_by(CNT, ST004D01T) %&gt;%\n4  summarise(mean_maths = mean(PV1MATH, na.rm=TRUE),\n            sd_maths = sd(PV1MATH, na.rm=TRUE),\n            students = n()) %&gt;%\n5  filter(!is.na(ST004D01T)) %&gt;%\n6  arrange(desc(mean_maths))\n\n\n1\n\nline 1 passes the whole PISA_2022 dataset and pipes it into the next line using %&gt;%\n\n2\n\nline 2 filters out any results that are from non-OECD countries by finding all the rows where OECD equals == “Yes”, this is then piped to the next line\n\n3\n\nline 3 groups the data by country CNT and by student gender ST004D01T, this is then piped to the next line\n\n4\n\nline 4-6 the summarise command performs a calculation on the country and gender groupings returning three new columns, each command is described by code on a new line and separated by a comma: the mean value for maths mean_maths, the standard deviation sd_maths, and a column telling us how many students were in each grouping using the n() which returns the number of rows in a group. These new columns and the grouping columns are then piped to the next line, all other columns are dropped\n\n5\n\nline 7 filters out any gender ST004D01T that is NA. First is finds all the students that have NA as their gender by using is.na(ST004D01T), then it NOTs/flips the result using the exclamation mark !, giving those students who don’t have their gender set to NA. The filtered data is then piped to the next line\n\n6\n\nline 8, finally we arrange/sort the results in descending order by the mean_maths column. The default for arrange is ascending order, leave out the desc(  ) for the numbers to be ordered in the opposite way.\n\n\n\n\n# A tibble: 74 × 5\n# Groups:   CNT [37]\n   CNT            ST004D01T mean_maths sd_maths students\n   &lt;fct&gt;          &lt;fct&gt;          &lt;dbl&gt;    &lt;dbl&gt;    &lt;int&gt;\n 1 Japan          Male            540.     99.0     2856\n 2 Korea          Male            534.    112.      3325\n 3 Japan          Female          531.     88.1     2904\n 4 Korea          Female          528.     99.1     3129\n 5 Estonia        Male            515.     87.4     3272\n 6 Switzerland    Male            511.     99.3     3540\n 7 Estonia        Female          510.     81.5     3120\n 8 Czech Republic Male            502.    100.      4232\n 9 Switzerland    Female          501.     90.9     3289\n10 Austria        Male            500.     94.5     3110\n# ℹ 64 more rows\nAcross the top few countries, Males get a slightly better maths score PV1MATH than Females, other scores are available, please read ?@sec-PV to find out more about the limitations of using a “PV” value.\nThe commands we have just used come from a package within the tidyverse called dplyr, let’s take a look at what they do:",
    "crumbs": [
      "02 Introduction to R",
      "Piping and dplyr"
    ]
  },
  {
    "objectID": "chapters/02-3-Intro_to_analysis_software.html#questions",
    "href": "chapters/02-3-Intro_to_analysis_software.html#questions",
    "title": "Piping and dplyr",
    "section": "1.1 Questions",
    "text": "1.1 Questions\n\n\nSpot the three errors with the following select statement\n\n\nPISA_2022 \n  select(CNT BELONG) %&gt;%\n\n\n\nanswer\nPISA_2022 %&gt;%  #1 missing pipe\n  select(CNT, BELONG) #2 no comma between column names, #3 stray pipe on end\n\n\n\nWrite a select statement to display the month ST003D02T and year of birth ST003D03T and the gender ST004D01T of each student.\n\n\n\nanswer\nPISA_2022 %&gt;% \n  select(ST003D02T, ST003D03T, ST004D01T)\n\n\n\nWrite a select statement to show all the fields that are to do with well being and health, e.g. WB150Q01HA “How is your health?”\n\n\n\nanswer\nPISA_2022 %&gt;% \n  select(starts_with(\"WB15\"))\n\n\n\n[EXTENSION] Adjust your answer to Q3 so that you select the gender ST004D01T and the ID CNTSTUID of each student in addition to the ST254____ fields looking at digital devices in the home:\n\n\n\nanswer\nPISA_2022 %&gt;% \n  select(CNTSTUID, ST004D01T, starts_with(\"ST254\")) %&gt;% na.omit()",
    "crumbs": [
      "02 Introduction to R",
      "Piping and dplyr"
    ]
  },
  {
    "objectID": "chapters/02-3-Intro_to_analysis_software.html#questions-1",
    "href": "chapters/02-3-Intro_to_analysis_software.html#questions-1",
    "title": "Piping and dplyr",
    "section": "2.1 Questions",
    "text": "2.1 Questions\n\n\nSpot the two errors with the following select statement\n\n\nPISA_2022\n  select(CNT, PV1READ) %&gt;%\n  filter(CNT = \"Finland\")\n\n\n\nanswer\nPISA_2022 %&gt;%  #1 missing pipe command\n  select(CNT, PV1READ) %&gt;%\n  filter(CNT == \"Finland\") #2 you need a double equals\n\n\n\nUse filter to find all the students with PV1READ grade equal to 333.\n\n\n\nanswer\nPISA_2022 %&gt;% \n  filter(PV1READ == 333)\n\n\n\nUse filter to find all the students with PV1READ, PV1SCIE, and PV1MATH grades over 800.\n\n\n\nanswer\nPISA_2022 %&gt;% \n  filter(PV1READ &gt; 800,\n         PV1SCIE &gt; 800,\n         PV1MATH &gt; 800)\n\n\n\nSpot the three errors with the following select statement\n\n\nPISA_2022 %&gt;% \n  select(CNT) %&gt;%\n  filter(CNT in c(\"France\", \"belgium\")\n         ESCS &lt; 0)\n\n\n\nanswer\nPISA_2022 %&gt;% \n  select(CNT, ESCS) %&gt;% #1 you have ESCS in the filter, it needs to be in the select as well\n  filter(CNT %in% c(\"France\", \"Belgium\"), #2 Belgium needs a capital letter\n                                          #3 the %in% command needs percentages\n                                          #4 you need a comma (or &) at the end of the line\n         ESCS &lt; 0)\n\n\n\nUse filter to find all the students with Three or more cars in their home ST251Q01JA. How does this compare to those with no None cars?\n\n\n\nanswer\n# cars 3+ \nPISA_2022 %&gt;%\n  select(CNT, ST251Q01JA) %&gt;%\n  filter(ST251Q01JA == \"Three or more\")\n\n# cars 0\nPISA_2022 %&gt;%\n  select(CNT, ST251Q01JA) %&gt;%\n  filter(ST251Q01JA == \"None\")\n\n\n\nAdjust your code in Q2. to find the number of students with Three or more cars in their home ST251Q01JA in Italy, how does this compare with Spain?\n\n\n\nanswer\nPISA_2022 %&gt;%\n  select(CNT, ST251Q01JA) %&gt;%\n  filter(ST251Q01JA == \"Three or more\",\n         CNT == \"Italy\")\n\nPISA_2022 %&gt;%\n  select(CNT, ST251Q01JA) %&gt;%\n  filter(ST251Q01JA == \"Three or more\",\n         CNT == \"Spain\")\n\n# EXTENSION:\n# Note we would need to know the percentage of students \n# in each country with that number of cars to make a proper\n# comparison. Spain might have more students taking the PISA\n# test than Italy, or vice-versa\n\nPISA_2022 %&gt;%\n  select(CNT, ST251Q01JA) %&gt;%\n  filter(CNT %in% c(\"Italy\", \"Spain\")) %&gt;%\n  group_by(CNT) %&gt;%\n  mutate(total_stus = n()) %&gt;%\n  filter(ST251Q01JA == \"Three or more\") %&gt;%\n  summarise(three_more = n(),\n            per_three_more = three_more/unique(total_stus))\n\n\n\nWrite a filter to create a table for the number of Female students with reading PV1READ scores lower than 400 in the United Kingdom, store the result as read_low_female, repeat but for Male students and store as read_low_male. Use nrow() to work out if there are more males or females with a low reading score in the UK\n\n\n\nanswer\nread_low_female &lt;- PISA_2022 %&gt;% \n  filter(CNT == \"United Kingdom\",\n         PV1READ &lt; 400,\n         ST004D01T == \"Female\")\n\nread_low_male &lt;- PISA_2022 %&gt;% \n  filter(CNT == \"United Kingdom\",\n         PV1READ &lt; 400,\n         ST004D01T == \"Male\")\n\nnrow(read_low_female)\nnrow(read_low_male)\n\n# You could also pipe the whole dataframe into nrow()\nPISA_2022 %&gt;% \n  filter(CNT == \"United Kingdom\",\n         PV1READ &lt; 400,\n         ST004D01T == \"Female\") %&gt;% \n  nrow()\n\n\n\nHow many students in the United Kingdom had no television ST254Q01JA OR no connection to the internet ST250Q05JA. HINT: use levels(PISA_2022$ST254Q01JA) to look at the levels available for each column.\n\n\n\nanswer\nPISA_2022 %&gt;% filter(CNT == \"United Kingdom\", \n                     ST254Q01JA == \"None\" |\n                     ST250Q05JA == \"None\")\n\n\n\nWhich countr[y|ies] had students with NA for Gender, remember to check for NA using is.na()?\n\n\n\nanswer\nPISA_2022 %&gt;% \n  filter(is.na(ST004D01T)) %&gt;%\n  select(CNT) %&gt;%\n  distinct()",
    "crumbs": [
      "02 Introduction to R",
      "Piping and dplyr"
    ]
  },
  {
    "objectID": "chapters/02-3-Intro_to_analysis_software.html#questions-2",
    "href": "chapters/02-3-Intro_to_analysis_software.html#questions-2",
    "title": "Piping and dplyr",
    "section": "4.1 Questions",
    "text": "4.1 Questions\n\n\nSpot the three errors with the following summarise statement\n\n\nPISA_2022 %&gt;% \n  group(CNT)\n  summarise(num_stus = n)\n\n\n\nanswer\nPISA_2022 %&gt;% \n  group_by(CNT) %&gt;% #1 group_by NOT group #2 missing pipe %&gt;%\n  summarise(num_stus = n()) #3 = n() not = n\n\n\n\nWrite a group_by and summarise statement to work out the mean and median cultural capital value ESCS for each student by country CNT\n\n\n\nanswer\nPISA_2022 %&gt;%\n  group_by(CNT) %&gt;%\n  summarise(escs_mean = mean(ESCS, na.rm=TRUE),\n            escs_median = median(ESCS, na.rm=TRUE))\n\n\n\nUsing summarise work out, Yes or No, by country CNT and gender ST004D01T, whether students “Agree/disagree: There are enough [digital resources] for every student at my school” IC172Q01JA. Filter out any NA values on IC172Q01JA:\n\n\n\nanswer\nPISA_2022 %&gt;% \n  filter(!is.na(IC172Q01JA)) %&gt;%\n  group_by(CNT, ST004D01T, IC172Q01JA) %&gt;% \n  summarise(n=n())",
    "crumbs": [
      "02 Introduction to R",
      "Piping and dplyr"
    ]
  },
  {
    "objectID": "chapters/02-3-Intro_to_analysis_software.html#sec-ifelse",
    "href": "chapters/02-3-Intro_to_analysis_software.html#sec-ifelse",
    "title": "Piping and dplyr",
    "section": "8.1 Recoding data (ifelse)",
    "text": "8.1 Recoding data (ifelse)\nOften we want to plot values in groupings that don’t yet exist, for example might want to give all schools over a certain size a different colour from others schools, or flag up students who have a different home language to the language that is being taught in school. To do this we need to look at how we can recode values. A common way to recode values is through an ifelse statement:\n\nifelse(&lt;statement(s)&gt;, &lt;value_if_true&gt;, &lt;value_if_false&gt;)\n\nifelse allows us to recode the data. In the example below, we are going to add a new column to the PISA_2022 dataset (using mutate) noting whether a student got a higher grade in their Maths PV1MATH or Reading PV1READ tests. if PV1MATH is bigger then PV1READ, the maths_better is TRUE, else maths_better is FALSE, or in dplyr format:\n\nmaths_data &lt;- PISA_2022 %&gt;%\n  mutate(maths_better = \n           ifelse(PV1MATH &gt; PV1READ,\n                  TRUE, \n                  FALSE)) %&gt;%\n  select(CNT, ST004D01T, maths_better, PV1MATH, PV1READ)\n\nprint(maths_data)\n\n# A tibble: 613,744 × 5\n   CNT     ST004D01T maths_better PV1MATH PV1READ\n   &lt;fct&gt;   &lt;fct&gt;     &lt;lgl&gt;          &lt;dbl&gt;   &lt;dbl&gt;\n 1 Albania Female    FALSE           180.    248.\n 2 Albania Male      TRUE            308.    258.\n 3 Albania Male      FALSE           268.    285.\n 4 Albania Female    FALSE           273.    322.\n 5 Albania Female    FALSE           435.    464.\n 6 Albania Male      TRUE            534.    451.\n 7 Albania Male      FALSE           382.    391.\n 8 Albania Female    FALSE           273.    308.\n 9 Albania Female    FALSE           355.    429.\n10 Albania Female    TRUE            430.    420.\n# ℹ 613,734 more rows\n\n\nWe now take this new dataset maths_data and look at whether the difference between relative performance in maths and reading is the same for girls and boys:\n\nmaths_data %&gt;% \n  filter(!is.na(ST004D01T), !is.na(maths_better)) %&gt;%\n  group_by(ST004D01T, maths_better) %&gt;%\n  summarise(n = n()) \n\n# A tibble: 4 × 3\n# Groups:   ST004D01T [2]\n  ST004D01T maths_better      n\n  &lt;fct&gt;     &lt;lgl&gt;         &lt;int&gt;\n1 Female    FALSE        180350\n2 Female    TRUE         125409\n3 Male      FALSE        118341\n4 Male      TRUE         189565\n\n\n\nAdjust the code above to work out the percentages of Males and Females ST004D01T in each group. Check to see if the pattern also exists between science PV1SCIE and reading PV1READ:\n\n\nadding percentage column\nPISA_2022 %&gt;%\n  mutate(maths_better = \n           ifelse(PV1MATH &gt; PV1READ,\n                  TRUE, \n                  FALSE)) %&gt;%\n  select(CNT, ST004D01T, maths_better, PV1MATH, PV1READ) %&gt;% \n  filter(!is.na(ST004D01T), !is.na(maths_better)) %&gt;%\n  group_by(ST004D01T) %&gt;%\n  mutate(students_n = n()) %&gt;%\n  group_by(ST004D01T, maths_better) %&gt;%\n  summarise(n = n(),\n            per = n/unique(students_n))\n\n\n\n\ncomparing science and reading\nPISA_2022 %&gt;%\n  mutate(sci_better = \n           ifelse(PV1SCIE &gt; PV1READ,\n                  TRUE, \n                  FALSE)) %&gt;%\n  select(CNT, ST004D01T, sci_better, PV1SCIE, PV1READ) %&gt;% \n  filter(!is.na(ST004D01T), !is.na(sci_better)) %&gt;%\n  group_by(ST004D01T) %&gt;%\n  mutate(students_n = n()) %&gt;%\n  group_by(ST004D01T, sci_better) %&gt;%\n  summarise(n = n(),\n            per = n/unique(students_n))\n\n\n\n\ncomparing science and maths\nPISA_2022 %&gt;%\n  mutate(sci_better = \n           ifelse(PV1SCIE &gt; PV1MATH,\n                  TRUE, \n                  FALSE)) %&gt;%\n  select(CNT, ST004D01T, sci_better, PV1SCIE, PV1MATH) %&gt;% \n  filter(!is.na(ST004D01T), !is.na(sci_better)) %&gt;%\n  group_by(ST004D01T) %&gt;%\n  mutate(students_n = n()) %&gt;%\n  group_by(ST004D01T, sci_better) %&gt;%\n  summarise(n = n(),\n            per = n/unique(students_n))\n\n\n\nifelse statements can get a little complicated when using factors (see: Section 8.2). Take this example. Let’s flag students who have a different home language LANGN to the language that is being used in the PISA assessment tool LANGTEST_QQQ. We make an assumption here that the assessment tool will be the language used at school, so these students will be learning in a different language to their mother tongue. if LANGN equals LANGTEST_QQQ, the lang_diff is FALSE, else lang_diff is TRUE, this raises an error:\n\nlang_data &lt;- PISA_2022 %&gt;%\n  mutate(lang_diff = \n           ifelse(LANGN == LANGTEST_QQQ,\n                  FALSE, \n                  TRUE)) %&gt;%\n  select(CNT, lang_diff, LANGTEST_QQQ, LANGN)\n\nError in `mutate()`:\nℹ In argument: `lang_diff = ifelse(LANGN == LANGTEST_QQQ, FALSE, TRUE)`.\nCaused by error in `Ops.factor()`:\n! level sets of factors are different\n\n\nThe levels in each field are different, i.e. the range of home languages is larger than the range of test languages. To fix this, all we need to do is change the datatype of the factors LANGN and LANGTEST_QQQ to characters using as.character(&lt;field&gt;). This will then allow the comparison of the text stored in each row:\n\nlang_data &lt;- PISA_2022 %&gt;%\n  mutate(lang_diff = \n           ifelse(as.character(LANGN) == as.character(LANGTEST_QQQ),\n                  FALSE, \n                  TRUE)) %&gt;%\n  select(CNT, lang_diff, LANGTEST_QQQ, LANGN)\n\nprint(lang_data)\n\n# A tibble: 613,744 × 4\n   CNT     lang_diff LANGTEST_QQQ LANGN   \n   &lt;fct&gt;   &lt;lgl&gt;     &lt;fct&gt;        &lt;fct&gt;   \n 1 Albania FALSE     Albanian     Albanian\n 2 Albania FALSE     Albanian     Albanian\n 3 Albania FALSE     Albanian     Albanian\n 4 Albania FALSE     Albanian     Albanian\n 5 Albania FALSE     Albanian     Albanian\n 6 Albania FALSE     Albanian     Albanian\n 7 Albania FALSE     Albanian     Albanian\n 8 Albania FALSE     Albanian     Albanian\n 9 Albania FALSE     Albanian     Albanian\n10 Albania FALSE     Albanian     Albanian\n# ℹ 613,734 more rows\n\n\nWe can now look at this dataset to get an idea of which countries have the largest percentage of students learning in a language other than their mother tongue:\n\nlang_data_diff &lt;- lang_data %&gt;% \n  group_by(CNT) %&gt;%\n  mutate(student_n = n()) %&gt;%\n  group_by(CNT, lang_diff) %&gt;%\n  summarise(n = n(),\n            percentage = 100*(n / max(student_n))) %&gt;%\n    filter(!is.na(lang_diff),\n         lang_diff == TRUE)\n\nprint(lang_data_diff)\n\n# A tibble: 80 × 4\n# Groups:   CNT [80]\n   CNT                  lang_diff     n percentage\n   &lt;fct&gt;                &lt;lgl&gt;     &lt;int&gt;      &lt;dbl&gt;\n 1 Albania              TRUE        720      11.7 \n 2 United Arab Emirates TRUE      13933      56.6 \n 3 Argentina            TRUE        788       6.51\n 4 Australia            TRUE       1827      13.6 \n 5 Austria              TRUE       1455      23.7 \n 6 Belgium              TRUE       2445      29.5 \n 7 Bulgaria             TRUE        961      15.7 \n 8 Brazil               TRUE        559       5.18\n 9 Brunei Darussalam    TRUE       4831      86.6 \n10 Canada               TRUE       5971      25.9 \n# ℹ 70 more rows\n\n\nThis looks like a promising dataset, but there are some strange results:\n\nlang_data_diff %&gt;% filter(percentage &gt; 92)\n\n# A tibble: 8 × 4\n# Groups:   CNT [8]\n  CNT                          lang_diff     n percentage\n  &lt;fct&gt;                        &lt;lgl&gt;     &lt;int&gt;      &lt;dbl&gt;\n1 Hong Kong (China)            TRUE       5626       95.2\n2 Macao (China)                TRUE       4384      100  \n3 Montenegro                   TRUE       5596       96.6\n4 Norway                       TRUE       6611      100  \n5 Philippines                  TRUE       6693       93.0\n6 Ukrainian regions (18 of 27) TRUE       3747       96.7\n7 Singapore                    TRUE       6567       99.4\n8 Chinese Taipei               TRUE       5821       99.4\n\n\nExploring data for Ukraine, we can see that a different spelling has been used in each field, Ukrainian and Ukranain, an incorrect spelling.\n\nlang_data %&gt;% filter(CNT == \"Ukrainian regions (18 of 27)\")\n\n# A tibble: 3,876 × 4\n   CNT                          lang_diff LANGTEST_QQQ LANGN    \n   &lt;fct&gt;                        &lt;lgl&gt;     &lt;fct&gt;        &lt;fct&gt;    \n 1 Ukrainian regions (18 of 27) TRUE      Ukranian     Ukrainian\n 2 Ukrainian regions (18 of 27) TRUE      Ukranian     Ukrainian\n 3 Ukrainian regions (18 of 27) TRUE      Ukranian     Russian  \n 4 Ukrainian regions (18 of 27) TRUE      Ukranian     Ukrainian\n 5 Ukrainian regions (18 of 27) TRUE      Ukranian     Ukrainian\n 6 Ukrainian regions (18 of 27) TRUE      Ukranian     Ukrainian\n 7 Ukrainian regions (18 of 27) TRUE      Ukranian     Russian  \n 8 Ukrainian regions (18 of 27) TRUE      Ukranian     Ukrainian\n 9 Ukrainian regions (18 of 27) TRUE      Ukranian     Ukrainian\n10 Ukrainian regions (18 of 27) TRUE      Ukranian     Ukrainian\n# ℹ 3,866 more rows\n\n\nifelse can help here too. If we pick the spelling we want to stick to, we can recode fields to match:\n\nlang_data %&gt;% \n  mutate(LANGTEST_QQQ = \n           ifelse(as.character(LANGTEST_QQQ) == \"Ukranian\",\n                 \"Ukrainian\",\n                 as.character(LANGTEST_QQQ))) %&gt;%\n  mutate(lang_diff = \n           ifelse(as.character(LANGN) == as.character(LANGTEST_QQQ),\n                  FALSE, \n                  TRUE)) %&gt;%\n  filter(CNT == \"Ukrainian regions (18 of 27)\")\n\n# A tibble: 3,876 × 4\n   CNT                          lang_diff LANGTEST_QQQ LANGN    \n   &lt;fct&gt;                        &lt;lgl&gt;     &lt;chr&gt;        &lt;fct&gt;    \n 1 Ukrainian regions (18 of 27) FALSE     Ukrainian    Ukrainian\n 2 Ukrainian regions (18 of 27) FALSE     Ukrainian    Ukrainian\n 3 Ukrainian regions (18 of 27) TRUE      Ukrainian    Russian  \n 4 Ukrainian regions (18 of 27) FALSE     Ukrainian    Ukrainian\n 5 Ukrainian regions (18 of 27) FALSE     Ukrainian    Ukrainian\n 6 Ukrainian regions (18 of 27) FALSE     Ukrainian    Ukrainian\n 7 Ukrainian regions (18 of 27) TRUE      Ukrainian    Russian  \n 8 Ukrainian regions (18 of 27) FALSE     Ukrainian    Ukrainian\n 9 Ukrainian regions (18 of 27) FALSE     Ukrainian    Ukrainian\n10 Ukrainian regions (18 of 27) FALSE     Ukrainian    Ukrainian\n# ℹ 3,866 more rows\n\n\nUnfortunately, if you explore this dataset a little further, the language fields don’t conform well with each other and a lot more work with ifelse will be needed before you could put together any full analysis around students who speak different languages at home and at school.\n\n\n\n\n\n\nTip\n\n\n\nIt’s possible to nest our ifelse statements, by writing another ifelse where you would have the &lt;value_if_false&gt;, for example we might want to give describe the type of school in England:\n\n# TODO: use PISA for this\nplot_data &lt;- schools %&gt;% \n  mutate(sch_type = \n           ifelse(EstablishmentGroup == \"Special schools\", \"Special\",\n                  ifelse(EstablishmentGroup == \"Independent schools\", \"Independent\",\n                         ifelse(AdmissionsPolicy==\"Selective\", \n                                \"Grammar\", \"Comprehensive\"))))",
    "crumbs": [
      "02 Introduction to R",
      "Piping and dplyr"
    ]
  },
  {
    "objectID": "chapters/02-3-Intro_to_analysis_software.html#sec-factors",
    "href": "chapters/02-3-Intro_to_analysis_software.html#sec-factors",
    "title": "Piping and dplyr",
    "section": "8.2 Factors and statistical data types",
    "text": "8.2 Factors and statistical data types\nThe types of variable will heavily influence what statistical analysis you can perform, e.g. you’ll need numeric values for a t-test. R is there to help by assigning datatypes to each field. We have different sorts of data that can be stored:\n\n\nCategorical - data that can be divided into groups or categories\n\nNominal - categorical data where the order isn’t important, e.g. gender, or colours\nOrdinal - categorical data that may have order or ranking, e.g. exam grades (A, B, C, D) or lickert scales (strongly agree, agree, disgaree, strongly disagree)\n\nNumeric - data that consists of numbers\n\nContinuous - numeric data that can take any value within a given range, e.g. height (178cm, 134.54cm)\nDiscrete - numeric data that can take only certain values within a range, e.g. number of children in a family (0,1,2,3,4,5)\n\n\nBut here we are going to look at how R handles factors. Factors have two parts, levels and codes. levels are what you see when you view a table column, codes are an underlying order to the data. Factors allow you to store data that has a known set of values that you might want to display in an order other than alphabetical. For example, if we look at the month field ST003D02T using the levels(&lt;field&gt;) command:\n\nlevels(PISA_2022$ST003D02T)\n\n [1] \"January\"        \"February\"       \"March\"          \"April\"         \n [5] \"May\"            \"June\"           \"July\"           \"August\"        \n [9] \"September\"      \"October\"        \"November\"       \"December\"      \n[13] \"Valid Skip\"     \"Not Applicable\" \"Invalid\"        \"No Response\"   \n\n\nWe can see that the months of the year are there along with other possible levels. With this particular column there are levels for missing or wrong responses (“Valid Skip”, “Not Applicable” “Invalid”, “No Response”), though PISA rarely uses them. You are more likely to find that missing/wrong data items are coded as NA, as you can see below:\n\nPISA_2022 %&gt;% count(ST003D02T)\n\n# A tibble: 13 × 2\n   ST003D02T     n\n   &lt;fct&gt;     &lt;int&gt;\n 1 January   48760\n 2 February  43030\n 3 March     48671\n 4 April     47014\n 5 May       49235\n 6 June      48890\n 7 July      51262\n 8 August    51681\n 9 September 51755\n10 October   51703\n11 November  48179\n12 December  48156\n13 &lt;NA&gt;      25408\n\n\nCodes are the underlying numbers/order for each level, in this case 1 = January, 2 = February, etc. R stores factors as codes, then uses the levels to display the data. You can see the codes by using the as.numeric command on a factor:\n\nas.numeric(PISA_2022$ST003D02T)\n\n [1]  5  2  8  7  1  5  5 12  8  9 10  4  5  8  7  2  3  6  3  8 10  1 10  2  5\n[26]  6  8  1  3  2  5  7 12  4  1 10 10  3  3  9\n [ reached getOption(\"max.print\") -- omitted 613704 entries ]\n\n\nHow can this be useful? Firstly it’s more efficient for R to store data this way, numbers (codes) are smaller and easier to sort/search than text (levels). But it also helps when we come to presenting data. A good example is how plots are made, they will use the codes to give an order to the display of columns, in the plot below, February (2) comes before August (8), even though there were more students born in August and A is before F in the alphabet:\n\ngrph_data &lt;- PISA_2022 %&gt;% \n         group_by(ST003D02T) %&gt;% \n         summarise(n=n())\n\ngrph_data %&gt;% arrange(desc(n)) %&gt;% pull(ST003D02T)\n\n [1] September October   August    July      May       June      January  \n [8] March     November  December  April     February  &lt;NA&gt;     \nattr(,\"label\")\n[1] Student (Standardized) Birth - Month\n16 Levels: January February March April May June July August ... No Response\n\nggplot(data=grph_data, aes(x=ST003D02T, y=n)) + \n  geom_bar(stat = \"identity\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\nTo re-order the columns to match the number of students in each month, we can either try to do this manually, which is rather cumbersome:\n\nmy_levels &lt;- c(\"September\", \"October\", \"August\", \"July\", \"May\", \"June\", \n               \"January\", \"March\", \"November\", \"December\", \"April\", \"February\",\n               \"Valid Skip\", \"Not Applicable\", \"Invalid\", \"No Response\")\n\ngrph_data$ST003D02T &lt;- factor(grph_data$ST003D02T, levels=my_levels)\n\nggplot(data=grph_data, aes(x=ST003D02T, y=n)) + \n  geom_bar(stat = \"identity\")+\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\nOr we can get R to do this for us:\n\n# get the levels in order and pull/create a vector of them\nmy_levels &lt;- grph_data %&gt;% arrange(desc(n)) %&gt;% pull(ST003D02T)\n\n# reassign the re-ordered levels to the dataframe column\ngrph_data$ST003D02T &lt;- factor(grph_data$ST003D02T, levels=my_levels)\n\nggplot(data=grph_data, aes(x=ST003D02T, y=n)) + \n  geom_bar(stat = \"identity\")\n\n\n\n\n\n\n\n\nTo learn a lot more about factors, see Hadley’s chapter",
    "crumbs": [
      "02 Introduction to R",
      "Piping and dplyr"
    ]
  },
  {
    "objectID": "chapters/02-3-Intro_to_analysis_software.html#student-dataset",
    "href": "chapters/02-3-Intro_to_analysis_software.html#student-dataset",
    "title": "Piping and dplyr",
    "section": "9.1 Student dataset",
    "text": "9.1 Student dataset\n\n\nHow many unique values are there in the OCOD3 field for student intended future occupation? How does the most desired career vary by gender?\n\n\n\nanswer\nPISA_2022$OCOD3 %&gt;% unique() %&gt;% length()\n\nPISA_2022 %&gt;% \n  group_by(ST004D01T, OCOD3) %&gt;%\n  summarise(n =n()) %&gt;%\n  arrange(desc(n))\n\n\n\nwrite code to work out the mean and median PV1MATH score for each country CNT.\n\n\n\nanswer\nPISA_2022 %&gt;% \n  group_by(CNT) %&gt;%\n  summarise(mean_PV1MATH = mean(PV1MATH, na.rm=TRUE),\n            median_PV1MATH = median(PV1MATH, na.rm=TRUE)) %&gt;%\n  arrange(desc(median_PV1MATH))\n\n\n\nwhat is the fourth most popular language at home LANGN spoken by students in schools in the Ireland, how does this compare to Germany?\n\n\n\nanswer\nPISA_2022 %&gt;% \n  filter(CNT %in% c(\"Germany\", \"Ireland\")) %&gt;%\n  group_by(CNT, LANGN) %&gt;%\n  summarise(n = n()) %&gt;%\n  arrange(desc(n))\n\n\n\nSpot the five errors with the following code. Can you make it work? What does it do?\n\n\n# Work out when science scores are better than maths\nPISA_2022_scimath &lt; PISA_2022 %&gt;%\n  rename(gender = ST004D01T) %&gt;%\n  mutate(sci better = PV1SCIE - PV1MATH) %&gt;%\n  filter(is.na(scibetter) %&gt;%\n  group_by(CNT gender) %&gt;%\n  summarise(students = n,\n            sci_win = sum(scibetter &gt;= 0),\n            per_scibetter = 100*(sci_win/students))\n\n\n\nanswer\n# Work out when more time spent in language lessons than maths lessons\nPISA_2022_scimath &lt;- PISA_2022 %&gt;%  #1 make sure you have the assignment arrow &lt;-\n  rename(gender = ST004D01T) %&gt;%\n  mutate(sci_better = PV1MATH - PV1SCIE) %&gt;% #2 _ not space in name of field\n  filter(!is.na(sci_better)) %&gt;%  #3 this needs to be !is.na, otherwise it'll return nothing\n  group_by(CNT, gender) %&gt;% #4 missing comma\n  summarise(students = n(),   #5 missing brackets on the n() command\n            sci_win = sum(sci_better &gt;= 0),\n            per_sci_win = 100*(sci_win/students))\n\n\n\nBy country and gender work out the mean, median and standard deviations of STUBMI, order by the descending mean.\n\n\n\nanswer\npisa_bmi &lt;- PISA_2022 %&gt;%\n  rename(gender = ST004D01T) %&gt;%\n  group_by(CNT, gender) %&gt;%\n  summarise(n=n(),\n            bmi_mean = mean(STUBMI, na.rm=TRUE),\n            bmi_median = median(STUBMI, na.rm=TRUE),\n            bmi_sd = sd(STUBMI, na.rm=TRUE)) %&gt;%\n  arrange(desc(bmi_mean))",
    "crumbs": [
      "02 Introduction to R",
      "Piping and dplyr"
    ]
  },
  {
    "objectID": "chapters/02-3-Intro_to_analysis_software.html#teacher-dataset",
    "href": "chapters/02-3-Intro_to_analysis_software.html#teacher-dataset",
    "title": "Piping and dplyr",
    "section": "9.2 Teacher dataset",
    "text": "9.2 Teacher dataset\nTo further check your understanding of this section you will be attempting to analyse the 2022 teacher dataset. This dataset includes records for 68054 teachers from 18 countries, including 544 columns, covering attitudinal, demographic and workplace data. You can find the dataset here in the .parquet format.\n\n\nexample loading code\n# download the file then\n# Work out when more time spent in language lessons than maths lessons\nPISA_2022_teacher &lt;- read_parquet(\"C:/Users/Peter/Downloads/PISA_2012_teacher.parquet\")\n\n\n\n\nWork out how many teachers are in the dataset for Portugal\n\n\n\nanswer\nPISA_2022_teacher %&gt;% \n  group_by(CNTRYID) %&gt;%\n  summarise(n=n()) %&gt;%\n  filter(CNTRYID == \"Portugal\")\n\n\n\nFor each country CNTRYID by gender TC001Q01NA, what is the mean time that a teacher has been in the teaching profession TC007Q02NA? Include the number of teachers in each group. Order this to show the country with the longest serving workforce:\n\n\n\nanswer\nPISA_2022_teacher %&gt;%\n  group_by(CNTRYID, TC001Q01NA) %&gt;%\n  summarise(avg_years = mean(TC007Q02NA, na.rm=TRUE),\n            n = n()) %&gt;%\n  arrange(desc(avg_years))\n\n\n\nFor each country CNT find out which teachers report that they ‘Help students think critically’ TC199Q07HA. Hin: you’ll need to look at the levels of this question to find the correct filter:\n\n\n\nanswer\ncrit_thinking &lt;- PISA_2022_teacher %&gt;% \n  rename(crit_think = TC199Q07HA) %&gt;%\n  group_by(CNT) %&gt;%\n  mutate(teachers=n()) %&gt;%\n  group_by(CNT, crit_think) %&gt;%\n  summarise(n = n(),\n            per = n()/unique(teachers)) %&gt;%\n  arrange(desc(per)) %&gt;%\n  filter(crit_think == \"A lot\")\n\n# interestingly the highest performing countries also \n# have some of the lowest scores in helping children \n# think critically. To plot this:\n\nleft_join(crit_thinking,\n          PISA_2022 %&gt;% group_by(CNT) %&gt;% summarise(maths = mean(PV1MATH))) %&gt;%\n  ggplot(aes(x=per, y=maths)) + \n  geom_point() +\n  geom_smooth()\n\n\n\nExplore the data on use of technology in the classroom TC169____\n\n\n\nanswer\nPISA_2022_teacher %&gt;% select(CNT, TC001Q01NA, starts_with(\"TC169\"))\n\n\n\nSave the results of one of the above questions using write_csv().\n[EXTENSION] explore the dataset and find out some more interesting facts to share with your group",
    "crumbs": [
      "02 Introduction to R",
      "Piping and dplyr"
    ]
  }
]